{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5U8S7TPcTsw-",
        "outputId": "2a163614-2509-4a92-96f4-e86186732331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.18.5-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting crewai\n",
            "  Downloading crewai-0.141.0-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.4)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.14.1)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.38.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.2.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.2.1)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.9.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair==0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.25.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting json5>=0.10.0 (from crewai)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.72.6 (from crewai)\n",
            "  Downloading litellm-1.72.6-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting onnxruntime==1.22.0 (from crewai)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.93.3)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Collecting opentelemetry-api>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.10.1)\n",
            "Collecting python-dotenv>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.21.2)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.7.20-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.72.6->crewai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.72.6->crewai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.72.6->crewai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.72.6->crewai) (4.24.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.72.6->crewai) (0.9.0)\n",
            "Collecting coloredlogs (from onnxruntime==1.22.0->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.2.2.post1)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.73.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.18)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Requirement already satisfied: jiter<0.11,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.10.0)\n",
            "Collecting mkdocs-material>=9.5.49 (from instructor>=1.3.3->crewai)\n",
            "  Downloading mkdocs_material-9.6.15-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting mkdocs>=1.6.1 (from instructor>=1.3.3->crewai)\n",
            "  Downloading mkdocs-1.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting pre-commit>=4.2.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.33.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.1.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.9)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.20.3->crewai) (0.33.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.5.1)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (24.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (1.17.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.72.6->crewai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.72.6->crewai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.72.6->crewai) (3.23.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.72.6->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.72.6->crewai) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.72.6->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.72.6->crewai) (0.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting ghp-import>=1.0 (from mkdocs>=1.6.1->instructor>=1.3.3->crewai)\n",
            "  Downloading ghp_import-2.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: markdown>=3.3.6 in /usr/local/lib/python3.11/dist-packages (from mkdocs>=1.6.1->instructor>=1.3.3->crewai) (3.8.2)\n",
            "Collecting mergedeep>=1.3.4 (from mkdocs>=1.6.1->instructor>=1.3.3->crewai)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mkdocs-get-deps>=0.2.0 (from mkdocs>=1.6.1->instructor>=1.3.3->crewai)\n",
            "  Downloading mkdocs_get_deps-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pathspec>=0.11.1 (from mkdocs>=1.6.1->instructor>=1.3.3->crewai)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyyaml-env-tag>=0.1 (from mkdocs>=1.6.1->instructor>=1.3.3->crewai)\n",
            "  Downloading pyyaml_env_tag-1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting watchdog>=2.0 (from mkdocs>=1.6.1->instructor>=1.3.3->crewai)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel~=2.10 in /usr/local/lib/python3.11/dist-packages (from mkdocs-material>=9.5.49->instructor>=1.3.3->crewai) (2.17.0)\n",
            "Collecting backrefs~=5.7.post1 (from mkdocs-material>=9.5.49->instructor>=1.3.3->crewai)\n",
            "  Downloading backrefs-5.9-py311-none-any.whl.metadata (3.2 kB)\n",
            "Collecting colorama~=0.4 (from mkdocs-material>=9.5.49->instructor>=1.3.3->crewai)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting mkdocs-material-extensions~=1.3 (from mkdocs-material>=9.5.49->instructor>=1.3.3->crewai)\n",
            "  Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting paginate~=0.5 (from mkdocs-material>=9.5.49->instructor>=1.3.3->crewai)\n",
            "  Downloading paginate-0.5.7-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pymdown-extensions~=10.2 (from mkdocs-material>=9.5.49->instructor>=1.3.3->crewai)\n",
            "  Downloading pymdown_extensions-10.16-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.2.0->instructor>=1.3.3->crewai)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.2.0->instructor>=1.3.3->crewai)\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.2.0->instructor>=1.3.3->crewai)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.2.0->instructor>=1.3.3->crewai)\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.22.0->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.22.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from mkdocs-get-deps>=0.2.0->mkdocs>=1.6.1->instructor>=1.3.3->crewai) (4.3.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.2.0->instructor>=1.3.3->crewai)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.7-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.18.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.141.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.1/337.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.25.2-py3-none-any.whl (12 kB)\n",
            "Downloading litellm-1.72.6-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading instructor-1.9.2-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.7.20-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.4/18.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.38.1-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.6/212.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mkdocs-1.6.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mkdocs_material-9.6.15-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backrefs-5.9-py311-none-any.whl (392 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.1/392.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading ghp_import-2.1.0-py3-none-any.whl (11 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading mkdocs_get_deps-0.2.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl (8.7 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading paginate-0.5.7-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pymdown_extensions-10.16-py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml_env_tag-1.1-py3-none-any.whl (4.7 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, pypika\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=d4181c4df0aab5d8d08c44bff363e050aa6d0b67b922a4f7f43f380ac32dfaf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=b8132918b4105ed25fa5e989c5393dcd67c3de423e39cc537c251008e0794dc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built langdetect pypika\n",
            "Installing collected packages: pypika, paginate, filetype, durationpy, distlib, appdirs, XlsxWriter, watchdog, virtualenv, uvloop, uv, tomli-w, tomli, rapidfuzz, pyyaml-env-tag, python-magic, python-iso639, python-dotenv, pypdfium2, pypdf, pymupdf, pymdown-extensions, pybase64, pathspec, overrides, opentelemetry-proto, olefile, nodeenv, mypy-extensions, mmh3, mkdocs-material-extensions, mergedeep, marshmallow, langdetect, jsonref, json5, json-repair, jedi, identify, humanfriendly, httpx-sse, httptools, faiss-cpu, emoji, colorama, cfgv, bcrypt, backrefs, backoff, watchfiles, typing-inspect, python-pptx, python-oxmsg, pre-commit, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, mkdocs-get-deps, ghp-import, coloredlogs, unstructured-client, pyvis, pydantic-settings, pdfminer.six, opentelemetry-semantic-conventions, onnxruntime, mkdocs, kubernetes, dataclasses-json, unstructured, pdfplumber, opentelemetry-sdk, mkdocs-material, litellm, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, instructor, google-ai-generativelanguage, langchain_google_genai, chromadb, langchain-community, crewai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.2.5 appdirs-1.4.4 backoff-2.2.1 backrefs-5.9 bcrypt-4.3.0 cfgv-3.4.0 chromadb-1.0.15 colorama-0.4.6 coloredlogs-15.0.1 crewai-0.141.0 dataclasses-json-0.6.7 distlib-0.3.9 durationpy-0.10 emoji-2.14.1 faiss-cpu-1.11.0 filetype-1.2.0 ghp-import-2.1.0 google-ai-generativelanguage-0.6.18 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 identify-2.6.12 instructor-1.9.2 jedi-0.19.2 json-repair-0.25.2 json5-0.12.0 jsonref-1.1.0 kubernetes-33.1.0 langchain-community-0.3.27 langchain_google_genai-2.1.7 langdetect-1.0.9 litellm-1.72.6 marshmallow-3.26.1 mergedeep-1.3.4 mkdocs-1.6.1 mkdocs-get-deps-0.2.0 mkdocs-material-9.6.15 mkdocs-material-extensions-1.3.1 mmh3-5.1.0 mypy-extensions-1.1.0 nodeenv-1.9.1 olefile-0.47 onnxruntime-1.22.0 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-exporter-otlp-proto-http-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 paginate-0.5.7 pathspec-0.12.1 pdfminer.six-20250506 pdfplumber-0.11.7 posthog-5.4.0 pre-commit-4.2.0 pybase64-1.4.1 pydantic-settings-2.10.1 pymdown-extensions-10.16 pymupdf-1.26.3 pypdf-5.7.0 pypdfium2-4.30.1 pypika-0.48.9 python-dotenv-1.1.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 python-pptx-1.0.2 pyvis-0.3.2 pyyaml-env-tag-1.1 rapidfuzz-3.13.0 tomli-2.2.1 tomli-w-1.2.0 typing-inspect-0.9.0 unstructured-0.18.5 unstructured-client-0.38.1 uv-0.7.20 uvloop-0.21.0 virtualenv-20.31.2 watchdog-6.0.0 watchfiles-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "28a44d9d30204e20b661a37f32ffc7c8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain  langchain-community pypdf pymupdf langchain_google_genai unstructured python-pptx crewai faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEZrTpvPz8a6",
        "outputId": "0dd1db5d-3bd1-4070-d256-d0eeb4ba33b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\n",
            "Downloading reportlab-4.4.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.6/2.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: connect with drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krSuCGBXU60J",
        "outputId": "94629d03-5051-46bd-ad57-ac9a0062131f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, LLM\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\",\n",
        "    api_key=\"AIzaSyATVonQ3KEbyC6tRt-UF1d6g18HPwcjXAk\",\n",
        "    temperature=0.3,\n",
        ")"
      ],
      "metadata": {
        "id": "nAdJSOVcU7F6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import (\n",
        "    PyMuPDFLoader,\n",
        "    TextLoader,\n",
        "    UnstructuredWordDocumentLoader,\n",
        "    UnstructuredPowerPointLoader,\n",
        ")\n",
        "\n",
        "def load_documents(directory_path):\n",
        "    \"\"\"Load all PDF, TXT, DOCX, and PPTX documents from a directory\"\"\"\n",
        "    documents = []\n",
        "    titles = []\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        path = os.path.join(directory_path, filename)\n",
        "        ext = os.path.splitext(filename)[1].lower()\n",
        "\n",
        "        # Select appropriate loader\n",
        "        if ext == \".pdf\":\n",
        "            loader = PyMuPDFLoader(path)\n",
        "        elif ext == \".txt\":\n",
        "            loader = TextLoader(path, encoding=\"utf-8\")\n",
        "        elif ext == \".docx\":\n",
        "            loader = UnstructuredWordDocumentLoader(path)\n",
        "        elif ext == \".pptx\":\n",
        "            loader = UnstructuredPowerPointLoader(path)\n",
        "        else:\n",
        "            print(f\"Skipping unsupported file: {filename}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Load and enrich documents\n",
        "            docs = loader.load()\n",
        "            title = os.path.splitext(filename)[0]\n",
        "            titles.append(title)\n",
        "\n",
        "            for doc in docs:\n",
        "                doc.metadata[\"title\"] = title\n",
        "                doc.metadata[\"source_file\"] = filename\n",
        "\n",
        "            documents.extend(docs)\n",
        "            print(f\"Loaded document: {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load {filename}: {e}\")\n",
        "\n",
        "    print(f\"\\n✅ Total documents loaded: {len(documents)}\")\n",
        "    return documents, titles\n"
      ],
      "metadata": {
        "id": "-1jqYht6VB5H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "def split_by_chunk_size(documents, chunk_size=1000):\n",
        "\n",
        "    all_chunks = []\n",
        "\n",
        "    doc_groups = {}\n",
        "    for doc in documents:\n",
        "        doc_id = doc.metadata.get(\"title\") or doc.metadata.get(\"source_file\") or \"Unknown_Document\"\n",
        "        doc_groups.setdefault(doc_id, []).append(doc)\n",
        "\n",
        "    # Process each grouped document\n",
        "    for doc_id, docs in doc_groups.items():\n",
        "        full_text = \" \".join([doc.page_content for doc in docs])\n",
        "        source_file = docs[0].metadata.get(\"source_file\", doc_id)\n",
        "\n",
        "        num_chunks = (len(full_text) + chunk_size - 1) // chunk_size\n",
        "\n",
        "        for i in range(0, len(full_text), chunk_size):\n",
        "            chunk_text = full_text[i:i + chunk_size]\n",
        "            chunk_index = i // chunk_size\n",
        "\n",
        "            chunk = Document(\n",
        "                page_content=chunk_text,\n",
        "                metadata={\n",
        "                    \"title\": doc_id,\n",
        "                    \"source_file\": source_file,\n",
        "                    \"chunk_index\": chunk_index,\n",
        "                    \"total_chunks\": num_chunks\n",
        "                }\n",
        "            )\n",
        "            all_chunks.append(chunk)\n",
        "\n",
        "        print(f\"✅ Split document '{doc_id}' into {num_chunks} chunks\")\n",
        "\n",
        "    print(f\"\\n📄 Total chunks created: {len(all_chunks)}\")\n",
        "    return all_chunks\n"
      ],
      "metadata": {
        "id": "tSS1aMG6VCFN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def create_vector_store(chunks):\n",
        "    \"\"\"\n",
        "    Create a vector store from document chunks\n",
        "    \"\"\"\n",
        "    print(\"Creating vector store...\")\n",
        "    # Using HuggingFace embeddings (open-source alternative)\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    # Create the vector store\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    print(\"Vector store created successfully\")\n",
        "    return vector_store"
      ],
      "metadata": {
        "id": "oui0VTUlVLKr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_database={}\n"
      ],
      "metadata": {
        "id": "BkyR4EIGsg_X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "course_name=\"classical machine learning\"\n",
        "saved_name=course_name+\"vector\"\n",
        "def get_vector_store(folder_path,found,course_name):\n",
        "    if found==False:\n",
        "        documents, candidate_names = load_documents(folder_path)\n",
        "        chunks=split_by_chunk_size(documents)\n",
        "        vector_store = create_vector_store(chunks)\n",
        "        vector_store.save_local(saved_name)\n",
        "        vector_database[course_name]=saved_name\n",
        "    else:\n",
        "        vector_store = FAISS.load_local(saved_name, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),allow_dangerous_deserialization=True)\n",
        "    return vector_store\n"
      ],
      "metadata": {
        "id": "R8VJZcS-Wz6z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.dml.color import RGBColor\n",
        "from pptx.enum.text import PP_PARAGRAPH_ALIGNMENT\n",
        "from crewai.tools import tool\n",
        "import re\n",
        "\n",
        "@tool\n",
        "def generate_pptx_from_json(json_data: dict) -> str:\n",
        "    \"\"\"\n",
        "    Generate PowerPoint from structured JSON content, including:\n",
        "    - Agenda slides with overflow handling\n",
        "    - Content slides with bullet splitting\n",
        "    - Code block formatting\n",
        "    - Spacing, coloring, layout consistency\n",
        "    \"\"\"\n",
        "\n",
        "    # Design & Layout\n",
        "    primary_color = RGBColor(139, 0, 0)        # Dark red for headers & agenda\n",
        "    dark_text = RGBColor(30, 30, 30)           # General text\n",
        "    code_bg = RGBColor(240, 240, 240)          # Code block background\n",
        "    white_bg = RGBColor(255, 255, 255)         # Background\n",
        "\n",
        "    font_name = \"Calibri\"\n",
        "    code_font_name = \"Consolas\"\n",
        "    title_font_size = Pt(36)\n",
        "    header_font_size = Pt(28)\n",
        "    content_font_size = Pt(20)\n",
        "    code_font_size = Pt(16)\n",
        "    max_bullets_per_slide = 6\n",
        "\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Title Slide\n",
        "    title_slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
        "    title = title_slide.shapes.title\n",
        "    title.text = json_data.get(\"course_title\", \"Course Title\")\n",
        "    title.text_frame.paragraphs[0].font.size = title_font_size\n",
        "    title.text_frame.paragraphs[0].font.bold = True\n",
        "    title.text_frame.paragraphs[0].font.color.rgb = primary_color\n",
        "\n",
        "    def split_into_bullets(text_or_list):\n",
        "        \"\"\"Handles both strings and lists.\"\"\"\n",
        "        if isinstance(text_or_list, list):\n",
        "            return text_or_list\n",
        "        lines = [p.strip() for p in str(text_or_list).split('\\n') if p.strip()]\n",
        "        bullets = []\n",
        "        for line in lines:\n",
        "            if len(line.split()) > 15 or any(x in line for x in [';', '•', '- ', '1.', '2.']):\n",
        "                split_line = re.split(r'(?<=[.;]) |(?<=\\d\\.) |(?<=•) |(?<=- )', line)\n",
        "                bullets.extend([s.strip() for s in split_line if s.strip()])\n",
        "            else:\n",
        "                bullets.append(line)\n",
        "        return bullets\n",
        "\n",
        "    def add_agenda_slide(agenda_items, part=1):\n",
        "        \"\"\"Adds one agenda slide with up to max_bullets_per_slide bullet items.\"\"\"\n",
        "        slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
        "        title = slide.shapes.title\n",
        "        suffix = f\" (Part {part})\" if part > 1 else \"\"\n",
        "        title.text = \"Agenda\" + suffix\n",
        "        title.text_frame.paragraphs[0].font.size = header_font_size\n",
        "        title.text_frame.paragraphs[0].font.color.rgb = primary_color\n",
        "        title.text_frame.paragraphs[0].font.bold = True\n",
        "\n",
        "        tf = slide.placeholders[1].text_frame\n",
        "        tf.clear()\n",
        "\n",
        "        for entry in agenda_items:\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = entry['text']\n",
        "            p.level = entry['level']\n",
        "            p.font.name = font_name\n",
        "            p.font.size = header_font_size if entry['level'] == 0 else content_font_size\n",
        "            p.font.color.rgb = primary_color if entry['level'] == 0 else dark_text\n",
        "            p.font.bold = entry['level'] == 0\n",
        "            p.space_after = Pt(4)\n",
        "\n",
        "    # Generate full agenda list\n",
        "    full_agenda = []\n",
        "    for topic in json_data.get(\"topics\", []):\n",
        "        full_agenda.append({'text': topic.get(\"topic_title\", \"Untitled Topic\"), 'level': 0})\n",
        "        for session in topic.get(\"sessions\", []):\n",
        "            full_agenda.append({'text': session.get(\"session_title\", \"Untitled Session\"), 'level': 1})\n",
        "\n",
        "    # Create paginated agenda slides\n",
        "    i = 0\n",
        "    part = 1\n",
        "    while i < len(full_agenda):\n",
        "        add_agenda_slide(full_agenda[i:i + max_bullets_per_slide], part)\n",
        "        i += max_bullets_per_slide\n",
        "        part += 1\n",
        "\n",
        "    def add_content_slide(session_title, bullets, examples, code, part=1):\n",
        "        \"\"\"Adds content slide with header and up to max_bullets_per_slide bullets.\"\"\"\n",
        "        slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
        "        slide.background.fill.solid()\n",
        "        slide.background.fill.fore_color.rgb = white_bg\n",
        "\n",
        "        # Title\n",
        "        title = slide.shapes.title\n",
        "        suffix = f\" (Part {part})\" if part > 1 else \"\"\n",
        "        title.text = session_title + suffix\n",
        "        title.text_frame.paragraphs[0].font.size = header_font_size\n",
        "        title.text_frame.paragraphs[0].font.color.rgb = primary_color\n",
        "        title.text_frame.paragraphs[0].font.bold = True\n",
        "\n",
        "        # Bullet content\n",
        "        content = slide.placeholders[1]\n",
        "        tf = content.text_frame\n",
        "        tf.clear()\n",
        "\n",
        "        count = 0\n",
        "        for point in bullets[:max_bullets_per_slide]:\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = point\n",
        "            p.level = 0\n",
        "            p.font.name = font_name\n",
        "            p.font.size = content_font_size\n",
        "            p.font.color.rgb = dark_text\n",
        "            p.space_after = Pt(6)\n",
        "            count += 1\n",
        "\n",
        "        # Examples\n",
        "        for ex in examples:\n",
        "            for ex_point in split_into_bullets(ex):\n",
        "                if count >= max_bullets_per_slide:\n",
        "                    break\n",
        "                p = tf.add_paragraph()\n",
        "                p.text = ex_point\n",
        "                p.level = 0\n",
        "                p.font.name = font_name\n",
        "                p.font.size = content_font_size\n",
        "                p.font.italic = True\n",
        "                p.font.color.rgb = dark_text\n",
        "                p.space_after = Pt(6)\n",
        "                count += 1\n",
        "\n",
        "        # Code block\n",
        "        if code and part == 1:\n",
        "            code_lines = code.strip().split('\\n')\n",
        "            if len(code_lines) > 0:\n",
        "                txBox = slide.shapes.add_textbox(Inches(1), Inches(5.3), Inches(8), Inches(1.2))\n",
        "                tf_code = txBox.text_frame\n",
        "                tf_code.clear()\n",
        "                p_code = tf_code.add_paragraph()\n",
        "                p_code.text = code.strip()\n",
        "                p_code.font.name = code_font_name\n",
        "                p_code.font.size = code_font_size\n",
        "                p_code.font.color.rgb = dark_text\n",
        "                txBox.fill.solid()\n",
        "                txBox.fill.fore_color.rgb = code_bg\n",
        "\n",
        "        return bullets[max_bullets_per_slide:]\n",
        "\n",
        "    # Content Slides\n",
        "    for topic in json_data.get(\"topics\", []):\n",
        "        for session in topic.get(\"sessions\", []):\n",
        "            bullets = split_into_bullets(session.get(\"content\", []))\n",
        "            examples = session.get(\"examples\", []) if isinstance(session.get(\"examples\", []), list) else []\n",
        "            code = session.get(\"code\", \"\")\n",
        "            part = 1\n",
        "            while bullets:\n",
        "                bullets = add_content_slide(session.get(\"session_title\", \"Untitled Session\"), bullets, examples if part == 1 else [], code if part == 1 else \"\", part)\n",
        "                part += 1\n",
        "\n",
        "    prs.save(\"course_presentation.pptx\")\n",
        "    return \"✅ PowerPoint saved as 'course_presentation.pptx' with multi-page agenda and structured slides.\"\n"
      ],
      "metadata": {
        "id": "n024luHdoSAq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, LLM\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "class Project_agents:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize with a selected LLM provider and model\"\"\"\n",
        "        self.llm = llm\n",
        "\n",
        "    def context_retriever_agent(self):\n",
        "        return Agent(\n",
        "            role=\"Document Search Assistant\",\n",
        "            goal=\"Find and return relevant text chunks for each topic from a document store.\",\n",
        "            backstory=(\n",
        "                \"You specialize in retrieving relevant information for educational purposes. \"\n",
        "                \"When given a topic, you search a document database and return the most relevant text chunks \"\n",
        "                \"to support curriculum generation and slide creation.\"\n",
        "            ),\n",
        "            verbose=True,\n",
        "            allow_delegation=False,\n",
        "            llm=self.llm\n",
        "    )\n",
        "\n",
        "    def summary_agent(self):\n",
        "        \"\"\"Initialize with a selected LLM provider and model\"\"\"\n",
        "        return Agent(\n",
        "            role=\"HTML Summary Generator\",\n",
        "            goal=\"Generate a clear and well-structured HTML summary from the input content.\",\n",
        "            backstory=(\n",
        "                \"You are an expert assistant specialized in transforming complex or lengthy educational content \"\n",
        "                \"into organized, visually structured HTML summaries. You make the information easy to understand \"\n",
        "                \"by dividing it into sections with headers, paragraphs, and bullet points.\"\n",
        "            ),\n",
        "            verbose=True,\n",
        "            allow_delegation=False,\n",
        "            llm=self.llm,\n",
        "            instructions=f\"\"\"\n",
        "You will receive a block of raw content. Your task is to:\n",
        "- Carefully analyze and summarize the content\n",
        "- Format the output as a valid HTML page\n",
        "\n",
        "📄 Output Formatting Instructions:\n",
        "- Use <h1> for the main title (if identifiable)\n",
        "- Use <h2> for section headings like \"Overview\", \"Key Points\", \"Examples\", \"Conclusion\"\n",
        "- Use <p> for paragraph content\n",
        "- Use <ul><li> for lists or bullet points\n",
        "- Ensure spacing and nesting are correct for proper rendering\n",
        "- Do not include any explanatory text, only return clean HTML content\n",
        "\n",
        "🧠 Content Understanding:\n",
        "- Identify and highlight the main ideas\n",
        "- Break down the explanation into short readable sections\n",
        "- Include real-world examples or applications if mentioned\n",
        "\n",
        "\n",
        "🎯 Return only a complete and well-structured HTML document (no Markdown, no comments).\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "    def json_agent(self,context):\n",
        "\n",
        "      return Agent(\n",
        "        role=\"Course Structuring and Summarization Agent\",\n",
        "        goal=(\n",
        "            \"Analyze the course content, summarize it accurately without missing key information, \"\n",
        "            \"organize it into well-defined topics and subtopics, and output it in a structured JSON format \"\n",
        "            \"ready for slide generation.\"\n",
        "        ),\n",
        "        backstory=(\n",
        "            \"You are an expert assistant trained to analyze and restructure educational content. \"\n",
        "            \"Given course material, your job is to understand and summarize the content into key topics and subtopics. \"\n",
        "            \"Each subtopic should include important points in a bullet-point format. \"\n",
        "            \"The final structured output should be ready for use in slide creation.\"\n",
        "        ),\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=self.llm,\n",
        "        instructions=(\n",
        "            \"You will be given course content. Based on this content:\\n\\n\"\n",
        "            \"1. Understand the entire material deeply and identify all **key topics** or **chapters**.\\n\"\n",
        "            \"2. Under each topic, create **subtopics or sessions**, and summarize them clearly.\\n\"\n",
        "            \"3. For each session, extract the main concepts into **bullet points** to ensure clarity and coverage.\\n\\n\"\n",
        "            \"💡 For example:\\n\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"course_title\\\": \\\"Introduction to Ensemble Learning\\\",\\n\"\n",
        "            \"  \\\"topics\\\": [\\n\"\n",
        "            \"    {\\n\"\n",
        "            \"      \\\"topic_title\\\": \\\"Ensemble Learning\\\",\\n\"\n",
        "            \"      \\\"sessions\\\": [\\n\"\n",
        "            \"        {\\n\"\n",
        "            \"          \\\"session_title\\\": \\\"Random Forest\\\",\\n\"\n",
        "            \"          \\\"content\\\": [\\n\"\n",
        "            \"            \\\"Random Forest is an ensemble of decision trees\\\",\\n\"\n",
        "            \"            \\\"It reduces variance and avoids overfitting\\\",\\n\"\n",
        "            \"            \\\"Uses bagging and feature randomness\\\"\\n\"\n",
        "            \"          ]\\n\"\n",
        "            \"        },\\n\"\n",
        "            \"        {\\n\"\n",
        "            \"          \\\"session_title\\\": \\\"Boosting\\\",\\n\"\n",
        "            \"          \\\"content\\\": [\\n\"\n",
        "            \"            \\\"Boosting focuses on errors made by previous models\\\",\\n\"\n",
        "            \"            \\\"Popular boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost\\\",\\n\"\n",
        "            \"            \\\"It reduces bias and improves prediction accuracy\\\"\\n\"\n",
        "            \"          ]\\n\"\n",
        "            \"        }\\n\"\n",
        "            \"      ]\\n\"\n",
        "            \"    }\\n\"\n",
        "            \"  ]\\n\"\n",
        "            \"}\\n\\n\"\n",
        "            \"✔️ Ensure:\\n\"\n",
        "            \"- The structure is clean and fully JSON-compatible.\\n\"\n",
        "            \"- No important concepts are missed.\\n\"\n",
        "            \"- Each session has bullet-point content for easier transformation into slides.\\n\"\n",
        "            \"- Keep explanations concise, clear, and factual.\\n\"\n",
        "        ),\n",
        "        memory=[{\"context\": context}]\n",
        "    )\n",
        "\n",
        "    def pptx_generation_agent(self):\n",
        "\n",
        "      return Agent(\n",
        "        role=\"Bullet Point PowerPoint Specialist\",\n",
        "        goal=\"Transform a structured JSON course file into a polished PowerPoint presentation with a full agenda and detailed, bulleted slides.\",\n",
        "        backstory=(\n",
        "            \"You are a presentation specialist converting structured JSON into PowerPoint slides. \"\n",
        "            \"You include an agenda, break content into bullet points, and add brief introductory details to enrich each session.\"\n",
        "        ),\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=self.llm,\n",
        "        instructions=(\n",
        "            \"INPUT:\\n\"\n",
        "            \"- A structured JSON file:\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"course_title\\\": \\\"...\\\",\\n\"\n",
        "            \"  \\\"topics\\\": [\\n\"\n",
        "            \"    {\\n\"\n",
        "            \"      \\\"topic_title\\\": \\\"...\\\",\\n\"\n",
        "            \"      \\\"sessions\\\": [\\n\"\n",
        "            \"        {\\n\"\n",
        "            \"          \\\"session_title\\\": \\\"...\\\",\\n\"\n",
        "            \"          \\\"content\\\": [\\n\"\n",
        "            \"            \\\"bullet point 1\\\",\\n\"\n",
        "            \"            \\\"bullet point 2\\\",\\n\"\n",
        "            \"            ...\\n\"\n",
        "            \"          ]\\n\"\n",
        "            \"        }\\n\"\n",
        "            \"      ]\\n\"\n",
        "            \"    }\\n\"\n",
        "            \"  ]\\n\"\n",
        "            \"}\\n\\n\"\n",
        "\n",
        "            \"AGENDA RULES:\\n\"\n",
        "            \"1. Create one or more slides titled 'Agenda' immediately after the title slide.\\n\"\n",
        "            \"2. Display ALL topic titles and session titles using nested bullets:\\n\"\n",
        "            \"   - Topic Title → Level 0, dark red, bold, 28pt\\n\"\n",
        "            \"   - Session Title → Level 1, gray, normal, 20pt\\n\"\n",
        "            \"3. If >6 items total, split agenda across multiple slides labeled 'Agenda (Part 2)', etc.\\n\"\n",
        "\n",
        "            \"SESSION SLIDES:\\n\"\n",
        "            \"For each session:\\n\"\n",
        "            \"1. Create a slide titled with the `session_title`\\n\"\n",
        "            \"2. Just below the title, add a **brief detailed summary** or explanatory paragraph (1–2 lines max), generated from the title and bullet themes.\\n\"\n",
        "            \"   - Format: italic, Calibri, 18pt, gray, max width of 2 lines\\n\"\n",
        "            \"3. Below the detail paragraph, add the bullet points from `content`\\n\"\n",
        "            \"   - Each bullet: ≤ 2 lines\\n\"\n",
        "            \"   - If >6 bullets, split into multiple slides (Session Title (Part 2), etc.)\\n\"\n",
        "            \"   - Indent sub-points where needed\\n\"\n",
        "            \"   - Italicize examples\\n\"\n",
        "            \"   - Bold technical terms\\n\"\n",
        "            \"   - Use larger font (22pt) for key concepts\\n\"\n",
        "\n",
        "            \"CODE RULES:\\n\"\n",
        "            \"If any bullet contains code (e.g. starts with `def`, `class`, `import`, or uses symbols like `()`, `{}`):\\n\"\n",
        "            \"- Extract it into a dedicated code block (gray box, monospaced font, preserved indentation)\\n\"\n",
        "            \"- Place the code block below the bullets (or move to next slide if space is limited)\\n\"\n",
        "            \"- Add line numbers if >5 lines\\n\"\n",
        "            \"- Keep code block ≤ 1/3 of slide height\\n\"\n",
        "\n",
        "            \"QUALITY CONTROL:\\n\"\n",
        "            \"- No bullets should wrap beyond 2 lines\\n\"\n",
        "            \"- No slide should have more than 6 main bullets\\n\"\n",
        "            \"- Code blocks and bullets should never overlap\\n\"\n",
        "            \"- Ensure detailed paragraph appears before bullets\\n\"\n",
        "\n",
        "            \"FINAL OUTPUT:\\n\"\n",
        "            \"- Export the file as 'course_presentation.pptx'\\n\"\n",
        "            \"- Agenda must be complete and fully paginated if needed\\n\"\n",
        "            \"- All session content must be present, formatted, and include a detail paragraph\\n\"\n",
        "            \"- Slides must be presentation-ready, clean, and consistent\"\n",
        "        ),\n",
        "        tools=[generate_pptx_from_json]\n",
        "    )\n",
        "\n",
        "    def narrative_agent(self):\n",
        "      return Agent(\n",
        "        role=\"Narrative Creator\",\n",
        "        goal=\"Generate educational narrative text based on course context and input content.\",\n",
        "        backstory=\"You are specialized in creating clear, engaging educational narratives.\",\n",
        "        llm=llm,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    def customize_agent(self):\n",
        "        return Agent(\n",
        "          role=\"Narrative Customizer\",\n",
        "          goal=\"Revise the narrative text to match specified style, language, and length.\",\n",
        "          backstory=\"You are an expert in adapting educational content to different tones and styles.\",\n",
        "          llm=llm,\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Ok194LEX8D-"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "narrative_prompt = PromptTemplate(\n",
        "    input_variables=[\n",
        "        \"content\",\n",
        "        \"presentation\",\n",
        "        \"course_title\",\n",
        "        \"course_desc\",\n",
        "        \"audience_age\",\n",
        "        \"teaching_style\",\n",
        "        \"language\"\n",
        "    ],\n",
        "    template=\"\"\"\n",
        "You are a highly skilled educational content narrator.\n",
        "\n",
        "Your goal is to generate an engaging, easy-to-follow narrative that reflects the structure of a PowerPoint presentation and expands on the key points.\n",
        "\n",
        "---\n",
        "\n",
        "Course Title: {course_title}\n",
        "Course Description: {course_desc}\n",
        "Audience Age Group: {audience_age}\n",
        "Teaching Style: {teaching_style}\n",
        "Language: {language}\n",
        "\n",
        "---\n",
        "\n",
        "Presentation Slide Outline:\n",
        "{presentation}\n",
        "\n",
        "Raw Content for This Section:\n",
        "{content}\n",
        "\n",
        "---\n",
        "\n",
        "🎯 Instructions:\n",
        "Write a **structured educational narrative** that includes estimated **time durations** for each part. Format it so it can be used as a **video script**.\n",
        "\n",
        "For each section, include:\n",
        "1. **[Duration: ~X min]** at the beginning of the paragraph.\n",
        "2. A clear and age-appropriate **introduction** to the topic.\n",
        "3. A **step-by-step walkthrough** of each key point or slide element, reflecting the `presentation`.\n",
        "4. A **real-world example or analogy** to make the topic relatable.\n",
        "5. A **brief conclusion** connecting the lesson back to the overall course goal.\n",
        "\n",
        "💡 Tone & Style:\n",
        "- Match the teaching style: {teaching_style}\n",
        "- Language: {language}\n",
        "- Use age-appropriate vocabulary and structure based on the audience age: {audience_age}\n",
        "- Ensure logical flow aligned with the slide sequence\n",
        "- Avoid excessive technical jargon unless intended for advanced audiences\n",
        "\n",
        "🕒 Example Output Structure:\n",
        "[Duration: ~1 min] Introduction\n",
        "[Duration: ~2 min] Slide 1 Explanation\n",
        "[Duration: ~2 min] Slide 2 Explanation\n",
        "[Duration: ~1 min] Real-World Analogy\n",
        "[Duration: ~1 min] Conclusion\n",
        "\n",
        "---\n",
        "\n",
        "Return only the narrative in plain text, clearly structured with headings and time estimates.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "customize_prompt = PromptTemplate(\n",
        "    input_variables=[\"narrative\", \"style\", \"language\", \"length\"],\n",
        "    template=\"\"\"\n",
        "You are an expert educational narrative editor and HTML formatter.\n",
        "\n",
        "Here is the original narrative:\n",
        "{narrative}\n",
        "\n",
        "Revise it according to the following:\n",
        "- Writing Style: {style}\n",
        "- Language: {language}\n",
        "- Desired Length: {length} (e.g., short summary, in-depth walkthrough)\n",
        "\n",
        "🎯 Output Instructions:\n",
        "- Format the final output in **clean, well-structured HTML**\n",
        "- Use a **black-and-white color scheme** (purely grayscale)\n",
        "- Use appropriate HTML tags:\n",
        "  - <h1> for the main title\n",
        "  - <h2> for section headers (e.g., \"Introduction\", \"Key Concepts\", \"Real-World Example\", \"Conclusion\")\n",
        "  - Add a small estimated duration under each section header (e.g., <small>~2 minutes</small>)\n",
        "  - <p> for paragraphs\n",
        "  - <ul><li> for bullet points (if needed)\n",
        "- Wrap the output in complete HTML including <html>, <head>, <body>\n",
        "- Apply this CSS:\n",
        "  - Body: white background, black text\n",
        "  - Font: Helvetica, Arial, sans-serif\n",
        "  - No borders, no background colors\n",
        "  - Clean layout suitable for printing and web reading\n",
        "\n",
        "🚫 Do NOT include:\n",
        "- Any markdown\n",
        "- Instructional text\n",
        "- Extra commentary outside of HTML\n",
        "\n",
        "📄 This content will be saved into a `narrative.html` file and viewed in a web browser.\n",
        "\n",
        "Return only the complete HTML file, properly formatted and styled.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BQahgoVwBfx-"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "from tqdm import tqdm\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "\n",
        "class ProjectTasks:\n",
        "\n",
        "  def retrieve_combined_context_task(self, agent, course_name, course_description, found, folder_path,topic, k=30):\n",
        "    \"\"\"\n",
        "    Retrieves context from the vector store relevant to a specific topic/lesson/chapter.\n",
        "\n",
        "    Args:\n",
        "        agent: The LLM agent to handle the task.\n",
        "        course_name: The overall name of the course.\n",
        "        course_description: A general description of the course.\n",
        "        found: Data required to build the vector store.\n",
        "        folder_path: Path to the vector store or documents.\n",
        "        query: Specific topic, lesson, or chapter to retrieve context for.\n",
        "        k: Number of most similar documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        A Task object with context relevant to the specific query.\n",
        "    \"\"\"\n",
        "    # Build the vector store\n",
        "    vector_store = get_vector_store(folder_path, found, course_name)\n",
        "\n",
        "    # Search based on specific topic/chapter/lesson\n",
        "    relevant_docs = vector_store.similarity_search(topic, k=k)\n",
        "\n",
        "    # Combine document content\n",
        "    combined_context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "    # Return a task with detailed instructions and context\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"You are given content from the course '{course_name}'.\\n\\n\"\n",
        "            f\"Course Description: {course_description}\\n\\n\"\n",
        "            f\"Your task is to focus specifically on the topic: '{topic}' and extract or summarize relevant information.\\n\\n\"\n",
        "            f\"Context:\\n{combined_context}\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        expected_output=f\"A summary, explanation, or response focused on: '{topic}'.\"\n",
        "    )\n",
        "\n",
        "\n",
        "  def summary_task(self, agent, context):\n",
        "        task = Task(\n",
        "            agent=agent,\n",
        "            description=\"Summarize the input content and return a well-formatted HTML page.\",\n",
        "            expected_output=\"Valid HTML with structured sections (<h1>, <h2>, <p>, <ul><li>) saved as summary.html\",\n",
        "            context=context\n",
        "        )\n",
        "  def json_task(self, agent, age, experience_level,context):\n",
        "\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"You are tasked with converting the provided course context into a structured JSON format, ready for presentation slides.\\n\\n\"\n",
        "            f\"🎯 Target Audience:\\n\"\n",
        "            f\"- Age Group: {age}\\n\"\n",
        "            f\"- Experience Level: {experience_level}\\n\\n\"\n",
        "            f\"📋 Instructions:\\n\"\n",
        "            f\"1. Analyze and understand the provided course material thoroughly.\\n\"\n",
        "            f\"2. Identify major **topics or chapters** based on the flow of the content.\\n\"\n",
        "            f\"3. Break down each topic into **sessions** (or subtopics).\\n\"\n",
        "            f\"4. Summarize the content of each session using **bullet points**.\\n\"\n",
        "            f\"5. Adapt the tone and depth of content to match the **target audience**:\\n\"\n",
        "            f\"   - Use engaging, simple, and example-rich language for younger or beginner users.\\n\"\n",
        "            f\"   - Use technical and detailed language for experienced or advanced learners.\\n\\n\"\n",
        "            f\"6. Return the output in the following **strict JSON format**:\\n\\n\"\n",
        "            \"{\\n\"\n",
        "            \"  \\\"course_title\\\": \\\"...\\\",\\n\"\n",
        "            \"  \\\"topics\\\": [\\n\"\n",
        "            \"    {\\n\"\n",
        "            \"      \\\"topic_title\\\": \\\"...\\\",\\n\"\n",
        "            \"      \\\"sessions\\\": [\\n\"\n",
        "            \"        {\\n\"\n",
        "            \"          \\\"session_title\\\": \\\"...\\\",\\n\"\n",
        "            \"          \\\"content\\\": [\\n\"\n",
        "            \"            \\\"Bullet point 1\\\",\\n\"\n",
        "            \"            \\\"Bullet point 2\\\",\\n\"\n",
        "            \"            \\\"...\\\"\\n\"\n",
        "            \"          ]\\n\"\n",
        "            \"        }\\n\"\n",
        "            \"      ]\\n\"\n",
        "            \"    }\\n\"\n",
        "            \"  ]\\n\"\n",
        "            \"}\\n\\n\"\n",
        "            f\"⚠️ Ensure the JSON is clean, coherent, and free of missing or redundant information.\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        expected_output=(\n",
        "            \"A JSON file that clearly organizes the course into topics and bullet-point sessions, \"\n",
        "            \"tailored to the specified age and experience level. Ready to be used in slide generation.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def pptx_task(self, agent, input_from):\n",
        "    return Task(\n",
        "        description=(\n",
        "            \"Take the JSON output from the previous step and generate a PowerPoint presentation. \"\n",
        "            \"Include a title slide with the course name and audience info, then one slide per session with session titles and content.\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        expected_output=\"A PowerPoint file named 'course_presentation.pptx'.\",\n",
        "        input_from=agent  # or explicitly input_from if your system requires\n",
        "    )\n",
        "\n",
        "  def narrative_task(self,content_task, course_name, course_description, presentation_task, age, teaching_style, language, narrative_agent, narrative_prompt):\n",
        "    return Task(\n",
        "        agent=narrative_agent,\n",
        "        description=narrative_prompt.format(\n",
        "            content=content_task.output,\n",
        "            course_title=course_name,\n",
        "            course_desc=course_description,\n",
        "            presentation=presentation_task.output,\n",
        "            audience_age=age,\n",
        "            teaching_style=teaching_style,\n",
        "            language=language\n",
        "        ),\n",
        "        expected_output=\"Narrative text explaining the topic clearly in English.\"\n",
        "    )\n",
        "\n",
        "  def customize_task(self,narrative_task, customize_agent, customize_prompt,teaching_style,language,length):\n",
        "    return Task(\n",
        "        agent=customize_agent,\n",
        "        description=customize_prompt.format(\n",
        "            narrative=narrative_task.output,\n",
        "            style=teaching_style,\n",
        "            language=language,\n",
        "            length=length\n",
        "        ),\n",
        "        expected_output=\"Customized narrative text matching style and length and saved to 'narrative.html' \",\n",
        "        output_file=\"narrative.html\"\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "lHQ4pHlwYoIK"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/Matrials\"\n",
        "course_name=\"classical machine learning\"\n",
        "course_description=\"An introduction to core machine learning algorithms like regression, classification, and clustering, focusing on their concepts and practical applications.\"\n",
        "topic=\"ensemble learning\"\n",
        "age=\"20-22\",\n",
        "experience_level=\"advanced\"\n",
        "language=\"English\"\n",
        "teaching_style=\"Motivational storytelling\"\n",
        "length=\"Detailed explanation with example\"\n",
        "found=False\n",
        "for course in vector_database.keys():\n",
        "  if course==course_name:\n",
        "    found=True"
      ],
      "metadata": {
        "id": "DAaIqdI_hS-0"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(found)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN_PKhu0qmBN",
        "outputId": "70c814ee-86a9-44c4-d7f5-e223f4df92af"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "import json\n",
        "\n",
        "class Project_crew:\n",
        "    def __init__(self):\n",
        "        self.agents = Project_agents()\n",
        "        self.tasks = ProjectTasks()\n",
        "\n",
        "    def create_crew(self):\n",
        "        # Define agents\n",
        "        content_creator = self.agents.context_retriever_agent()\n",
        "        summary_creator=self.agents.summary_agent()\n",
        "        json_creator = self.agents.json_agent(content_creator)\n",
        "        pptx_creator = self.agents.pptx_generation_agent()\n",
        "        narrative_creator = self.agents.narrative_agent()\n",
        "        customize_creator = self.agents.customize_agent()\n",
        "\n",
        "        # Define tasks\n",
        "        content_retriever_task = self.tasks.retrieve_combined_context_task(\n",
        "            agent=content_creator,\n",
        "            course_name=course_name,\n",
        "            course_description=course_description,\n",
        "            found=found,\n",
        "            folder_path=folder_path,\n",
        "            topic=topic\n",
        "        )\n",
        "\n",
        "        summary_task = self.tasks.summary_task(\n",
        "            agent=summary_creator,\n",
        "            context=content_retriever_task.output\n",
        "        )\n",
        "\n",
        "        json_task = self.tasks.json_task(\n",
        "            agent=json_creator,\n",
        "            age=age,\n",
        "            experience_level=experience_level,\n",
        "            context=content_retriever_task.output\n",
        "        )\n",
        "\n",
        "        pptx_task = self.tasks.pptx_task(\n",
        "            agent=pptx_creator,\n",
        "            input_from=json_task\n",
        "        )\n",
        "\n",
        "        narrative_task = self.tasks.narrative_task(content_retriever_task,course_name, course_description,\n",
        "                                pptx_task, age, teaching_style, language, narrative_creator, narrative_prompt)\n",
        "\n",
        "        customize_task = self.tasks.customize_task(\n",
        "            narrative_task, customize_creator, customize_prompt,teaching_style,language,length)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Create crew\n",
        "        return Crew(\n",
        "            agents=[content_creator,json_creator, pptx_creator,\n",
        "                narrative_creator, customize_creator],\n",
        "          tasks=[content_retriever_task,json_task, pptx_task,\n",
        "               narrative_task, customize_task],\n",
        "          process=Process.sequential,\n",
        "          verbose=False\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        crew = self.create_crew()\n",
        "        result = crew.kickoff()\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "wWTG04Ylfa-Z"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew=Project_crew()\n",
        "result=crew.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pw8-Fa6sfbGU",
        "outputId": "4ea55571-b910-4796-de90-5c38a51f747d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mDocument Search Assistant\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mYou are given content from the course 'classical machine learning'.\u001b[0m                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mCourse Description: An introduction to core machine learning algorithms like regression, classification, and \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclustering, focusing on their concepts and practical applications.\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYour task is to focus specifically on the topic: 'ensemble learning' and extract or summarize relevant \u001b[0m        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minformation.\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mContext:\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92me method, you can train a group of decision tree\u001b[0m                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclassifiers, each on a different random subset of the training set. You can then obtain\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe predictions of all the individual trees, and the class that gets the most votes is\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe ensemble’s prediction (see the last exercise in Chapter 6). Such an ensemble of\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdecision trees is called a random forest, and despite its simplicity, this is one of the\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmost powerful machine learning algorithms available today.\u001b[0m                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAs discussed in Chapter 2, you will often use ensemble methods near the end of\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ma project, once you have already built a few good predictors, to combine them\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minto an even better predictor. In fact, the winning solutions in machine learning\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcompetitions often involve several ensemble methods—most famously in the Netflix\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mPrize competition.\u001b[0m                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mIn this chapter we will examine the most popular ensemble methods, including\u001b[0m                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mvoting classifiers, bagging and pasting ensembles, random forests, and boosting, and\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mstacking ensembles.\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m211 Voting Classifiers\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m trained a blender, and\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mExercises \u001b[0m                                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m235 together with the classifiers it forms a stacking ensemble! Now evaluate the\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mensemble on the test set. For each image in the test set, make predictions with all\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92myour classifiers, then feed the predictions to the blender to get the ensemble’s pre‐\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdictions. How does it compare to the voting classifier you trained earlier? Now\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtry again using a StackingClassifier instead. Do you get better performance? If\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mso, why?\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSolutions to these exercises are available at the end of this chapter’s notebook, at\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mhttps://homl.info/colab3.\u001b[0m                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m236 \u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 7: Ensemble Learning and Random Forests CHAPTER 8\u001b[0m                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDimensionality Reduction\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mMany machine learning problems involve thousands or even millions of features for\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92meach training instance. Not only do all these features make training extremely slow,\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbut they can also make it much harder to find a good solution, as you will see. This\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mproblem is often referred to as the curse of dimensionality.\u001b[0m                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFortunately, in real-world \u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m7-3. The law of large numbers\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSimilarly, suppose you build an ensemble containing 1,000 classifiers that are indi‐\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mvidually correct only 51% of the time (barely better than random guessing). If you\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpredict the majority voted class, you can hope for up to 75% accuracy! However, this\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mis only true if all classifiers are perfectly independent, making uncorrelated errors,\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mwhich is clearly not the case because they are trained on the same data. They are likely\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mto make the same types of errors, so there will be many majority votes for the wrong\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclass, reducing the ensemble’s accuracy.\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mVoting Classifiers \u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m213 Ensemble methods work best when the predictors are as independ‐\u001b[0m                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ment from one another as possible. One way to get diverse classifiers\u001b[0m                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mis to train them using very different algorithms. This increases the\u001b[0m                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mchance that they will make very different types of errors, improving\u001b[0m                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe ensemble’s accuracy.\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mScikit-Learn provides a VotingClassifier class that’s quite easy to use: just give\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mit a list\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSuppose you have trained a few classifiers, each one achieving about 80% accuracy.\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYou may have a logistic regression classifier, an SVM classifier, a random forest\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclassifier, a k-nearest neighbors classifier, and perhaps a few more (see Figure 7-1).\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-1. Training diverse classifiers\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mA very simple way to create an even better classifier is to aggregate the predictions\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mof each classifier: the class that gets the most votes is the ensemble’s prediction. This\u001b[0m                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmajority-vote classifier is called a hard voting classifier (see Figure 7-2).\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-2. Hard voting classifier predictions\u001b[0m                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m212 \u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 7: Ensemble Learning and Random Forests Somewhat surprisingly, this voting classifier often achieves \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ma higher accuracy than\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe best classifier in the ensemble. In fact, even if each classifier is a weak learner\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(meaning it does only slightly better than random guessing), the ensemble can still be\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ma strong learner (achieving high accuracy), provided there are a sufficient number of\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mweak \u001b[0m                                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mt replacement, it is called\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpasting.4\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBagging and Pasting \u001b[0m                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m215 5 Bias and variance were introduced in Chapter 4.\u001b[0m                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mIn other words, both bagging and pasting allow training instances to be sampled\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mseveral times across multiple predictors, but only bagging allows training instances to\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbe sampled several times for the same predictor. This sampling and training process\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mis represented in Figure 7-4.\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-4. Bagging and pasting involve training several predictors on different random\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msamples of the training set\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mOnce all predictors are trained, the ensemble can make a prediction for a new\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minstance by simply aggregating the predictions of all predictors. The aggregation\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfunction is typically the statistical mode for classification (i.e., the most frequent\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mprediction, just like with a hard voting classifier), or the average for regression. Each\u001b[0m                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mindividual predictor has a higher bias than if it were trained on the original training\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mset, but aggregation reduces both bias and variance.5 General\u001b[0m                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mr the test set.\u001b[0m                                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92md. Evaluate these predictions on the test set: you should obtain a slightly higher\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92md.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92maccuracy than your first model (about 0.5 to 1.5% higher). Congratulations,\u001b[0m                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92myou have trained a random forest classifier!\u001b[0m                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSolutions to these exercises are available at the end of this chapter’s notebook, at\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mhttps://homl.info/colab3.\u001b[0m                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mExercises \u001b[0m                                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m209  CHAPTER 7\u001b[0m                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mEnsemble Learning and Random Forests\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSuppose you pose a complex question to thousands of random people, then aggregate\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtheir answers. In many cases you will find that this aggregated answer is better than\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92man expert’s answer. This is called the wisdom of the crowd. Similarly, if you aggregate\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe predictions of a group of predictors (such as classifiers or regressors), you will\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92moften get better predictions than with the best individual predictor. A group of\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpredictors is called an ensemble; thus, this technique is called ensemble learning, and\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92man ensemble learning algorithm is called an ensemble method.\u001b[0m                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAs an example of an ensembl\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m several rounds, the final\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcandidates are evaluated using full resources. This may save you some time tuning\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mhyperparameters.\u001b[0m                                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m94 \u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 2: End-to-End Machine Learning Project Ensemble Methods\u001b[0m                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAnother way to fine-tune your system is to try to combine the models that perform\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbest. The group (or “ensemble”) will often perform better than the best individual\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmodel—just like random forests perform better than the individual decision trees\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthey rely on—especially if the individual models make very different types of errors.\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFor example, you could train and fine-tune a k-nearest neighbors model, then create\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92man ensemble model that just predicts the mean of the random forest prediction and\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthat model’s prediction. We will cover this topic in more detail in Chapter 7.\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAnalyzing the Best Models and Their Errors\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYou will often gain good insights on the problem by inspecting the best models. For\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mexample, the RandomForestRegressor can indicate the relative importance of each\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mattribute for makin\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mt algorithm is a supervised classification algorithm Based on Decision Trees, also known as random decision \u001b[0m   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mforests, are a popular ensemble method that can be used to build predictive models for both classification \u001b[0m    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand regression problems.\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mEnsemble we mean(In Random Forest Context), Collective Decisions of Different Decision Trees. In RFT(Random \u001b[0m   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mForest Tree), we make a prediction about the class, not simply based on One Decision Trees, but by an \u001b[0m         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(almost) Unanimous Prediction, made by 'K' Decision Trees.\u001b[0m                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mConstruction:\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m'K' Individual Decision Trees are made from given Dataset, by randomly dividing the Dataset and the Feature \u001b[0m   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSubspace by process called as Bootstrap Aggregation(Bagging), which is process of random selection with \u001b[0m       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mreplacement. Generally 2/3rd of the Dataset (row-wise 2/3rd) is selected by bagging, and On that Selected \u001b[0m     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDataset we perform what we call is Attribute Bagging. \u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mNow Attribute Bagging is done to select 'm' features from given M features,(this Process is also c\u001b[0m             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92man help push your system’s performance to its limits.\u001b[0m                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mExercises\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m1. If you have trained five different models on the exact same training data, and\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m1.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthey all achieve 95% precision, is there any chance that you can combine these\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmodels to get better results? If so, how? If not, why?\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m2. What is the difference between hard and soft voting classifiers?\u001b[0m                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m2.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m3. Is it possible to speed up training of a bagging ensemble by distributing it across\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m3.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmultiple servers? What about pasting ensembles, boosting ensembles, random\u001b[0m                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mforests, or stacking ensembles?\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m4. What is the benefit of out-of-bag evaluation?\u001b[0m                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m4.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m5. What makes extra-trees ensembles more random than regular random forests?\u001b[0m                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m5.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mHow can this extra randomness help? Are extra-trees classifiers slower or faster\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthan regular random forests?\u001b[0m                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m6. If your AdaBoost ensemble underfits the training data, which hyperparameters\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m6.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mshould you tweak, and how?\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m7. If your gradient boosting ensemble overfits the training set, should you increase\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m7.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mor decrea\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92monal\u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeatures, including GPU acceleration; you should definitely check\u001b[0m                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthem out! Moreover, the TensorFlow Random Forests library pro‐\u001b[0m                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mvides optimized implementations of a variety of random forest\u001b[0m                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92malgorithms, including plain random forests, extra-trees, GBRT, and\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mseveral more.\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBoosting \u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m231 18 David H. Wolpert, “Stacked Generalization”, Neural Networks 5, no. 2 (1992): 241–259.\u001b[0m                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStacking\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mThe last ensemble method we will discuss in this chapter is called stacking (short for\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mstacked generalization).18 It is based on a simple idea: instead of using trivial functions\u001b[0m                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(such as hard voting) to aggregate the predictions of all predictors in an ensemble,\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mwhy don’t we train a model to perform this aggregation? Figure 7-11 shows such an\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mensemble performing a regression task on a new instance. Each of the bottom three\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpredictors predicts a different value (3.1, 2.7, and 2.9), and then the final predictor\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(called a blender, or a meta learner) takes these predictions as inputs and makes the\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfinal \u001b[0m                                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92malled Random Subspace Creation.) Generally value of 'm' is square-root of M. Now we select say, 10 such \u001b[0m       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mvalues of m, and then Build 10 Decision Trees based on them, and test the 1/3rd remaining Dataset on these(10\u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDecision Trees).We would then Select the Best Decision Tree out of this. And Repeat the whole Process 'K' \u001b[0m     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtimes again to build such 'K' decision trees.\u001b[0m                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mClassification:\u001b[0m                                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mPrediction in Random Forest (a collection of 'K' Decision Trees) is truly ensemble ie, For Each Decision \u001b[0m      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mTree, Predict the class of Instance and then return the class which was predicted the most often.\u001b[0m              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mUsing Random Forest Classifier\u001b[0m                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m from sklearn.ensemble import RandomForestClassifier //Importing library\u001b[0m                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m TRAIN_DIR = \"../train-mails\"\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m TEST_DIR = \"../test-mails\"\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m dictionary = make_Dictionary(TRAIN_DIR)\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m print \"reading and processing emails from file.\"\u001b[0m                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m features_matrix, labels = extract_features(TRAIN_DIR)\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m test_feature_matrix, test_labels = extract_features(TEST_DIR)\u001b[0m                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m model = RandomForestClassifier\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mprediction (3.0).\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-11. Aggregating predictions using a blending predictor\u001b[0m                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mTo train the blender, you first need to build the blending training set. You can\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92muse cross_val_predict() on every predictor in the ensemble to get out-of-sample\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpredictions for each instance in the original training set (Figure 7-12), and use these\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m232 \u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 7: Ensemble Learning and Random Forests can be used as the input features to train the blender; and \u001b[0m   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe targets can simply be\u001b[0m                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcopied from the original training set. Note that regardless of the number of features\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92min the original training set (just one in this example), the blending training set will\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcontain one input feature per predictor (three in this example). Once the blender is\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtrained, the base predictors are retrained one last time on the full original training set.\u001b[0m                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-12. Training the blender in a stacking ensemble\u001b[0m                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mIt is actually possible to train several different blenders this way (e.g., one using linear\u001b[0m                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mregression, another using \u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mly, the net result is that\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe ensemble has a similar bias but a lower variance than a single predictor trained on\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe original training set.\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAs you can see in Figure 7-4, predictors can all be trained in parallel, via different\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mCPU cores or even different servers. Similarly, predictions can be made in parallel.\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mThis is one of the reasons bagging and pasting are such popular methods: they scale\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mvery well.\u001b[0m                                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m216 \u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 7: Ensemble Learning and Random Forests 6 max_samples can alternatively be set to a float between 0.0\u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand 1.0, in which case the max number of sampled\u001b[0m                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minstances is equal to the size of the training set times max_samples.\u001b[0m                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBagging and Pasting in Scikit-Learn\u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mScikit-Learn offers a simple API for both bagging and pasting: BaggingClassifier\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclass (or BaggingRegressor for regression). The following code trains an ensemble\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mof 500 decision tree classifiers:6 each is trained on 100 training instances randomly\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msampled from the training set with replacement (this is an example of\u001b[0m                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mntaining three trees. It can make predictions on a new\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minstance simply by adding up the predictions of all the trees:\u001b[0m                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m>>> X_new = np.array([[-0.4], [0.], [0.5]])\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m>>> sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\u001b[0m                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92marray([0.49484029, 0.04021166, 0.75026781])\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-9 represents the predictions of these three trees in the left column, and the\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mensemble’s predictions in the right column. In the first row, the ensemble has just one\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtree, so its predictions are exactly the same as the first tree’s predictions. In the second\u001b[0m                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mrow, a new tree is trained on the residual errors of the first tree. On the right you can\u001b[0m                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msee that the ensemble’s predictions are equal to the sum of the predictions of the first\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtwo trees. Similarly, in the third row another tree is trained on the residual errors of\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe second tree. You can see that the ensemble’s predictions gradually get better as\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtrees are added to the ensemble.\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYou can use Scikit-Learn’s GradientBoostingRegressor class to tra\u001b[0m                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mstacking_clf.fit(X_train, y_train)\u001b[0m                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFor each predictor, the stacking classifier will call predict_proba() if available; if not\u001b[0m                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mit will fall back to decision_function() or, as a last resort, call predict(). If you\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdon’t provide a final estimator, StackingClassifier will use LogisticRegression\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand StackingRegressor will use RidgeCV.\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m234 \u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 7: Ensemble Learning and Random Forests If you evaluate this stacking model on the test set, you will\u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfind 92.8% accuracy,\u001b[0m                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mwhich is a bit better than the voting classifier using soft voting, which got 92%.\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mIn conclusion, ensemble methods are versatile, powerful, and fairly simple to use.\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRandom forests, AdaBoost, and GBRT are among the first models you should test for\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmost machine learning tasks, and they particularly shine with heterogeneous tabular\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdata. Moreover, as they require very little preprocessing, they’re great for getting a\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mprototype up and running quickly. Lastly, ensemble methods like voting classifiers\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand stacking classifiers c\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mrandom forest regression) to get a whole layer of blenders,\u001b[0m                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand then add another blender on top of that to produce the final prediction, as shown\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92min Figure 7-13. You may be able to squeeze out a few more drops of performance by\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdoing this, but it will cost you in both training time and system complexity.\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStacking \u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m233 Figure 7-13. Predictions in a multilayer stacking ensemble\u001b[0m                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mScikit-Learn provides two classes for stacking ensembles: StackingClassifier and\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStackingRegressor. For example, we can replace the VotingClassifier we used at\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe beginning of this chapter on the moons dataset with a StackingClassifier:\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import StackingClassifier\u001b[0m                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mstacking_clf = StackingClassifier(\u001b[0m                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m    estimators=[\u001b[0m                                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m        ('lr', LogisticRegression(random_state=42)),\u001b[0m                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m        ('rf', RandomForestClassifier(random_state=42)),\u001b[0m                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m        ('svc', SVC(probability=True, random_state=42))\u001b[0m                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m    ],\u001b[0m                                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m    final_estimator=RandomForestClassifier(random_state=43),\u001b[0m                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m    cv=5  # number of cross-validation folds\u001b[0m                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m)\u001b[0m                                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mven\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpredictor, while others may not be sampled at all. By default a BaggingClassifier\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msamples m training instances with replacement (bootstrap=True), where m is the\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msize of the training set. With this process, it can be shown mathematically that only\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mabout 63% of the training instances are sampled on average for each predictor.7 The\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mremaining 37% of the training instances that are not sampled are called out-of-bag\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(OOB) instances. Note that they are not the same 37% for all predictors.\u001b[0m                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mA bagging ensemble can be evaluated using OOB instances, without the need for\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ma separate validation set: indeed, if there are enough estimators, then each instance\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92min the training set will likely be an OOB instance of several estimators, so these\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mestimators can be used to make a fair ensemble prediction for that instance. Once\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92myou have a prediction for each instance, you can compute the ensemble’s prediction\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92maccuracy (or any other metric).\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mIn Scikit-Learn, you can set oob_score=True when creating a Baggi\u001b[0m                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m bagging, but\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mif you want to use pasting instead, just set bootstrap=False). The n_jobs parameter\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtells Scikit-Learn the number of CPU cores to use for training and predictions, and\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m–1 tells Scikit-Learn to use all available cores:\u001b[0m                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import BaggingClassifier\u001b[0m                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfrom sklearn.tree import DecisionTreeClassifier\u001b[0m                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\u001b[0m                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m                            max_samples=100, n_jobs=-1, random_state=42)\u001b[0m                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbag_clf.fit(X_train, y_train)\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mA BaggingClassifier automatically performs soft voting instead\u001b[0m                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mof hard voting if the base classifier can estimate class probabilities\u001b[0m                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(i.e., if it has a predict_proba() method), which is the case with\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdecision tree classifiers.\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-5 compares the decision boundary of a single decision tree with the decision\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mboundary of a bagging ensemble of 500 trees (from the preceding code), both trained\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mon the moons dataset. As you can see, the ensemble’s predictions will likely generalize\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmuch better \u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mad\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mof instance sampling. Thus, each predictor will be trained on a random subset of the\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minput features.\u001b[0m                                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mThis technique is particularly useful when you are dealing with high-dimensional\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minputs (such as images), as it can considerably speed up training. Sampling both\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtraining instances and features is called the random patches method.8 Keeping all\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtraining instances (by setting bootstrap=False and max_samples=1.0) but sampling\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeatures (by setting bootstrap_features to True and/or max_features to a value\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msmaller than 1.0) is called the random subspaces method.9\u001b[0m                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSampling features results in even more predictor diversity, trading a bit more bias for\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ma lower variance.\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBagging and Pasting \u001b[0m                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m219 10 Tin Kam Ho, “Random Decision Forests”, Proceedings of the Third International Conference on Document\u001b[0m    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAnalysis and Recognition 1 (1995): 278.\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m11 The BaggingClassifier class remains useful if you want a bag of something other than decision trees.\u001b[0m        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRandom Forests\u001b[0m                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAs we have discussed, a random forest\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mearn, xvi\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbagging and pasting in, 217\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mCART algorithm, 199, 205\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcross-validation, 89-91\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdesign principles, 70-71\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mPCA implementation, 246\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mPipeline constructor, 84-87\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.base.BaseEstimator, 80\u001b[0m                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.base.clone(), 163\u001b[0m                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.base.TransformerMixin, 80\u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.cluster.DBSCAN, 279\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.cluster.KMeans, 81, 263\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.cluster.MiniBatchKMeans, 268\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.compose.ColumnTransformer, 85\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.compose.TransformedTargetRegres‐\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msor, 79\u001b[0m                                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.datasets.load_iris(), 167\u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.datasets.make_moons(), 179\u001b[0m                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.decomposition.IncrementalPCA,\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m251\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.decomposition.PCA, 246\u001b[0m                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.AdaBoostClassifier, 226\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.BaggingClassifier, 217\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.GradientBoostingRegres‐\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msor, 227-230\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.HistGradientBoosting‐\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mClassifier, 230\u001b[0m                                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.HistGradientBoostingRe‐\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mgressor, 230\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.RandomForestClassifier,\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m117-119, 214, 220, 221, 248\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.RandomForestRegressor,\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m90, 220\u001b[0m                                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.StackingClassifier, 234\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mes and repeat the same process on every branch.\u001b[0m                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStep 4a: A branch with entropy of 0 is a leaf node\u001b[0m                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStep 4b: A branch with entropy more than 0 needs further splitting\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStep 5: The ID3 algorithm is run recursively on the non-leaf branches, until all data is classified.\u001b[0m           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDecision Tree to Decision Rules\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mA decision tree can easily be transformed to a set of rules by mapping from the root node to the leaf nodes \u001b[0m   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mone by one.\u001b[0m                                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mLimitations to Decision Trees\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDecision trees tend to have high variance when they utilize different training and test sets of the same \u001b[0m      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdata, since they tend to overfit on training data. This leads to poor performance on unseen data. \u001b[0m             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mUnfortunately, this limits the usage of decision trees in predictive modeling. \u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mTo overcome these problems we use ensemble methods, we can create models that utilize underlying(weak) \u001b[0m        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdecision trees as a foundation for producing powerful results and this is done in Random Forest Algorithm\u001b[0m      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRandom forest\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDefinition:\u001b[0m                                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRandom fores\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtance, you get the image represented in\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-6.\u001b[0m                                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-6. MNIST pixel importance (according to a random forest classifier)\u001b[0m                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRandom forests are very handy to get a quick understanding of what features actually\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmatter, in particular if you need to perform feature selection.\u001b[0m                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBoosting\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBoosting (originally called hypothesis boosting) refers to any ensemble method that\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcan combine several weak learners into a strong learner. The general idea of most\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mboosting methods is to train predictors sequentially, each trying to correct its prede‐\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcessor. There are many boosting methods available, but by far the most popular\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mare AdaBoost13 (short for adaptive boosting) and gradient boosting. Let’s start with\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAdaBoost.\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAdaBoost\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mOne way for a new predictor to correct its predecessor is to pay a bit more attention\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mto the training instances that the predecessor underfit. This results in new predictors\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfocusing more and more on the hard cases. This is the technique used by AdaBoost.\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m222 \u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mChapter 7: E\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mlearners in the ensemble and they are sufficiently diverse.\u001b[0m                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mHow is this possible? The following analogy can help shed some light on this mystery.\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSuppose you have a slightly biased coin that has a 51% chance of coming up heads\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand 49% chance of coming up tails. If you toss it 1,000 times, you will generally get\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmore or less 510 heads and 490 tails, and hence a majority of heads. If you do the\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mmath, you will find that the probability of obtaining a majority of heads after 1,000\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtosses is close to 75%. The more you toss the coin, the higher the probability (e.g.,\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mwith 10,000 tosses, the probability climbs over 97%). This is due to the law of large\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mnumbers: as you keep tossing the coin, the ratio of heads gets closer and closer to\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe probability of heads (51%). Figure 7-3 shows 10 series of biased coin tosses. You\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcan see that as the number of tosses increases, the ratio of heads approaches 51%.\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mEventually all 10 series end up so close to 51% that they are consistently above 50%.\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure \u001b[0m                                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m learning, 692\u001b[0m                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mexponential linear unit (ELU), 363-366\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mexponential scheduling, 389, 392\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mexport_graphviz(), 196\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mextra-trees, random forest, 220\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mextremely randomized trees ensemble (extra-\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtrees), 221\u001b[0m                                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mF\u001b[0m                                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mface-recognition classifier, 125\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfalse negatives, confusion matrix, 109\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfalse positive rate (FPR) or fall-out, 115\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfalse positives, confusion matrix, 109\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfan-in/fan-out, 359\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfast-MCD, 293\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFCNs (fully convolutional networks), 525-526,\u001b[0m                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m532\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeature engineering, 30, 262\u001b[0m                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeature extraction, 12, 30\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeature maps, 485-487, 488, 508, 511\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeature scaling, 75-79, 141, 176\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeature selection, 30, 95, 159, 221\u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeature vectors, 45, 133, 186\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeatures, 11\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfederated learning, 746\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfeedforward neural network (FNN), 309, 538\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfetch_openml(), 104\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfillna(), 68\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfilters, convolutional layers, 484, 487, 497, 509\u001b[0m                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfirst moment (mean of gradient), 384\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfirst-order partial derivatives (Jacobians), 386\u001b[0m                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfit()\u001b[0m                                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mand custom transformers, 80, 84\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mdata cleaning, 69\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mversus partial_fit(), 148\u001b[0m                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92musing only with training set, 75\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfitnes\u001b[0m                                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthan the single decision tree’s predictions: the ensemble has a compara‐\u001b[0m                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mble bias but a smaller variance (it makes roughly the same number of errors on the\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtraining set, but the decision boundary is less irregular).\u001b[0m                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBagging introduces a bit more diversity in the subsets that each predictor is trained\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mon, so bagging ends up with a slightly higher bias than pasting; but the extra diversity\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92malso means that the predictors end up being less correlated, so the ensemble’s variance\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mis reduced. Overall, bagging often results in better models, which explains why\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mit’s generally preferred. But if you have spare time and CPU power, you can use\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcross-validation to evaluate both bagging and pasting and select the one that works\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbest.\u001b[0m                                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBagging and Pasting \u001b[0m                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m217 7 As m grows, this ratio approaches 1 – exp(–1) ≈ 63%.\u001b[0m                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFigure 7-5. A single decision tree (left) versus a bagging ensemble of 500 trees (right)\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mOut-of-Bag Evaluation\u001b[0m                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mWith bagging, some training instances may be sampled several times for any gi\u001b[0m                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mameter to \"soft\", and ensure that all classifiers can estimate\u001b[0m                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclass probabilities. This is not the case for the SVC class by default, so you need\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mto set its probability hyperparameter to True (this will make the SVC class use\u001b[0m                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcross-validation to estimate class probabilities, slowing down training, and it will add\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92ma predict_proba() method). Let’s try that:\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m>>> voting_clf.voting = \"soft\"\u001b[0m                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m>>> voting_clf.named_estimators[\"svc\"].probability = True\u001b[0m                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m>>> voting_clf.fit(X_train, y_train)\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m>>> voting_clf.score(X_test, y_test)\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m0.92\u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mWe reach 92% accuracy simply by using soft voting—not bad!\u001b[0m                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBagging and Pasting\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mOne way to get a diverse set of classifiers is to use very different training algorithms,\u001b[0m                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mas just discussed. Another approach is to use the same training algorithm for every\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpredictor but train them on different random subsets of the training set. When\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msampling is performed with replacement,1 this method is called bagging2 (short for\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbootstrap aggregating3). When sampling is performed withou\u001b[0m                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92min GBRT ensem‐\u001b[0m                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mbles more easily (there’s also a GradientBoostingClassifier class for classifica‐\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mtion). Much like the RandomForestRegressor class, it has hyperparameters to\u001b[0m                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcontrol the growth of decision trees (e.g., max_depth, min_samples_leaf), as well\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mas hyperparameters to control the ensemble training, such as the number of trees\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m(n_estimators). The following code creates the same ensemble as the previous one:\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import GradientBoostingRegressor\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mgbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3,\u001b[0m                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m                                 learning_rate=1.0, random_state=42)\u001b[0m                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mgbrt.fit(X, y)\u001b[0m                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mBoosting \u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m| \u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m227 Figure 7-9. In this depiction of gradient boosting, the first predictor (top left) is trained\u001b[0m              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mnormally, then each consecutive predictor (middle left and lower left) is trained on the\u001b[0m                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mprevious predictor’s residuals; the right column shows the resulting ensemble’s predictions\u001b[0m                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mThe learning_rate hyperparameter scales the contribution of each tree. If you set\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mit to a\u001b[0m                                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mse the learning rate?\u001b[0m                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m8. Load the MNIST dataset (introduced in Chapter 3), and split it into a training\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m8.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mset, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000\u001b[0m                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mfor validation, and 10,000 for testing). Then train various classifiers, such as a\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mrandom forest classifier, an extra-trees classifier, and an SVM classifier. Next, try\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mto combine them into an ensemble that outperforms each individual classifier\u001b[0m                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mon the validation set, using soft or hard voting. Once you have found one, try\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mit on the test set. How much better does it perform compared to the individual\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclassifiers?\u001b[0m                                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m9. Run the individual classifiers from the previous exercise to make predictions on\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m9.\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mthe validation set, and create a new training set with the resulting predictions:\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92meach training instance is a vector containing the set of predictions from all your\u001b[0m                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclassifiers for an image, and the target is the image’s class. Train a classifier\u001b[0m                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mon this new training set. Congratulations—you have just\u001b[0m                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m                             199\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mComputational Complexity                                                                                     \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m200\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mGini Impurity or Entropy?                                                                                    \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m201\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRegularization Hyperparameters                                                                              \u001b[0m   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m201\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRegression                                                                                                   \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m204\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mSensitivity to Axis Orientation                                                                              \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m206\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mDecision Trees Have a High Variance                                                                       207\u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mExercises                                                                                                    \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m208\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m7. Ensemble Learning and Random Forests. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m. .  211\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mVoting Clas\u001b[0m                                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mStackingRegressor, 234\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.ensemble.VotingClassifier, 214\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.externals.joblib, 97-98\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.feature_selection.SelectFromModel,\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m95\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.impute.IterativeImputer, 69\u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.impute.KNNImputer, 69\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.impute.SimpleImputer, 68\u001b[0m                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.ElasticNet, 162\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.Lasso, 161\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.LinearRegression, 25,\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m71, 79, 137, 138, 150\u001b[0m                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.LogisticRegression,\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m168, 172, 275\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.Perceptron, 307\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.Ridge, 157\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.RidgeCV, 158\u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.SGDClassifier, 106,\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m111, 112, 117-119, 121, 183, 188, 307\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.linear_model.SGDRegressor, 147,\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m163\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.manifold.LocallyLinearEmbedding,\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m254\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.ConfusionMatrixDisplay,\u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m122\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.confusion_matrix(), 109,\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m122\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.f1_score(), 111, 126\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.mean_squared_error(), 88\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.precision_recall_curve(),\u001b[0m                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m113, 117\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.precision_score(), 110\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.metrics.recall_score(), 110\u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92msklearn.\u001b[0m                                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Document Search Assistant</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">You are given content from the course 'classical machine learning'.</span>                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Course Description: An introduction to core machine learning algorithms like regression, classification, and </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clustering, focusing on their concepts and practical applications.</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Your task is to focus specifically on the topic: 'ensemble learning' and extract or summarize relevant </span>        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">information.</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Context:</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">e method, you can train a group of decision tree</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifiers, each on a different random subset of the training set. You can then obtain</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the predictions of all the individual trees, and the class that gets the most votes is</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble’s prediction (see the last exercise in Chapter 6). Such an ensemble of</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision trees is called a random forest, and despite its simplicity, this is one of the</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">most powerful machine learning algorithms available today.</span>                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As discussed in Chapter 2, you will often use ensemble methods near the end of</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a project, once you have already built a few good predictors, to combine them</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">into an even better predictor. In fact, the winning solutions in machine learning</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">competitions often involve several ensemble methods—most famously in the Netflix</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Prize competition.</span>                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In this chapter we will examine the most popular ensemble methods, including</span>                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">voting classifiers, bagging and pasting ensembles, random forests, and boosting, and</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacking ensembles.</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">211 Voting Classifiers</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> trained a blender, and</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Exercises </span>                                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">235 together with the classifiers it forms a stacking ensemble! Now evaluate the</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble on the test set. For each image in the test set, make predictions with all</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">your classifiers, then feed the predictions to the blender to get the ensemble’s pre‐</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dictions. How does it compare to the voting classifier you trained earlier? Now</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">try again using a StackingClassifier instead. Do you get better performance? If</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">so, why?</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Solutions to these exercises are available at the end of this chapter’s notebook, at</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">https://homl.info/colab3.</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">236 </span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 7: Ensemble Learning and Random Forests CHAPTER 8</span>                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Dimensionality Reduction</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Many machine learning problems involve thousands or even millions of features for</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each training instance. Not only do all these features make training extremely slow,</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">but they can also make it much harder to find a good solution, as you will see. This</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">problem is often referred to as the curse of dimensionality.</span>                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Fortunately, in real-world </span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">7-3. The law of large numbers</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Similarly, suppose you build an ensemble containing 1,000 classifiers that are indi‐</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">vidually correct only 51% of the time (barely better than random guessing). If you</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict the majority voted class, you can hope for up to 75% accuracy! However, this</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is only true if all classifiers are perfectly independent, making uncorrelated errors,</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which is clearly not the case because they are trained on the same data. They are likely</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to make the same types of errors, so there will be many majority votes for the wrong</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">class, reducing the ensemble’s accuracy.</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Voting Classifiers </span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">213 Ensemble methods work best when the predictors are as independ‐</span>                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ent from one another as possible. One way to get diverse classifiers</span>                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is to train them using very different algorithms. This increases the</span>                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">chance that they will make very different types of errors, improving</span>                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble’s accuracy.</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn provides a VotingClassifier class that’s quite easy to use: just give</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it a list</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Suppose you have trained a few classifiers, each one achieving about 80% accuracy.</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You may have a logistic regression classifier, an SVM classifier, a random forest</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifier, a k-nearest neighbors classifier, and perhaps a few more (see Figure 7-1).</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-1. Training diverse classifiers</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A very simple way to create an even better classifier is to aggregate the predictions</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of each classifier: the class that gets the most votes is the ensemble’s prediction. This</span>                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">majority-vote classifier is called a hard voting classifier (see Figure 7-2).</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-2. Hard voting classifier predictions</span>                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">212 </span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 7: Ensemble Learning and Random Forests Somewhat surprisingly, this voting classifier often achieves </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a higher accuracy than</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the best classifier in the ensemble. In fact, even if each classifier is a weak learner</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(meaning it does only slightly better than random guessing), the ensemble can still be</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a strong learner (achieving high accuracy), provided there are a sufficient number of</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weak </span>                                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">t replacement, it is called</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pasting.4</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting </span>                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">215 5 Bias and variance were introduced in Chapter 4.</span>                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In other words, both bagging and pasting allow training instances to be sampled</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">several times across multiple predictors, but only bagging allows training instances to</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">be sampled several times for the same predictor. This sampling and training process</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is represented in Figure 7-4.</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-4. Bagging and pasting involve training several predictors on different random</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">samples of the training set</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Once all predictors are trained, the ensemble can make a prediction for a new</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance by simply aggregating the predictions of all predictors. The aggregation</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">function is typically the statistical mode for classification (i.e., the most frequent</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prediction, just like with a hard voting classifier), or the average for regression. Each</span>                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">individual predictor has a higher bias than if it were trained on the original training</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set, but aggregation reduces both bias and variance.5 General</span>                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">r the test set.</span>                                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">d. Evaluate these predictions on the test set: you should obtain a slightly higher</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">d.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">accuracy than your first model (about 0.5 to 1.5% higher). Congratulations,</span>                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you have trained a random forest classifier!</span>                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Solutions to these exercises are available at the end of this chapter’s notebook, at</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">https://homl.info/colab3.</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Exercises </span>                                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">209  CHAPTER 7</span>                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Ensemble Learning and Random Forests</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Suppose you pose a complex question to thousands of random people, then aggregate</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">their answers. In many cases you will find that this aggregated answer is better than</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an expert’s answer. This is called the wisdom of the crowd. Similarly, if you aggregate</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the predictions of a group of predictors (such as classifiers or regressors), you will</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">often get better predictions than with the best individual predictor. A group of</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors is called an ensemble; thus, this technique is called ensemble learning, and</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an ensemble learning algorithm is called an ensemble method.</span>                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As an example of an ensembl</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> several rounds, the final</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">candidates are evaluated using full resources. This may save you some time tuning</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hyperparameters.</span>                                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">94 </span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 2: End-to-End Machine Learning Project Ensemble Methods</span>                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Another way to fine-tune your system is to try to combine the models that perform</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">best. The group (or “ensemble”) will often perform better than the best individual</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model—just like random forests perform better than the individual decision trees</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">they rely on—especially if the individual models make very different types of errors.</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">For example, you could train and fine-tune a k-nearest neighbors model, then create</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an ensemble model that just predicts the mean of the random forest prediction and</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">that model’s prediction. We will cover this topic in more detail in Chapter 7.</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Analyzing the Best Models and Their Errors</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You will often gain good insights on the problem by inspecting the best models. For</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">example, the RandomForestRegressor can indicate the relative importance of each</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">attribute for makin</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">t algorithm is a supervised classification algorithm Based on Decision Trees, also known as random decision </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forests, are a popular ensemble method that can be used to build predictive models for both classification </span>    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and regression problems.</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Ensemble we mean(In Random Forest Context), Collective Decisions of Different Decision Trees. In RFT(Random </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Forest Tree), we make a prediction about the class, not simply based on One Decision Trees, but by an </span>         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(almost) Unanimous Prediction, made by 'K' Decision Trees.</span>                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Construction:</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">'K' Individual Decision Trees are made from given Dataset, by randomly dividing the Dataset and the Feature </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Subspace by process called as Bootstrap Aggregation(Bagging), which is process of random selection with </span>       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">replacement. Generally 2/3rd of the Dataset (row-wise 2/3rd) is selected by bagging, and On that Selected </span>     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Dataset we perform what we call is Attribute Bagging. </span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now Attribute Bagging is done to select 'm' features from given M features,(this Process is also c</span>             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an help push your system’s performance to its limits.</span>                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Exercises</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. If you have trained five different models on the exact same training data, and</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">they all achieve 95% precision, is there any chance that you can combine these</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">models to get better results? If so, how? If not, why?</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. What is the difference between hard and soft voting classifiers?</span>                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3. Is it possible to speed up training of a bagging ensemble by distributing it across</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multiple servers? What about pasting ensembles, boosting ensembles, random</span>                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forests, or stacking ensembles?</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">4. What is the benefit of out-of-bag evaluation?</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">4.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">5. What makes extra-trees ensembles more random than regular random forests?</span>                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">5.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">How can this extra randomness help? Are extra-trees classifiers slower or faster</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">than regular random forests?</span>                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">6. If your AdaBoost ensemble underfits the training data, which hyperparameters</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">6.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">should you tweak, and how?</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">7. If your gradient boosting ensemble overfits the training set, should you increase</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">7.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">or decrea</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">onal</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">features, including GPU acceleration; you should definitely check</span>                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">them out! Moreover, the TensorFlow Random Forests library pro‐</span>                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">vides optimized implementations of a variety of random forest</span>                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">algorithms, including plain random forests, extra-trees, GBRT, and</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">several more.</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Boosting </span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">231 18 David H. Wolpert, “Stacked Generalization”, Neural Networks 5, no. 2 (1992): 241–259.</span>                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Stacking</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The last ensemble method we will discuss in this chapter is called stacking (short for</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacked generalization).18 It is based on a simple idea: instead of using trivial functions</span>                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(such as hard voting) to aggregate the predictions of all predictors in an ensemble,</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">why don’t we train a model to perform this aggregation? Figure 7-11 shows such an</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble performing a regression task on a new instance. Each of the bottom three</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors predicts a different value (3.1, 2.7, and 2.9), and then the final predictor</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(called a blender, or a meta learner) takes these predictions as inputs and makes the</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">final </span>                                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">alled Random Subspace Creation.) Generally value of 'm' is square-root of M. Now we select say, 10 such </span>       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">values of m, and then Build 10 Decision Trees based on them, and test the 1/3rd remaining Dataset on these(10</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Decision Trees).We would then Select the Best Decision Tree out of this. And Repeat the whole Process 'K' </span>     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">times again to build such 'K' decision trees.</span>                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Classification:</span>                                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Prediction in Random Forest (a collection of 'K' Decision Trees) is truly ensemble ie, For Each Decision </span>      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Tree, Predict the class of Instance and then return the class which was predicted the most often.</span>              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Using Random Forest Classifier</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> from sklearn.ensemble import RandomForestClassifier //Importing library</span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> TRAIN_DIR = \"../train-mails\"</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> TEST_DIR = \"../test-mails\"</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> dictionary = make_Dictionary(TRAIN_DIR)</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> print \"reading and processing emails from file.\"</span>                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> features_matrix, labels = extract_features(TRAIN_DIR)</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> test_feature_matrix, test_labels = extract_features(TEST_DIR)</span>                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> model = RandomForestClassifier</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prediction (3.0).</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-11. Aggregating predictions using a blending predictor</span>                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To train the blender, you first need to build the blending training set. You can</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">use cross_val_predict() on every predictor in the ensemble to get out-of-sample</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictions for each instance in the original training set (Figure 7-12), and use these</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">232 </span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 7: Ensemble Learning and Random Forests can be used as the input features to train the blender; and </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the targets can simply be</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">copied from the original training set. Note that regardless of the number of features</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in the original training set (just one in this example), the blending training set will</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">contain one input feature per predictor (three in this example). Once the blender is</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained, the base predictors are retrained one last time on the full original training set.</span>                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-12. Training the blender in a stacking ensemble</span>                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">It is actually possible to train several different blenders this way (e.g., one using linear</span>                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regression, another using </span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ly, the net result is that</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble has a similar bias but a lower variance than a single predictor trained on</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the original training set.</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As you can see in Figure 7-4, predictors can all be trained in parallel, via different</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">CPU cores or even different servers. Similarly, predictions can be made in parallel.</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">This is one of the reasons bagging and pasting are such popular methods: they scale</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">very well.</span>                                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">216 </span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 7: Ensemble Learning and Random Forests 6 max_samples can alternatively be set to a float between 0.0</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and 1.0, in which case the max number of sampled</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances is equal to the size of the training set times max_samples.</span>                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting in Scikit-Learn</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn offers a simple API for both bagging and pasting: BaggingClassifier</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">class (or BaggingRegressor for regression). The following code trains an ensemble</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of 500 decision tree classifiers:6 each is trained on 100 training instances randomly</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sampled from the training set with replacement (this is an example of</span>                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ntaining three trees. It can make predictions on a new</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance simply by adding up the predictions of all the trees:</span>                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; X_new = np.array([[-0.4], [0.], [0.5]])</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))</span>                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">array([0.49484029, 0.04021166, 0.75026781])</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-9 represents the predictions of these three trees in the left column, and the</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble’s predictions in the right column. In the first row, the ensemble has just one</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree, so its predictions are exactly the same as the first tree’s predictions. In the second</span>                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">row, a new tree is trained on the residual errors of the first tree. On the right you can</span>                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">see that the ensemble’s predictions are equal to the sum of the predictions of the first</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">two trees. Similarly, in the third row another tree is trained on the residual errors of</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the second tree. You can see that the ensemble’s predictions gradually get better as</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trees are added to the ensemble.</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You can use Scikit-Learn’s GradientBoostingRegressor class to tra</span>                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacking_clf.fit(X_train, y_train)</span>                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">For each predictor, the stacking classifier will call predict_proba() if available; if not</span>                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it will fall back to decision_function() or, as a last resort, call predict(). If you</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">don’t provide a final estimator, StackingClassifier will use LogisticRegression</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and StackingRegressor will use RidgeCV.</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">234 </span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 7: Ensemble Learning and Random Forests If you evaluate this stacking model on the test set, you will</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">find 92.8% accuracy,</span>                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which is a bit better than the voting classifier using soft voting, which got 92%.</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In conclusion, ensemble methods are versatile, powerful, and fairly simple to use.</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random forests, AdaBoost, and GBRT are among the first models you should test for</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">most machine learning tasks, and they particularly shine with heterogeneous tabular</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">data. Moreover, as they require very little preprocessing, they’re great for getting a</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prototype up and running quickly. Lastly, ensemble methods like voting classifiers</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and stacking classifiers c</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">random forest regression) to get a whole layer of blenders,</span>                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and then add another blender on top of that to produce the final prediction, as shown</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in Figure 7-13. You may be able to squeeze out a few more drops of performance by</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">doing this, but it will cost you in both training time and system complexity.</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Stacking </span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">233 Figure 7-13. Predictions in a multilayer stacking ensemble</span>                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn provides two classes for stacking ensembles: StackingClassifier and</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">StackingRegressor. For example, we can replace the VotingClassifier we used at</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the beginning of this chapter on the moons dataset with a StackingClassifier:</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import StackingClassifier</span>                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacking_clf = StackingClassifier(</span>                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    estimators=[</span>                                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ('lr', LogisticRegression(random_state=42)),</span>                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ('rf', RandomForestClassifier(random_state=42)),</span>                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ('svc', SVC(probability=True, random_state=42))</span>                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    ],</span>                                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    final_estimator=RandomForestClassifier(random_state=43),</span>                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    cv=5  # number of cross-validation folds</span>                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">)</span>                                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ven</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor, while others may not be sampled at all. By default a BaggingClassifier</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">samples m training instances with replacement (bootstrap=True), where m is the</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">size of the training set. With this process, it can be shown mathematically that only</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">about 63% of the training instances are sampled on average for each predictor.7 The</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">remaining 37% of the training instances that are not sampled are called out-of-bag</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(OOB) instances. Note that they are not the same 37% for all predictors.</span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A bagging ensemble can be evaluated using OOB instances, without the need for</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a separate validation set: indeed, if there are enough estimators, then each instance</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in the training set will likely be an OOB instance of several estimators, so these</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">estimators can be used to make a fair ensemble prediction for that instance. Once</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you have a prediction for each instance, you can compute the ensemble’s prediction</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">accuracy (or any other metric).</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In Scikit-Learn, you can set oob_score=True when creating a Baggi</span>                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> bagging, but</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">if you want to use pasting instead, just set bootstrap=False). The n_jobs parameter</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tells Scikit-Learn the number of CPU cores to use for training and predictions, and</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">–1 tells Scikit-Learn to use all available cores:</span>                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import BaggingClassifier</span>                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.tree import DecisionTreeClassifier</span>                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,</span>                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">                            max_samples=100, n_jobs=-1, random_state=42)</span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bag_clf.fit(X_train, y_train)</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A BaggingClassifier automatically performs soft voting instead</span>                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of hard voting if the base classifier can estimate class probabilities</span>                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(i.e., if it has a predict_proba() method), which is the case with</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision tree classifiers.</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-5 compares the decision boundary of a single decision tree with the decision</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">boundary of a bagging ensemble of 500 trees (from the preceding code), both trained</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on the moons dataset. As you can see, the ensemble’s predictions will likely generalize</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">much better </span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ad</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of instance sampling. Thus, each predictor will be trained on a random subset of the</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">input features.</span>                                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">This technique is particularly useful when you are dealing with high-dimensional</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inputs (such as images), as it can considerably speed up training. Sampling both</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances and features is called the random patches method.8 Keeping all</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances (by setting bootstrap=False and max_samples=1.0) but sampling</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">features (by setting bootstrap_features to True and/or max_features to a value</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">smaller than 1.0) is called the random subspaces method.9</span>                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Sampling features results in even more predictor diversity, trading a bit more bias for</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a lower variance.</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting </span>                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">219 10 Tin Kam Ho, “Random Decision Forests”, Proceedings of the Third International Conference on Document</span>    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Analysis and Recognition 1 (1995): 278.</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">11 The BaggingClassifier class remains useful if you want a bag of something other than decision trees.</span>        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random Forests</span>                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As we have discussed, a random forest</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">earn, xvi</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bagging and pasting in, 217</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">CART algorithm, 199, 205</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross-validation, 89-91</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">design principles, 70-71</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">PCA implementation, 246</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Pipeline constructor, 84-87</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.base.BaseEstimator, 80</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.base.clone(), 163</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.base.TransformerMixin, 80</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.cluster.DBSCAN, 279</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.cluster.KMeans, 81, 263</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.cluster.MiniBatchKMeans, 268</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.compose.ColumnTransformer, 85</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.compose.TransformedTargetRegres‐</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sor, 79</span>                                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.datasets.load_iris(), 167</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.datasets.make_moons(), 179</span>                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.decomposition.IncrementalPCA,</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">251</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.decomposition.PCA, 246</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.AdaBoostClassifier, 226</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.BaggingClassifier, 217</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.GradientBoostingRegres‐</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sor, 227-230</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.HistGradientBoosting‐</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Classifier, 230</span>                                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.HistGradientBoostingRe‐</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gressor, 230</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.RandomForestClassifier,</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">117-119, 214, 220, 221, 248</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.RandomForestRegressor,</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">90, 220</span>                                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.StackingClassifier, 234</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">es and repeat the same process on every branch.</span>                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Step 4a: A branch with entropy of 0 is a leaf node</span>                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Step 4b: A branch with entropy more than 0 needs further splitting</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Step 5: The ID3 algorithm is run recursively on the non-leaf branches, until all data is classified.</span>           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Decision Tree to Decision Rules</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A decision tree can easily be transformed to a set of rules by mapping from the root node to the leaf nodes </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">one by one.</span>                                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Limitations to Decision Trees</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Decision trees tend to have high variance when they utilize different training and test sets of the same </span>      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">data, since they tend to overfit on training data. This leads to poor performance on unseen data. </span>             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Unfortunately, this limits the usage of decision trees in predictive modeling. </span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To overcome these problems we use ensemble methods, we can create models that utilize underlying(weak) </span>        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision trees as a foundation for producing powerful results and this is done in Random Forest Algorithm</span>      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random forest</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Definition:</span>                                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random fores</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tance, you get the image represented in</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-6.</span>                                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-6. MNIST pixel importance (according to a random forest classifier)</span>                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random forests are very handy to get a quick understanding of what features actually</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">matter, in particular if you need to perform feature selection.</span>                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Boosting</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Boosting (originally called hypothesis boosting) refers to any ensemble method that</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can combine several weak learners into a strong learner. The general idea of most</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">boosting methods is to train predictors sequentially, each trying to correct its prede‐</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cessor. There are many boosting methods available, but by far the most popular</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">are AdaBoost13 (short for adaptive boosting) and gradient boosting. Let’s start with</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost.</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One way for a new predictor to correct its predecessor is to pay a bit more attention</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to the training instances that the predecessor underfit. This results in new predictors</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">focusing more and more on the hard cases. This is the technique used by AdaBoost.</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">222 </span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Chapter 7: E</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learners in the ensemble and they are sufficiently diverse.</span>                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">How is this possible? The following analogy can help shed some light on this mystery.</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Suppose you have a slightly biased coin that has a 51% chance of coming up heads</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and 49% chance of coming up tails. If you toss it 1,000 times, you will generally get</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">more or less 510 heads and 490 tails, and hence a majority of heads. If you do the</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">math, you will find that the probability of obtaining a majority of heads after 1,000</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tosses is close to 75%. The more you toss the coin, the higher the probability (e.g.,</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with 10,000 tosses, the probability climbs over 97%). This is due to the law of large</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">numbers: as you keep tossing the coin, the ratio of heads gets closer and closer to</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the probability of heads (51%). Figure 7-3 shows 10 series of biased coin tosses. You</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can see that as the number of tosses increases, the ratio of heads approaches 51%.</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Eventually all 10 series end up so close to 51% that they are consistently above 50%.</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure </span>                                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\"> learning, 692</span>                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exponential linear unit (ELU), 363-366</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exponential scheduling, 389, 392</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">export_graphviz(), 196</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra-trees, random forest, 220</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extremely randomized trees ensemble (extra-</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trees), 221</span>                                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">F</span>                                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">face-recognition classifier, 125</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">false negatives, confusion matrix, 109</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">false positive rate (FPR) or fall-out, 115</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">false positives, confusion matrix, 109</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fan-in/fan-out, 359</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fast-MCD, 293</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">FCNs (fully convolutional networks), 525-526,</span>                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">532</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature engineering, 30, 262</span>                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature extraction, 12, 30</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature maps, 485-487, 488, 508, 511</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature scaling, 75-79, 141, 176</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature selection, 30, 95, 159, 221</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature vectors, 45, 133, 186</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">features, 11</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">federated learning, 746</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feedforward neural network (FNN), 309, 538</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch_openml(), 104</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fillna(), 68</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">filters, convolutional layers, 484, 487, 497, 509</span>                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">first moment (mean of gradient), 384</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">first-order partial derivatives (Jacobians), 386</span>                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit()</span>                                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and custom transformers, 80, 84</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">data cleaning, 69</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">versus partial_fit(), 148</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">using only with training set, 75</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fitnes</span>                                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">than the single decision tree’s predictions: the ensemble has a compara‐</span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ble bias but a smaller variance (it makes roughly the same number of errors on the</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training set, but the decision boundary is less irregular).</span>                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging introduces a bit more diversity in the subsets that each predictor is trained</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on, so bagging ends up with a slightly higher bias than pasting; but the extra diversity</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">also means that the predictors end up being less correlated, so the ensemble’s variance</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is reduced. Overall, bagging often results in better models, which explains why</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it’s generally preferred. But if you have spare time and CPU power, you can use</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross-validation to evaluate both bagging and pasting and select the one that works</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">best.</span>                                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting </span>                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">217 7 As m grows, this ratio approaches 1 – exp(–1) ≈ 63%.</span>                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-5. A single decision tree (left) versus a bagging ensemble of 500 trees (right)</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Out-of-Bag Evaluation</span>                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">With bagging, some training instances may be sampled several times for any gi</span>                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ameter to \"soft\", and ensure that all classifiers can estimate</span>                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">class probabilities. This is not the case for the SVC class by default, so you need</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to set its probability hyperparameter to True (this will make the SVC class use</span>                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross-validation to estimate class probabilities, slowing down training, and it will add</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a predict_proba() method). Let’s try that:</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; voting_clf.voting = \"soft\"</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; voting_clf.named_estimators[\"svc\"].probability = True</span>                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; voting_clf.fit(X_train, y_train)</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; voting_clf.score(X_test, y_test)</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">0.92</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">We reach 92% accuracy simply by using soft voting—not bad!</span>                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One way to get a diverse set of classifiers is to use very different training algorithms,</span>                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">as just discussed. Another approach is to use the same training algorithm for every</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor but train them on different random subsets of the training set. When</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sampling is performed with replacement,1 this method is called bagging2 (short for</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bootstrap aggregating3). When sampling is performed withou</span>                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in GBRT ensem‐</span>                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bles more easily (there’s also a GradientBoostingClassifier class for classifica‐</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tion). Much like the RandomForestRegressor class, it has hyperparameters to</span>                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">control the growth of decision trees (e.g., max_depth, min_samples_leaf), as well</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">as hyperparameters to control the ensemble training, such as the number of trees</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(n_estimators). The following code creates the same ensemble as the previous one:</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import GradientBoostingRegressor</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3,</span>                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">                                 learning_rate=1.0, random_state=42)</span>                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt.fit(X, y)</span>                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Boosting </span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">| </span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">227 Figure 7-9. In this depiction of gradient boosting, the first predictor (top left) is trained</span>              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">normally, then each consecutive predictor (middle left and lower left) is trained on the</span>                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">previous predictor’s residuals; the right column shows the resulting ensemble’s predictions</span>                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The learning_rate hyperparameter scales the contribution of each tree. If you set</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it to a</span>                                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">se the learning rate?</span>                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">8. Load the MNIST dataset (introduced in Chapter 3), and split it into a training</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">8.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000</span>                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for validation, and 10,000 for testing). Then train various classifiers, such as a</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">random forest classifier, an extra-trees classifier, and an SVM classifier. Next, try</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to combine them into an ensemble that outperforms each individual classifier</span>                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on the validation set, using soft or hard voting. Once you have found one, try</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it on the test set. How much better does it perform compared to the individual</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifiers?</span>                                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">9. Run the individual classifiers from the previous exercise to make predictions on</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">9.</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the validation set, and create a new training set with the resulting predictions:</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each training instance is a vector containing the set of predictions from all your</span>                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifiers for an image, and the target is the image’s class. Train a classifier</span>                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on this new training set. Congratulations—you have just</span>                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">                             199</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Computational Complexity                                                                                     </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">200</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Gini Impurity or Entropy?                                                                                    </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">201</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Regularization Hyperparameters                                                                              </span>   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">201</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Regression                                                                                                   </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">204</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Sensitivity to Axis Orientation                                                                              </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">206</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Decision Trees Have a High Variance                                                                       207</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Exercises                                                                                                    </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">208</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">7. Ensemble Learning and Random Forests. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">. .  211</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Voting Clas</span>                                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">StackingRegressor, 234</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.ensemble.VotingClassifier, 214</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.externals.joblib, 97-98</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.feature_selection.SelectFromModel,</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">95</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.impute.IterativeImputer, 69</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.impute.KNNImputer, 69</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.impute.SimpleImputer, 68</span>                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.ElasticNet, 162</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.Lasso, 161</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.LinearRegression, 25,</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">71, 79, 137, 138, 150</span>                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.LogisticRegression,</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">168, 172, 275</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.Perceptron, 307</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.Ridge, 157</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.RidgeCV, 158</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.SGDClassifier, 106,</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">111, 112, 117-119, 121, 183, 188, 307</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.linear_model.SGDRegressor, 147,</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">163</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.manifold.LocallyLinearEmbedding,</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">254</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.ConfusionMatrixDisplay,</span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">122</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.confusion_matrix(), 109,</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">122</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.f1_score(), 111, 126</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.mean_squared_error(), 88</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.precision_recall_curve(),</span>                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">113, 117</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.precision_score(), 110</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.metrics.recall_score(), 110</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearn.</span>                                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mDocument Search Assistant\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mEnsemble Learning and Random Forests\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSuppose you pose a complex question to thousands of random people, then aggregate\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtheir answers. In many cases you will find that this aggregated answer is better than\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92man expert’s answer. This is called the wisdom of the crowd. Similarly, if you aggregate\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe predictions of a group of predictors (such as classifiers or regressors), you will\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92moften get better predictions than with the best individual predictor. A group of\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors is called an ensemble; thus, this technique is called ensemble learning, and\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92man ensemble learning algorithm is called an ensemble method.\u001b[0m                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAs an example of an ensemble method, you can train a group of decision tree\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifiers, each on a different random subset of the training set. You can then obtain\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe predictions of all the individual trees, and the class that gets the most votes is\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe ensemble’s prediction (see the last exercise in Chapter 6). Such an ensemble of\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdecision trees is called a random forest, and despite its simplicity, this is one of the\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmost powerful machine learning algorithms available today.\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAs discussed in Chapter 2, you will often use ensemble methods near the end of\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma project, once you have already built a few good predictors, to combine them\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minto an even better predictor. In fact, the winning solutions in machine learning\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcompetitions often involve several ensemble methods—most famously in the Netflix\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mPrize competition.\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIn this chapter we will examine the most popular ensemble methods, including\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mvoting classifiers, bagging and pasting ensembles, random forests, and boosting, and\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mstacking ensembles.\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mVoting Classifiers\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSuppose you have trained a few classifiers, each one achieving about 80% accuracy.\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mYou may have a logistic regression classifier, an SVM classifier, a random forest\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifier, a k-nearest neighbors classifier, and perhaps a few more (see Figure 7-1).\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mA very simple way to create an even better classifier is to aggregate the predictions\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mof each classifier: the class that gets the most votes is the ensemble’s prediction. This\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmajority-vote classifier is called a hard voting classifier (see Figure 7-2).\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSomewhat surprisingly, this voting classifier often achieves a higher accuracy than\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe best classifier in the ensemble. In fact, even if each classifier is a weak learner\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(meaning it does only slightly better than random guessing), the ensemble can still be\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma strong learner (achieving high accuracy), provided there are a sufficient number of\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mweak learners in the ensemble and they are sufficiently diverse.\u001b[0m                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mHow is this possible? The following analogy can help shed some light on this mystery.\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSuppose you have a slightly biased coin that has a 51% chance of coming up heads\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand 49% chance of coming up tails. If you toss it 1,000 times, you will generally get\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmore or less 510 heads and 490 tails, and hence a majority of heads. If you do the\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmath, you will find that the probability of obtaining a majority of heads after 1,000\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtosses is close to 75%. The more you toss the coin, the higher the probability (e.g.,\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwith 10,000 tosses, the probability climbs over 97%). This is due to the law of large\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnumbers: as you keep tossing the coin, the ratio of heads gets closer and closer to\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe probability of heads (51%). Figure 7-3 shows 10 series of biased coin tosses. You\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcan see that as the number of tosses increases, the ratio of heads approaches 51%.\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mEventually all 10 series end up so close to 51% that they are consistently above 50%.\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mEnsemble methods work best when the predictors are as independ‐\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ment from one another as possible. One way to get diverse classifiers\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mis to train them using very different algorithms. This increases the\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mchance that they will make very different types of errors, improving\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe ensemble’s accuracy.\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn provides a VotingClassifier class that’s quite easy to use: just give\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit a list of named estimators, specify hard or soft voting, and that’s it!\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mBagging and Pasting\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOne way to get a diverse set of classifiers is to use very different training algorithms,\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mas just discussed. Another approach is to use the same training algorithm for every\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor but train them on different random subsets of the training set. When\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msampling is performed with replacement,1 this method is called bagging2 (short for\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbootstrap aggregating3). When sampling is performed without replacement, it is called\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpasting.\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIn other words, both bagging and pasting allow training instances to be sampled\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mseveral times across multiple predictors, but only bagging allows training instances to\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbe sampled several times for the same predictor. This sampling and training process\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mis represented in Figure 7-4.\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOnce all predictors are trained, the ensemble can make a prediction for a new\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstance by simply aggregating the predictions of all predictors. The aggregation\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfunction is typically the statistical mode for classification (i.e., the most frequent\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mprediction, just like with a hard voting classifier), or the average for regression. Each\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mindividual predictor has a higher bias than if it were trained on the original training\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mset, but aggregation reduces both bias and variance. General\u001b[0m                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAs you can see in Figure 7-4, predictors can all be trained in parallel, via different\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mCPU cores or even different servers. Similarly, predictions can be made in parallel.\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThis is one of the reasons bagging and pasting are such popular methods: they scale\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mvery well.\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mBagging and Pasting in Scikit-Learn\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn offers a simple API for both bagging and pasting: BaggingClassifier\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclass (or BaggingRegressor for regression). The following code trains an ensemble\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mof 500 decision tree classifiers:6 each is trained on 100 training instances randomly\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msampled from the training set with replacement (this is an example of bagging, but\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mif you want to use pasting instead, just set bootstrap=False). The n_jobs parameter\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtells Scikit-Learn the number of CPU cores to use for training and predictions, and\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m–1 tells Scikit-Learn to use all available cores:\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import BaggingClassifier\u001b[0m                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.tree import DecisionTreeClassifier\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\u001b[0m                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m                            max_samples=100, n_jobs=-1, random_state=42)\u001b[0m                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbag_clf.fit(X_train, y_train)\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mA BaggingClassifier automatically performs soft voting instead\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mof hard voting if the base classifier can estimate class probabilities\u001b[0m                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(i.e., if it has a predict_proba() method), which is the case with\u001b[0m                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdecision tree classifiers.\u001b[0m                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFigure 7-5 compares the decision boundary of a single decision tree with the decision\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mboundary of a bagging ensemble of 500 trees (from the preceding code), both trained\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mon the moons dataset. As you can see, the ensemble’s predictions will likely generalize\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmuch better than the single decision tree’s predictions: the ensemble has a compara‐\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mble bias but a smaller variance (it makes roughly the same number of errors on the\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining set, but the decision boundary is less irregular).\u001b[0m                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mBagging introduces a bit more diversity in the subsets that each predictor is trained\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mon, so bagging ends up with a slightly higher bias than pasting; but the extra diversity\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92malso means that the predictors end up being less correlated, so the ensemble’s variance\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mis reduced. Overall, bagging often results in better models, which explains why\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit’s generally preferred. But if you have spare time and CPU power, you can use\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcross-validation to evaluate both bagging and pasting and select the one that works\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbest.\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOut-of-Bag Evaluation\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mWith bagging, some training instances may be sampled several times for any gi\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mven\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor, while others may not be sampled at all. By default a BaggingClassifier\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msamples m training instances with replacement (bootstrap=True), where m is the\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msize of the training set. With this process, it can be shown mathematically that only\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mabout 63% of the training instances are sampled on average for each predictor.7 The\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mremaining 37% of the training instances that are not sampled are called out-of-bag\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(OOB) instances. Note that they are not the same 37% for all predictors.\u001b[0m                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mA bagging ensemble can be evaluated using OOB instances, without the need for\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma separate validation set: indeed, if there are enough estimators, then each instance\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92min the training set will likely be an OOB instance of several estimators, so these\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mestimators can be used to make a fair ensemble prediction for that instance. Once\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92myou have a prediction for each instance, you can compute the ensemble’s prediction\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92maccuracy (or any other metric).\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIn Scikit-Learn, you can set oob_score=True when creating a BaggingClassifier\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mto request an automatic OOB evaluation after training. The following code demonstrates this:\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...                             max_samples=100, oob_score=True, n_jobs=-1,\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...                             random_state=42)\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> bag_clf.fit(X_train, y_train)\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> bag_clf.oob_score_\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m0.901\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAccording to this OOB evaluation, this BaggingClassifier is likely to achieve\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mabout 90.1% accuracy on the test set. Let’s verify this:\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> from sklearn.metrics import accuracy_score\u001b[0m                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> y_pred = bag_clf.predict(X_test)\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> accuracy_score(y_test, y_pred)\u001b[0m                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m0.912\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mWe get 91.2% accuracy on the test set—close to what the OOB evaluation predicted!\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe OOB decision function is also available via the oob_decision_function_\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mvariable. In this case (since the base estimator has a predict_proba() method)\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit returns the class probabilities that each training instance received on average from\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe estimators that did not see it during training:\u001b[0m                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> bag_clf.oob_decision_function_[:3]  # proba for the first 3 instances\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92marray([[0.324, 0.676],  # proba of instance 1: 68% chance it's in class 1\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m       [0.356, 0.644],  # proba of instance 2: 64% chance it's in class 1\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m       [0.639, 0.361]])  # proba of instance 3: 64% chance it's in class 0\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mRandom Patches and Random Subspaces\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe BaggingClassifier class supports sampling the features as well. This is controlled\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mby two hyperparameters: max_features and bootstrap_features. They work just like\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmax_samples and bootstrap, but for feature sampling instead of instance sampling.\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThus, each predictor will be trained on a random subset of the input features.\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThis technique is particularly useful when you are dealing with high-dimensional\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minputs (such as images), as it can considerably speed up training. Sampling both\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining instances and features is called the random patches method.8 Keeping all\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining instances (by setting bootstrap=False and max_samples=1.0) but sampling\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfeatures (by setting bootstrap_features to True and/or max_features to a value\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msmaller than 1.0) is called the random subspaces method.9\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSampling features results in even more predictor diversity, trading a bit more bias for\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma lower variance.\u001b[0m                                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mRandom Forests\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAs we have discussed, a random forest is an ensemble of decision trees, generally\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrained via the bagging method (or sometimes pasting), typically with max_samples\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mset to the size of the training set. Instead of building a BaggingClassifier and passing\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit a DecisionTreeClassifier, you can instead use the RandomForestClassifier class\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(for regression tasks, there is also a RandomForestRegressor class). The following\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcode trains a random forest classifier with 500 trees (each limited to maximum 16\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnodes), using all available CPU cores:\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import RandomForestClassifier\u001b[0m                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,\u001b[0m                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m                                n_jobs=-1, random_state=42)\u001b[0m                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrnd_clf.fit(X_train, y_train)\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mRandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(to control how trees are grown), plus all the hyperparameters of a BaggingClassifier\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mto control the ensemble itself.\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe random forest algorithm introduces extra randomness when growing trees; instead\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mof searching for the very best feature when splitting a node (see Chapter 6), it searches\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfor the best feature among a random subset of features. This results in even greater\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree diversity, which (again) trades a higher bias for a lower variance, generally\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92myielding an overall better model. The following BaggingClassifier is roughly\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mequivalent to the previous RandomForestClassifier:\u001b[0m                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbag_clf = BaggingClassifier(\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\u001b[0m                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    n_estimators=500, n_jobs=-1, random_state=42)\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbag_clf.fit(X_train, y_train)\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> y_pred = bag_clf.predict(X_test)\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mWarning: the max_features hyperparameter used to be called\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmax_features in Scikit-Learn, but this is deprecated; now you\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmust use max_features. The default value has also changed from\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m0 to \"sqrt\".\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFeature Importance\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mYet another great quality of random forests is that they make it easy to measure the\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrelative importance of each feature. Scikit-Learn measures a feature’s importance by\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mlooking at how much the tree nodes that use that feature reduce impurity on average\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(across all trees in the forest). More precisely, it is a weighted average, where the\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mweight is the number of training samples that reach that node.\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn computes this score automatically for each feature after training, and\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit makes the result available via the feature_importances_ variable. For example,\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe following code trains a RandomForestClassifier on the MNIST dataset (intro‐\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mduced in Chapter 3) and displays each pixel’s importance:\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> from sklearn.datasets import fetch_openml\u001b[0m                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> mnist = fetch_openml('mnist_784', version=1, as_frame=False)\u001b[0m                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> mnist.target = mnist.target.astype(np.uint8)\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> from sklearn.model_selection import train_test_split\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> X_train, X_test, y_train, y_test = train_test_split(\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     mnist[\"data\"], mnist[\"target\"], random_state=42)\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> from sklearn.ensemble import RandomForestClassifier\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\u001b[0m                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> rnd_clf.fit(X_train, y_train)\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> def plot_digit(data):\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     image = data.reshape(28, 28)\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     plt.imshow(image, cmap = mpl.cm.hot,\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...                interpolation=\"nearest\")\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     plt.axis(\"off\")\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> plot_digit(rnd_clf.feature_importances_)\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),\u001b[0m                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...                           rnd_clf.feature_importances_.max()])\u001b[0m                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> cbar.ax.set_yticklabels(['Not important', 'Very important'])\u001b[0m                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> plt.show()\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNow if you look at the feature importances, you get the image represented in\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFigure 7-6.\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mRandom forests are very handy to get a quick understanding of what features actually\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmatter, in particular if you need to perform feature selection.\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mBoosting\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mBoosting (originally called hypothesis boosting) refers to any ensemble method that\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcan combine several weak learners into a strong learner. The general idea of most\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mboosting methods is to train predictors sequentially, each trying to correct its prede‐\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcessor. There are many boosting methods available, but by far the most popular\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mare AdaBoost13 (short for adaptive boosting) and gradient boosting. Let’s start with\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAdaBoost.\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAdaBoost\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOne way for a new predictor to correct its predecessor is to pay a bit more attention\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mto the training instances that the predecessor underfit. This results in new predictors\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfocusing more and more on the hard cases. This is the technique used by AdaBoost.\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFor example, to train an AdaBoost classifier, the algorithm first trains a base classifier\u001b[0m                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(such as a decision tree) and uses it to make predictions on the training set. The\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92malgorithm then increases the relative weight of misclassified training instances. Then,\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit trains a second classifier, using the updated weights, and again makes predictions\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mon the training set, updates the instance weights, and so on (see Figure 7-7).\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFigure 7-8 shows the decision boundaries of five consecutive predictors trained on the\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmoons dataset (in this case, each predictor is a highly regularized SVM classifier with\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92man RBF kernel). The first classifier gets many instances wrong, so their weights are\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mboosted. The second classifier therefore does a better job on these instances, and so\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mon. The plot on the right represents the decision boundary of the AdaBoost ensemble.\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNotice that by boosting the weights of misclassified instances, the algorithm forces\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92meach new classifier to focus more on the difficult cases.\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mLooking more closely, AdaBoost is actually doing something even more subtle. Each\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor has a weight αj that depends on its accuracy on the weighted training set.\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe more accurate the predictor is, the higher its weight will be. If it is just guessing\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrandomly, then its weight will be close to zero. However, if it is worse than random\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mguessing, then its weight will be negative.\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTo make predictions, AdaBoost simply computes the predictions of all the predictors\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand weighs them using the predictor weights αj. The predicted class is the one that\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mreceives the majority of weighted votes.\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn actually uses a multiclass version of AdaBoost called SAMME (which\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mstands for Stagewise Additive Modeling using a Multiclass Exponential loss function).\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mWhen there are just two classes, SAMME is equivalent to AdaBoost. If the predictors\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcan estimate class probabilities (i.e., if they have a predict_proba() method), Scikit-\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mLearn can use a variant of SAMME called SAMME.R (the “R” stands for “Real”),\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwhich relies on class probabilities rather than predictions and generally performs\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbetter.\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe following code trains an AdaBoostClassifier based on 200 decision stumps\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92musing the SAMME.R algorithm:\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import AdaBoostClassifier\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mada_clf = AdaBoostClassifier(\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    DecisionTreeClassifier(max_depth=1), n_estimators=200,\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\u001b[0m                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mada_clf.fit(X_train, y_train)\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIf your AdaBoost ensemble underfits the training data, you can try increasing the\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnumber of estimators or reducing the regularization hyperparameters of the base\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mestimator (e.g., max_depth).\u001b[0m                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mGradient Boosting\u001b[0m                                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAnother very popular boosting algorithm is gradient boosting.16 Just like AdaBoost,\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgradient boosting works by sequentially adding predictors to an ensemble, each one\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcorrecting its predecessor. However, instead of tweaking the instance weights at\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mevery iteration like AdaBoost does, this method tries to fit the new predictor to the\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mresidual errors made by the previous predictor.\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mLet’s go through a simple regression example using decision trees as the predictors\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(of course, gradient boosting also works with other predictors). This is called Gradient\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTree Boosting, or Gradient Boosted Regression Trees (GBRT). First, let’s fit a\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mDecisionTreeRegressor to the training set (for simplicity, let’s use a noisy quadratic\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining set):\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimport numpy as np\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.tree import DecisionTreeRegressor\u001b[0m                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnp.random.seed(42)\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mX = np.random.rand(100, 1) - 0.5\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92my = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\u001b[0m                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree_reg1.fit(X, y)\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNow let’s train a second DecisionTreeRegressor on the residual errors made by the\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfirst predictor:\u001b[0m                                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92my2 = y - tree_reg1.predict(X)\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree_reg2.fit(X, y2)\u001b[0m                                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThen we train a third regressor on the residual errors made by the second predictor:\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92my3 = y2 - tree_reg2.predict(X)\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree_reg3.fit(X, y3)\u001b[0m                                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNow we have an ensemble containing three trees. It can make predictions on a new\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstance simply by adding up the predictions of all the trees:\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> X_new = np.array([[-0.4], [0.], [0.5]])\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92marray([0.49484029, 0.04021166, 0.75026781])\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFigure 7-9 represents the predictions of these three trees in the left column, and the\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble’s predictions in the right column. In the first row, the ensemble has just one\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree, so its predictions are exactly the same as the first tree’s predictions. In the second\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrow, a new tree is trained on the residual errors of the first tree. On the right you can\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msee that the ensemble’s predictions are equal to the sum of the predictions of the first\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtwo trees. Similarly, in the third row another tree is trained on the residual errors of\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe second tree. You can see that the ensemble’s predictions gradually get better as\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrees are added to the ensemble.\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mYou can use Scikit-Learn’s GradientBoostingRegressor class to train GBRT ensembles. Here is a simple example:\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import GradientBoostingRegressor\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3,\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m                                 learning_rate=1.0, random_state=42)\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgbrt.fit(X, y)\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFigure 7-10 shows the predictions of this ensemble. Notice how each tree’s contribution is scaled by the \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mlearning_rate hyperparameter. If you set it to a low value, such as 0.05, you will need many more trees in \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe ensemble to fit the training data, but the predictions will usually generalize better. This is a \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregularization technique called shrinkage.\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTip: Finding the right number of trees\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTo find the optimal number of trees, you can use early stopping (again, see Chapter 4). A simple way to \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimplement this is to use the staged_predict() method: it returns an iterator over the predictions made by the\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble at each stage of training (with one tree, two trees, etc.). The following code trains a GBRT \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble with 120 trees, then measures the validation error at each stage of training to find the optimal \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnumber of trees, and finally trains another GBRT ensemble using the optimal number of trees:\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.model_selection import train_test_split\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.metrics import mean_squared_error\u001b[0m                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\u001b[0m                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgbrt.fit(X_train, y_train)\u001b[0m                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92merrors = [mean_squared_error(y_val, y_pred)\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          for y_pred in gbrt.staged_predict(X_val)]\u001b[0m                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbst_n_estimators = np.argmin(errors) + 1\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators, random_state=42)\u001b[0m              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgbrt_best.fit(X_train, y_train)\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe validation errors are represented on the left of Figure 7-10, and the best model’s predictions are \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrepresented on the right.\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIt is also possible to implement early stopping by actually interrupting training when the validation error \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdoes not improve for a number of iterations. You can do this by setting the warm_start=True when creating the\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mGradientBoostingRegressor. When the fit() method is called, training will resume from the previous state, \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mallowing you to tweak the number of estimators.\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> min_val_error = float(\"inf\")\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> error_going_up = 0\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m>>> for n_estimators in range(1, 120):\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     gbrt.n_estimators = n_estimators\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     gbrt.fit(X_train, y_train)\u001b[0m                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     y_pred = gbrt.predict(X_val)\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     val_error = mean_squared_error(y_val, y_pred)\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     if val_error < min_val_error:\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...         min_val_error = val_error\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...         error_going_up = 0\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...     else:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...         error_going_up += 1\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...         if error_going_up == 10:\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m...             break  # early stopping\u001b[0m                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe GradientBoostingRegressor also supports a subsample hyperparameter, which specifies the fraction of \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining instances to be used for training each tree. For example, if subsample=0.25, then each tree is \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrained on 25% of the training instances, selected randomly. As you can probably guess, this trades a higher \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbias for a lower variance. It also speeds up training considerably. This technique is called stochastic \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgradient boosting.\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIt is worth noting that it is possible to use other cost functions than the mean squared error. You control \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthis using the loss hyperparameter. Table 7-1 lists the available options.\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTable 7-1. Cost functions for GradientBoostingRegressor\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mloss    \u001b[0m\u001b[92mDescription\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msquared_error   \u001b[0m\u001b[92mMean Squared Error (default)\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mabsolute_error  \u001b[0m\u001b[92mMean Absolute Error\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhuber   \u001b[0m\u001b[92mCombination of the two; uses squared error for small errors and absolute error for large errors\u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mquantile        \u001b[0m\u001b[92mCost function for quantile regression (use alpha to specify the quantile)\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTip: HistGradientBoosting\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn 1.0 introduced two new classes for gradient boosting: HistGradientBoostingClassifier and \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mHistGradientBoostingRegressor. They are very similar to GradientBoostingClassifier and \u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mGradientBoostingRegressor, except they can be much faster, especially when the training set is large: indeed,\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthis implementation bins the inputs (like a preprocessing step), and it looks at these bins rather than at \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe exact values. This also makes it possible to support categorical features. Moreover, when building the \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdecision trees, it uses a much faster technique to find the best split at each node. This implementation was \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minspired by LightGBM,17 a very popular gradient boosting library.\u001b[0m                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTo use it, you must first install scikit-learn-intelex; this will install the Intel Extension for \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-learn, which contains optimized versions of many Scikit-Learn algorithms, including these two new \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgradient boosting classes.\u001b[0m                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimport sklearnex\u001b[0m                                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msklearnex.patch_sklearn()\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import HistGradientBoostingRegressor\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhist_gbrt = HistGradientBoostingRegressor(random_state=42)\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhist_gbrt.fit(X_train, y_train)\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThis implementation offers several other advantages: for example, it supports missing values (no need for \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimputation). For much more information, see the Scikit-Learn documentation.\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThere are also other implementations of gradient boosting, such as XGBoost, which used to be available via \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe xgboost Python library. It offers several nice features, such as automatically taking care of \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregularization (e.g., L1 or L2 regularization). And CatBoost is another popular gradient boosting library, \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwhich is particularly good at handling categorical features. Both XGBoost and CatBoost are available via \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtheir own Python libraries, and they are easy to install. These libraries also offer many other features, \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mincluding GPU acceleration; you should definitely check them out! Moreover, the TensorFlow Random Forests \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mlibrary provides optimized implementations of a variety of random forest algorithms, including plain random \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mforests, extra-trees, GBRT, and several more.\u001b[0m                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mStacking\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe last ensemble method we will discuss in this chapter is called stacking (short for\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mstacked generalization).18 It is based on a simple idea: instead of using trivial functions\u001b[0m                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(such as hard voting) to aggregate the predictions of all predictors in an ensemble,\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwhy don’t we train a model to perform this aggregation? Figure 7-11 shows such an\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble performing a regression task on a new instance. Each of the bottom three\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors predicts a different value (3.1, 2.7, and 2.9), and then the final predictor\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(called a blender, or a meta learner) takes these predictions as inputs and makes the\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfinal prediction (3.0).\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTo train the blender, you first need to build the blending training set. You can\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92muse cross_val_predict() on every predictor in the ensemble to get out-of-sample\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictions for each instance in the original training set (Figure 7-12), and use these\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcan be used as the input features to train the blender; and the targets can simply be\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcopied from the original training set. Note that regardless of the number of features\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92min the original training set (just one in this example), the blending training set will\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcontain one input feature per predictor (three in this example). Once the blender is\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrained, the base predictors are retrained one last time on the full original training set.\u001b[0m                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIt is actually possible to train several different blenders this way (e.g., one using linear\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregression, another using random forest regression) to get a whole layer of blenders,\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand then add another blender on top of that to produce the final prediction, as shown\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92min Figure 7-13. You may be able to squeeze out a few more drops of performance by\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdoing this, but it will cost you in both training time and system complexity.\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn provides two classes for stacking ensembles: StackingClassifier and\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mStackingRegressor. For example, we can replace the VotingClassifier we used at\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe beginning of this chapter on the moons dataset with a StackingClassifier:\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfrom sklearn.ensemble import StackingClassifier\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mstacking_clf = StackingClassifier(\u001b[0m                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    estimators=[\u001b[0m                                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        ('lr', LogisticRegression(random_state=42)),\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        ('rf', RandomForestClassifier(random_state=42)),\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        ('svc', SVC(probability=True, random_state=42))\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    ],\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    final_estimator=RandomForestClassifier(random_state=43),\u001b[0m                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    cv=5  # number of cross-validation folds\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m)\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mstacking_clf.fit(X_train, y_train)\u001b[0m                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFor each predictor, the stacking classifier will call predict_proba() if available; if not\u001b[0m                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mit will fall back to decision_function() or, as a last resort, call predict(). If you\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdon’t provide a final estimator, StackingClassifier will use LogisticRegression\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand StackingRegressor will use RidgeCV.\u001b[0m                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIf you evaluate this stacking model on the test set, you will find 92.8% accuracy,\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwhich is a bit better than the voting classifier using soft voting, which got 92%.\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIn conclusion, ensemble methods are versatile, powerful, and fairly simple to use.\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mRandom forests, AdaBoost, and GBRT are among the first models you should test for\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmost machine learning tasks, and they particularly shine with heterogeneous tabular\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdata. Moreover, as they require very little preprocessing, they’re great for getting a\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mprototype up and running quickly. Lastly, ensemble methods like voting classifiers\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand stacking classifiers can help push your system’s performance to its limits.\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Document Search Assistant</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Ensemble Learning and Random Forests</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Suppose you pose a complex question to thousands of random people, then aggregate</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">their answers. In many cases you will find that this aggregated answer is better than</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an expert’s answer. This is called the wisdom of the crowd. Similarly, if you aggregate</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the predictions of a group of predictors (such as classifiers or regressors), you will</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">often get better predictions than with the best individual predictor. A group of</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors is called an ensemble; thus, this technique is called ensemble learning, and</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an ensemble learning algorithm is called an ensemble method.</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As an example of an ensemble method, you can train a group of decision tree</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifiers, each on a different random subset of the training set. You can then obtain</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the predictions of all the individual trees, and the class that gets the most votes is</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble’s prediction (see the last exercise in Chapter 6). Such an ensemble of</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision trees is called a random forest, and despite its simplicity, this is one of the</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">most powerful machine learning algorithms available today.</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As discussed in Chapter 2, you will often use ensemble methods near the end of</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a project, once you have already built a few good predictors, to combine them</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">into an even better predictor. In fact, the winning solutions in machine learning</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">competitions often involve several ensemble methods—most famously in the Netflix</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Prize competition.</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In this chapter we will examine the most popular ensemble methods, including</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">voting classifiers, bagging and pasting ensembles, random forests, and boosting, and</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacking ensembles.</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Voting Classifiers</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Suppose you have trained a few classifiers, each one achieving about 80% accuracy.</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You may have a logistic regression classifier, an SVM classifier, a random forest</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifier, a k-nearest neighbors classifier, and perhaps a few more (see Figure 7-1).</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A very simple way to create an even better classifier is to aggregate the predictions</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of each classifier: the class that gets the most votes is the ensemble’s prediction. This</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">majority-vote classifier is called a hard voting classifier (see Figure 7-2).</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Somewhat surprisingly, this voting classifier often achieves a higher accuracy than</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the best classifier in the ensemble. In fact, even if each classifier is a weak learner</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(meaning it does only slightly better than random guessing), the ensemble can still be</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a strong learner (achieving high accuracy), provided there are a sufficient number of</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weak learners in the ensemble and they are sufficiently diverse.</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">How is this possible? The following analogy can help shed some light on this mystery.</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Suppose you have a slightly biased coin that has a 51% chance of coming up heads</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and 49% chance of coming up tails. If you toss it 1,000 times, you will generally get</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">more or less 510 heads and 490 tails, and hence a majority of heads. If you do the</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">math, you will find that the probability of obtaining a majority of heads after 1,000</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tosses is close to 75%. The more you toss the coin, the higher the probability (e.g.,</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with 10,000 tosses, the probability climbs over 97%). This is due to the law of large</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">numbers: as you keep tossing the coin, the ratio of heads gets closer and closer to</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the probability of heads (51%). Figure 7-3 shows 10 series of biased coin tosses. You</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can see that as the number of tosses increases, the ratio of heads approaches 51%.</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Eventually all 10 series end up so close to 51% that they are consistently above 50%.</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Ensemble methods work best when the predictors are as independ‐</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ent from one another as possible. One way to get diverse classifiers</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is to train them using very different algorithms. This increases the</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">chance that they will make very different types of errors, improving</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble’s accuracy.</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn provides a VotingClassifier class that’s quite easy to use: just give</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it a list of named estimators, specify hard or soft voting, and that’s it!</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One way to get a diverse set of classifiers is to use very different training algorithms,</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">as just discussed. Another approach is to use the same training algorithm for every</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor but train them on different random subsets of the training set. When</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sampling is performed with replacement,1 this method is called bagging2 (short for</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bootstrap aggregating3). When sampling is performed without replacement, it is called</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pasting.</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In other words, both bagging and pasting allow training instances to be sampled</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">several times across multiple predictors, but only bagging allows training instances to</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">be sampled several times for the same predictor. This sampling and training process</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is represented in Figure 7-4.</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Once all predictors are trained, the ensemble can make a prediction for a new</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance by simply aggregating the predictions of all predictors. The aggregation</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">function is typically the statistical mode for classification (i.e., the most frequent</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prediction, just like with a hard voting classifier), or the average for regression. Each</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">individual predictor has a higher bias than if it were trained on the original training</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set, but aggregation reduces both bias and variance. General</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As you can see in Figure 7-4, predictors can all be trained in parallel, via different</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">CPU cores or even different servers. Similarly, predictions can be made in parallel.</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">This is one of the reasons bagging and pasting are such popular methods: they scale</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">very well.</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging and Pasting in Scikit-Learn</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn offers a simple API for both bagging and pasting: BaggingClassifier</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">class (or BaggingRegressor for regression). The following code trains an ensemble</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of 500 decision tree classifiers:6 each is trained on 100 training instances randomly</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sampled from the training set with replacement (this is an example of bagging, but</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">if you want to use pasting instead, just set bootstrap=False). The n_jobs parameter</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tells Scikit-Learn the number of CPU cores to use for training and predictions, and</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">–1 tells Scikit-Learn to use all available cores:</span>                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import BaggingClassifier</span>                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.tree import DecisionTreeClassifier</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">                            max_samples=100, n_jobs=-1, random_state=42)</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bag_clf.fit(X_train, y_train)</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A BaggingClassifier automatically performs soft voting instead</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of hard voting if the base classifier can estimate class probabilities</span>                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(i.e., if it has a predict_proba() method), which is the case with</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision tree classifiers.</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-5 compares the decision boundary of a single decision tree with the decision</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">boundary of a bagging ensemble of 500 trees (from the preceding code), both trained</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on the moons dataset. As you can see, the ensemble’s predictions will likely generalize</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">much better than the single decision tree’s predictions: the ensemble has a compara‐</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ble bias but a smaller variance (it makes roughly the same number of errors on the</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training set, but the decision boundary is less irregular).</span>                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging introduces a bit more diversity in the subsets that each predictor is trained</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on, so bagging ends up with a slightly higher bias than pasting; but the extra diversity</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">also means that the predictors end up being less correlated, so the ensemble’s variance</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is reduced. Overall, bagging often results in better models, which explains why</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it’s generally preferred. But if you have spare time and CPU power, you can use</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross-validation to evaluate both bagging and pasting and select the one that works</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">best.</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Out-of-Bag Evaluation</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">With bagging, some training instances may be sampled several times for any gi</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ven</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor, while others may not be sampled at all. By default a BaggingClassifier</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">samples m training instances with replacement (bootstrap=True), where m is the</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">size of the training set. With this process, it can be shown mathematically that only</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">about 63% of the training instances are sampled on average for each predictor.7 The</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">remaining 37% of the training instances that are not sampled are called out-of-bag</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(OOB) instances. Note that they are not the same 37% for all predictors.</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">A bagging ensemble can be evaluated using OOB instances, without the need for</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a separate validation set: indeed, if there are enough estimators, then each instance</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in the training set will likely be an OOB instance of several estimators, so these</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">estimators can be used to make a fair ensemble prediction for that instance. Once</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you have a prediction for each instance, you can compute the ensemble’s prediction</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">accuracy (or any other metric).</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In Scikit-Learn, you can set oob_score=True when creating a BaggingClassifier</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to request an automatic OOB evaluation after training. The following code demonstrates this:</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...                             max_samples=100, oob_score=True, n_jobs=-1,</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...                             random_state=42)</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; bag_clf.fit(X_train, y_train)</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; bag_clf.oob_score_</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">0.901</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">According to this OOB evaluation, this BaggingClassifier is likely to achieve</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">about 90.1% accuracy on the test set. Let’s verify this:</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; from sklearn.metrics import accuracy_score</span>                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; y_pred = bag_clf.predict(X_test)</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; accuracy_score(y_test, y_pred)</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">0.912</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">We get 91.2% accuracy on the test set—close to what the OOB evaluation predicted!</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The OOB decision function is also available via the oob_decision_function_</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">variable. In this case (since the base estimator has a predict_proba() method)</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it returns the class probabilities that each training instance received on average from</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the estimators that did not see it during training:</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; bag_clf.oob_decision_function_[:3]  # proba for the first 3 instances</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">array([[0.324, 0.676],  # proba of instance 1: 68% chance it's in class 1</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">       [0.356, 0.644],  # proba of instance 2: 64% chance it's in class 1</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">       [0.639, 0.361]])  # proba of instance 3: 64% chance it's in class 0</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random Patches and Random Subspaces</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The BaggingClassifier class supports sampling the features as well. This is controlled</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">by two hyperparameters: max_features and bootstrap_features. They work just like</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">max_samples and bootstrap, but for feature sampling instead of instance sampling.</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Thus, each predictor will be trained on a random subset of the input features.</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">This technique is particularly useful when you are dealing with high-dimensional</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inputs (such as images), as it can considerably speed up training. Sampling both</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances and features is called the random patches method.8 Keeping all</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances (by setting bootstrap=False and max_samples=1.0) but sampling</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">features (by setting bootstrap_features to True and/or max_features to a value</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">smaller than 1.0) is called the random subspaces method.9</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Sampling features results in even more predictor diversity, trading a bit more bias for</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a lower variance.</span>                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random Forests</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">As we have discussed, a random forest is an ensemble of decision trees, generally</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained via the bagging method (or sometimes pasting), typically with max_samples</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set to the size of the training set. Instead of building a BaggingClassifier and passing</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it a DecisionTreeClassifier, you can instead use the RandomForestClassifier class</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(for regression tasks, there is also a RandomForestRegressor class). The following</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">code trains a random forest classifier with 500 trees (each limited to maximum 16</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">nodes), using all available CPU cores:</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import RandomForestClassifier</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,</span>                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">                                n_jobs=-1, random_state=42)</span>                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">rnd_clf.fit(X_train, y_train)</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">RandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(to control how trees are grown), plus all the hyperparameters of a BaggingClassifier</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to control the ensemble itself.</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The random forest algorithm introduces extra randomness when growing trees; instead</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of searching for the very best feature when splitting a node (see Chapter 6), it searches</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for the best feature among a random subset of features. This results in even greater</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree diversity, which (again) trades a higher bias for a lower variance, generally</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">yielding an overall better model. The following BaggingClassifier is roughly</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">equivalent to the previous RandomForestClassifier:</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bag_clf = BaggingClassifier(</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),</span>                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    n_estimators=500, n_jobs=-1, random_state=42)</span>                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bag_clf.fit(X_train, y_train)</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; y_pred = bag_clf.predict(X_test)</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Warning: the max_features hyperparameter used to be called</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">max_features in Scikit-Learn, but this is deprecated; now you</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">must use max_features. The default value has also changed from</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">0 to \"sqrt\".</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Feature Importance</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Yet another great quality of random forests is that they make it easy to measure the</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">relative importance of each feature. Scikit-Learn measures a feature’s importance by</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">looking at how much the tree nodes that use that feature reduce impurity on average</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(across all trees in the forest). More precisely, it is a weighted average, where the</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weight is the number of training samples that reach that node.</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn computes this score automatically for each feature after training, and</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it makes the result available via the feature_importances_ variable. For example,</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the following code trains a RandomForestClassifier on the MNIST dataset (intro‐</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">duced in Chapter 3) and displays each pixel’s importance:</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; from sklearn.datasets import fetch_openml</span>                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; mnist = fetch_openml('mnist_784', version=1, as_frame=False)</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; mnist.target = mnist.target.astype(np.uint8)</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     mnist[\"data\"], mnist[\"target\"], random_state=42)</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; rnd_clf.fit(X_train, y_train)</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; def plot_digit(data):</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     image = data.reshape(28, 28)</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     plt.imshow(image, cmap = mpl.cm.hot,</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...                interpolation=\"nearest\")</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     plt.axis(\"off\")</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; plot_digit(rnd_clf.feature_importances_)</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(),</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...                           rnd_clf.feature_importances_.max()])</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; cbar.ax.set_yticklabels(['Not important', 'Very important'])</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; plt.show()</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now if you look at the feature importances, you get the image represented in</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-6.</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random forests are very handy to get a quick understanding of what features actually</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">matter, in particular if you need to perform feature selection.</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Boosting</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Boosting (originally called hypothesis boosting) refers to any ensemble method that</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can combine several weak learners into a strong learner. The general idea of most</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">boosting methods is to train predictors sequentially, each trying to correct its prede‐</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cessor. There are many boosting methods available, but by far the most popular</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">are AdaBoost13 (short for adaptive boosting) and gradient boosting. Let’s start with</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost.</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One way for a new predictor to correct its predecessor is to pay a bit more attention</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to the training instances that the predecessor underfit. This results in new predictors</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">focusing more and more on the hard cases. This is the technique used by AdaBoost.</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">For example, to train an AdaBoost classifier, the algorithm first trains a base classifier</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(such as a decision tree) and uses it to make predictions on the training set. The</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">algorithm then increases the relative weight of misclassified training instances. Then,</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it trains a second classifier, using the updated weights, and again makes predictions</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on the training set, updates the instance weights, and so on (see Figure 7-7).</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-8 shows the decision boundaries of five consecutive predictors trained on the</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">moons dataset (in this case, each predictor is a highly regularized SVM classifier with</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an RBF kernel). The first classifier gets many instances wrong, so their weights are</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">boosted. The second classifier therefore does a better job on these instances, and so</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on. The plot on the right represents the decision boundary of the AdaBoost ensemble.</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Notice that by boosting the weights of misclassified instances, the algorithm forces</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each new classifier to focus more on the difficult cases.</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Looking more closely, AdaBoost is actually doing something even more subtle. Each</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor has a weight αj that depends on its accuracy on the weighted training set.</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The more accurate the predictor is, the higher its weight will be. If it is just guessing</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">randomly, then its weight will be close to zero. However, if it is worse than random</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">guessing, then its weight will be negative.</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To make predictions, AdaBoost simply computes the predictions of all the predictors</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and weighs them using the predictor weights αj. The predicted class is the one that</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">receives the majority of weighted votes.</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn actually uses a multiclass version of AdaBoost called SAMME (which</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stands for Stagewise Additive Modeling using a Multiclass Exponential loss function).</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">When there are just two classes, SAMME is equivalent to AdaBoost. If the predictors</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can estimate class probabilities (i.e., if they have a predict_proba() method), Scikit-</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Learn can use a variant of SAMME called SAMME.R (the “R” stands for “Real”),</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which relies on class probabilities rather than predictions and generally performs</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">better.</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The following code trains an AdaBoostClassifier based on 200 decision stumps</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">using the SAMME.R algorithm:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import AdaBoostClassifier</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ada_clf = AdaBoostClassifier(</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    DecisionTreeClassifier(max_depth=1), n_estimators=200,</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ada_clf.fit(X_train, y_train)</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">If your AdaBoost ensemble underfits the training data, you can try increasing the</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">number of estimators or reducing the regularization hyperparameters of the base</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">estimator (e.g., max_depth).</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Gradient Boosting</span>                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Another very popular boosting algorithm is gradient boosting.16 Just like AdaBoost,</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gradient boosting works by sequentially adding predictors to an ensemble, each one</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">correcting its predecessor. However, instead of tweaking the instance weights at</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">every iteration like AdaBoost does, this method tries to fit the new predictor to the</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">residual errors made by the previous predictor.</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Let’s go through a simple regression example using decision trees as the predictors</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(of course, gradient boosting also works with other predictors). This is called Gradient</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Tree Boosting, or Gradient Boosted Regression Trees (GBRT). First, let’s fit a</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">DecisionTreeRegressor to the training set (for simplicity, let’s use a noisy quadratic</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training set):</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">import numpy as np</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.tree import DecisionTreeRegressor</span>                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">np.random.seed(42)</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">X = np.random.rand(100, 1) - 0.5</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)</span>                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree_reg1.fit(X, y)</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now let’s train a second DecisionTreeRegressor on the residual errors made by the</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">first predictor:</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">y2 = y - tree_reg1.predict(X)</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree_reg2.fit(X, y2)</span>                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Then we train a third regressor on the residual errors made by the second predictor:</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">y3 = y2 - tree_reg2.predict(X)</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree_reg3.fit(X, y3)</span>                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now we have an ensemble containing three trees. It can make predictions on a new</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance simply by adding up the predictions of all the trees:</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; X_new = np.array([[-0.4], [0.], [0.5]])</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">array([0.49484029, 0.04021166, 0.75026781])</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-9 represents the predictions of these three trees in the left column, and the</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble’s predictions in the right column. In the first row, the ensemble has just one</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree, so its predictions are exactly the same as the first tree’s predictions. In the second</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">row, a new tree is trained on the residual errors of the first tree. On the right you can</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">see that the ensemble’s predictions are equal to the sum of the predictions of the first</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">two trees. Similarly, in the third row another tree is trained on the residual errors of</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the second tree. You can see that the ensemble’s predictions gradually get better as</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trees are added to the ensemble.</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You can use Scikit-Learn’s GradientBoostingRegressor class to train GBRT ensembles. Here is a simple example:</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import GradientBoostingRegressor</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3,</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">                                 learning_rate=1.0, random_state=42)</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt.fit(X, y)</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Figure 7-10 shows the predictions of this ensemble. Notice how each tree’s contribution is scaled by the </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learning_rate hyperparameter. If you set it to a low value, such as 0.05, you will need many more trees in </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble to fit the training data, but the predictions will usually generalize better. This is a </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regularization technique called shrinkage.</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Tip: Finding the right number of trees</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To find the optimal number of trees, you can use early stopping (again, see Chapter 4). A simple way to </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">implement this is to use the staged_predict() method: it returns an iterator over the predictions made by the</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble at each stage of training (with one tree, two trees, etc.). The following code trains a GBRT </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble with 120 trees, then measures the validation error at each stage of training to find the optimal </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">number of trees, and finally trains another GBRT ensemble using the optimal number of trees:</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.model_selection import train_test_split</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.metrics import mean_squared_error</span>                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt.fit(X_train, y_train)</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">errors = [mean_squared_error(y_val, y_pred)</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          for y_pred in gbrt.staged_predict(X_val)]</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bst_n_estimators = np.argmin(errors) + 1</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators, random_state=42)</span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gbrt_best.fit(X_train, y_train)</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The validation errors are represented on the left of Figure 7-10, and the best model’s predictions are </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">represented on the right.</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">It is also possible to implement early stopping by actually interrupting training when the validation error </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">does not improve for a number of iterations. You can do this by setting the warm_start=True when creating the</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">GradientBoostingRegressor. When the fit() method is called, training will resume from the previous state, </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">allowing you to tweak the number of estimators.</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; min_val_error = float(\"inf\")</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; error_going_up = 0</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&gt;&gt;&gt; for n_estimators in range(1, 120):</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     gbrt.n_estimators = n_estimators</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     gbrt.fit(X_train, y_train)</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     y_pred = gbrt.predict(X_val)</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     val_error = mean_squared_error(y_val, y_pred)</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     if val_error &lt; min_val_error:</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...         min_val_error = val_error</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...         error_going_up = 0</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...     else:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...         error_going_up += 1</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...         if error_going_up == 10:</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">...             break  # early stopping</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The GradientBoostingRegressor also supports a subsample hyperparameter, which specifies the fraction of </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances to be used for training each tree. For example, if subsample=0.25, then each tree is </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained on 25% of the training instances, selected randomly. As you can probably guess, this trades a higher </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bias for a lower variance. It also speeds up training considerably. This technique is called stochastic </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gradient boosting.</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">It is worth noting that it is possible to use other cost functions than the mean squared error. You control </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">this using the loss hyperparameter. Table 7-1 lists the available options.</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Table 7-1. Cost functions for GradientBoostingRegressor</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loss    Description</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">squared_error   Mean Squared Error (default)</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">absolute_error  Mean Absolute Error</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">huber   Combination of the two; uses squared error for small errors and absolute error for large errors</span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">quantile        Cost function for quantile regression (use alpha to specify the quantile)</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Tip: HistGradientBoosting</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn 1.0 introduced two new classes for gradient boosting: HistGradientBoostingClassifier and </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">HistGradientBoostingRegressor. They are very similar to GradientBoostingClassifier and </span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">GradientBoostingRegressor, except they can be much faster, especially when the training set is large: indeed,</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">this implementation bins the inputs (like a preprocessing step), and it looks at these bins rather than at </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the exact values. This also makes it possible to support categorical features. Moreover, when building the </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision trees, it uses a much faster technique to find the best split at each node. This implementation was </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inspired by LightGBM,17 a very popular gradient boosting library.</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To use it, you must first install scikit-learn-intelex; this will install the Intel Extension for </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-learn, which contains optimized versions of many Scikit-Learn algorithms, including these two new </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gradient boosting classes.</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">import sklearnex</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sklearnex.patch_sklearn()</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import HistGradientBoostingRegressor</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hist_gbrt = HistGradientBoostingRegressor(random_state=42)</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hist_gbrt.fit(X_train, y_train)</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">This implementation offers several other advantages: for example, it supports missing values (no need for </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">imputation). For much more information, see the Scikit-Learn documentation.</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">There are also other implementations of gradient boosting, such as XGBoost, which used to be available via </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the xgboost Python library. It offers several nice features, such as automatically taking care of </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regularization (e.g., L1 or L2 regularization). And CatBoost is another popular gradient boosting library, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which is particularly good at handling categorical features. Both XGBoost and CatBoost are available via </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">their own Python libraries, and they are easy to install. These libraries also offer many other features, </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">including GPU acceleration; you should definitely check them out! Moreover, the TensorFlow Random Forests </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">library provides optimized implementations of a variety of random forest algorithms, including plain random </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forests, extra-trees, GBRT, and several more.</span>                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Stacking</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The last ensemble method we will discuss in this chapter is called stacking (short for</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacked generalization).18 It is based on a simple idea: instead of using trivial functions</span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(such as hard voting) to aggregate the predictions of all predictors in an ensemble,</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">why don’t we train a model to perform this aggregation? Figure 7-11 shows such an</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble performing a regression task on a new instance. Each of the bottom three</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors predicts a different value (3.1, 2.7, and 2.9), and then the final predictor</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(called a blender, or a meta learner) takes these predictions as inputs and makes the</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">final prediction (3.0).</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To train the blender, you first need to build the blending training set. You can</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">use cross_val_predict() on every predictor in the ensemble to get out-of-sample</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictions for each instance in the original training set (Figure 7-12), and use these</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can be used as the input features to train the blender; and the targets can simply be</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">copied from the original training set. Note that regardless of the number of features</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in the original training set (just one in this example), the blending training set will</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">contain one input feature per predictor (three in this example). Once the blender is</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained, the base predictors are retrained one last time on the full original training set.</span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">It is actually possible to train several different blenders this way (e.g., one using linear</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regression, another using random forest regression) to get a whole layer of blenders,</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and then add another blender on top of that to produce the final prediction, as shown</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">in Figure 7-13. You may be able to squeeze out a few more drops of performance by</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">doing this, but it will cost you in both training time and system complexity.</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn provides two classes for stacking ensembles: StackingClassifier and</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">StackingRegressor. For example, we can replace the VotingClassifier we used at</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the beginning of this chapter on the moons dataset with a StackingClassifier:</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from sklearn.ensemble import StackingClassifier</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacking_clf = StackingClassifier(</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    estimators=[</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ('lr', LogisticRegression(random_state=42)),</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ('rf', RandomForestClassifier(random_state=42)),</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ('svc', SVC(probability=True, random_state=42))</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    ],</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    final_estimator=RandomForestClassifier(random_state=43),</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    cv=5  # number of cross-validation folds</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">)</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stacking_clf.fit(X_train, y_train)</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">For each predictor, the stacking classifier will call predict_proba() if available; if not</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it will fall back to decision_function() or, as a last resort, call predict(). If you</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">don’t provide a final estimator, StackingClassifier will use LogisticRegression</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and StackingRegressor will use RidgeCV.</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">If you evaluate this stacking model on the test set, you will find 92.8% accuracy,</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which is a bit better than the voting classifier using soft voting, which got 92%.</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In conclusion, ensemble methods are versatile, powerful, and fairly simple to use.</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Random forests, AdaBoost, and GBRT are among the first models you should test for</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">most machine learning tasks, and they particularly shine with heterogeneous tabular</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">data. Moreover, as they require very little preprocessing, they’re great for getting a</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prototype up and running quickly. Lastly, ensemble methods like voting classifiers</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and stacking classifiers can help push your system’s performance to its limits.</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mCourse Structuring and Summarization Agent\u001b[0m                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mYou are tasked with converting the provided course context into a structured JSON format, ready for \u001b[0m     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpresentation slides.\u001b[0m                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m🎯 Target Audience:\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Age Group: ('20-22',)\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Experience Level: advanced\u001b[0m                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m📋 Instructions:\u001b[0m                                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m1. Analyze and understand the provided course material thoroughly.\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m2. Identify major **topics or chapters** based on the flow of the content.\u001b[0m                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m3. Break down each topic into **sessions** (or subtopics).\u001b[0m                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m4. Summarize the content of each session using **bullet points**.\u001b[0m                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m5. Adapt the tone and depth of content to match the **target audience**:\u001b[0m                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m   - Use engaging, simple, and example-rich language for younger or beginner users.\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m   - Use technical and detailed language for experienced or advanced learners.\u001b[0m                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m6. Return the output in the following **strict JSON format**:\u001b[0m                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m{\u001b[0m                                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  \"course_title\": \"...\",\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  \"topics\": [\u001b[0m                                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m      \"topic_title\": \"...\",\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m          \"session_title\": \"...\",\u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m            \"Bullet point 1\",\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m            \"Bullet point 2\",\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m            \"...\"\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m    }\u001b[0m                                                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  ]\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m}\u001b[0m                                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m⚠️ Ensure the JSON is clean, coherent, and free of missing or redundant information.\u001b[0m                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Course Structuring and Summarization Agent</span>                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">You are tasked with converting the provided course context into a structured JSON format, ready for </span>     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">presentation slides.</span>                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">🎯 Target Audience:</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Age Group: ('20-22',)</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Experience Level: advanced</span>                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">📋 Instructions:</span>                                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. Analyze and understand the provided course material thoroughly.</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. Identify major **topics or chapters** based on the flow of the content.</span>                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3. Break down each topic into **sessions** (or subtopics).</span>                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">4. Summarize the content of each session using **bullet points**.</span>                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">5. Adapt the tone and depth of content to match the **target audience**:</span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Use engaging, simple, and example-rich language for younger or beginner users.</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">   - Use technical and detailed language for experienced or advanced learners.</span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">6. Return the output in the following **strict JSON format**:</span>                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">{</span>                                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"course_title\": \"...\",</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"topics\": [</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"...\",</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"...\",</span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bullet point 1\",</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bullet point 2\",</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"...\"</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    }</span>                                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  ]</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">}</span>                                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">⚠️ Ensure the JSON is clean, coherent, and free of missing or redundant information.</span>                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mCourse Structuring and Summarization Agent\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m```json\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m  \"course_title\": \"Ensemble Learning and Random Forests\",\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m  \"topics\": [\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Introduction to Ensemble Learning\",\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"The Wisdom of the Crowd\",\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Aggregating predictions from a group of predictors (an ensemble) often yields better results \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthan individual predictors.\",\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Ensemble methods are frequently used towards the end of a project to refine existing good \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors.\",\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Winning solutions in machine learning competitions often involve ensemble methods.\"\u001b[0m               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Common Ensemble Methods\",\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Voting Classifiers: Aggregate predictions based on majority voting.\",\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Bagging and Pasting: Train predictors on different random subsets of the training data.\",\u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Random Forests: Ensemble of decision trees, often trained via bagging.\",\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Boosting: Sequentially train predictors, each correcting its predecessor (e.g., AdaBoost, \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mGradient Boosting).\",\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Stacking: Train a model to aggregate the predictions of other models.\"\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    },\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Voting Classifiers\",\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Hard Voting Classifier\",\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Aggregate predictions of multiple classifiers; the class with the most votes is the ensemble's \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mprediction.\",\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Can achieve higher accuracy than the best individual classifier, even with weak learners.\",\u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Requires a sufficient number of diverse weak learners.\",\u001b[0m                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Diversity can be achieved by using different training algorithms.\"\u001b[0m                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Law of Large Numbers Analogy\",\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Analogy with a biased coin toss: as the number of tosses increases, the ratio of heads \u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mapproaches the probability of heads.\",\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Ensemble methods benefit from independent predictors to improve accuracy.\"\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"VotingClassifier in Scikit-Learn\",\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Scikit-Learn's VotingClassifier class simplifies the implementation of voting classifiers.\",\u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Requires a list of named estimators and specification of hard or soft voting.\"\u001b[0m                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    },\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Bagging and Pasting\",\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Basic Concepts\",\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Bagging: Training instances are sampled with replacement (bootstrap aggregating).\",\u001b[0m               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Pasting: Training instances are sampled without replacement.\",\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Both allow training instances to be sampled multiple times across predictors.\",\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Bagging allows training instances to be sampled multiple times for the same predictor.\"\u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Aggregation and Parallelization\",\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Predictions are aggregated using the statistical mode (classification) or average \u001b[0m                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m(regression).\",\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Bagging and pasting can be parallelized, making them scalable.\",\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Individual predictors have higher bias, but aggregation reduces both bias and variance.\"\u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Bagging and Pasting in Scikit-Learn\",\u001b[0m                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"BaggingClassifier (or BaggingRegressor) class provides a simple API.\",\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Example: training an ensemble of 500 decision tree classifiers on 100 randomly sampled instances\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwith replacement.\",\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"The n_jobs parameter controls the number of CPU cores used.\",\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Bagging often results in better models due to increased diversity.\"\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Out-of-Bag Evaluation\",\u001b[0m                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Approximately 37% of training instances are not sampled for each predictor (out-of-bag or OOB \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances).\",\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"OOB instances can be used to evaluate the ensemble without a separate validation set.\",\u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Set oob_score=True in BaggingClassifier to request OOB evaluation.\",\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"oob_decision_function_ variable provides class probabilities from OOB instances.\"\u001b[0m                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Random Patches and Random Subspaces\",\u001b[0m                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"BaggingClassifier supports sampling features using max_features and bootstrap_features.\",\u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Random patches method: sampling both training instances and features.\",\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Random subspaces method: keeping all training instances but sampling features.\",\u001b[0m                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Feature sampling increases predictor diversity, trading bias for lower variance.\"\u001b[0m                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    },\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Random Forests\",\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Random Forest Overview\",\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Ensemble of decision trees, typically trained via bagging.\",\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Can use RandomForestClassifier (or RandomForestRegressor for regression).\",\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Has hyperparameters of both DecisionTreeClassifier and BaggingClassifier.\",\u001b[0m                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Introduces extra randomness by searching for the best feature among a random subset of features \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mat each node.\"\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Feature Importance\",\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Random forests provide a measure of feature importance.\",\u001b[0m                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Importance is determined by how much tree nodes using a feature reduce impurity on average.\",\u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Scikit-Learn computes this score automatically and makes it available via \u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfeature_importances_.\",\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Useful for understanding which features matter and for feature selection.\"\u001b[0m                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    },\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Boosting\",\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Boosting Overview\",\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Combines several weak learners into a strong learner.\",\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Trains predictors sequentially, each trying to correct its predecessor.\",\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Popular methods: AdaBoost and Gradient Boosting.\"\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"AdaBoost\",\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"New predictors pay more attention to instances that the predecessor underfit.\",\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Increases the relative weight of misclassified training instances.\",\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Each predictor has a weight based on its accuracy.\",\u001b[0m                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Predictions are made by weighing the predictions of all predictors.\",\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Scikit-Learn uses SAMME (multiclass version of AdaBoost).\",\u001b[0m                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"SAMME.R relies on class probabilities and generally performs better.\",\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"AdaBoostClassifier can be trained using Scikit-Learn.\",\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"If the ensemble underfits, increase the number of estimators or reduce regularization.\"\u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Gradient Boosting\",\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Sequentially adds predictors to an ensemble, each correcting its predecessor.\",\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Fits the new predictor to the residual errors made by the previous predictor.\",\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Gradient Tree Boosting (Gradient Boosted Regression Trees - GBRT) uses decision trees as \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors.\",\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Scikit-Learn's GradientBoostingRegressor class can be used to train GBRT ensembles.\",\u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"The learning_rate hyperparameter scales each tree's contribution (shrinkage).\",\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Early stopping can be used to find the optimal number of trees.\"\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Gradient Boosting - Advanced Techniques\",\u001b[0m                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"staged_predict() method returns an iterator over predictions at each stage of training.\",\u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"warm_start=True allows resuming training from the previous state for early stopping.\",\u001b[0m            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"The subsample hyperparameter specifies the fraction of training instances used for training each\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtree (stochastic gradient boosting).\",\u001b[0m                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"loss hyperparameter controls the cost function (e.g., squared_error, absolute_error, huber, \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mquantile).\"\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"HistGradientBoosting\",\u001b[0m                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"HistGradientBoostingClassifier and HistGradientBoostingRegressor are faster, especially with \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mlarge datasets.\",\u001b[0m                                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Bins the inputs and looks at these bins rather than exact values.\",\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Supports categorical features and uses a faster technique to find the best split.\",\u001b[0m               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Requires installing scikit-learn-intelex.\",\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Offers advantages like support for missing values.\"\u001b[0m                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Other Gradient Boosting Implementations\",\u001b[0m                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"XGBoost: Offers features like automatic regularization.\",\u001b[0m                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"CatBoost: Good at handling categorical features.\",\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"TensorFlow Random Forests: Provides optimized implementations of various random forest \u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92malgorithms.\",\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"These libraries offer GPU acceleration.\"\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    },\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Stacking\",\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Stacking Overview\",\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Trains a model (blender or meta learner) to aggregate the predictions of other predictors.\",\u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"The blender takes the predictions of the base predictors as inputs and makes the final \u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mprediction.\",\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Requires building a blending training set using out-of-sample predictions from the base \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors.\"\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Training the Blender\",\u001b[0m                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Use cross_val_predict() on every predictor in the ensemble to get out-of-sample predictions.\",\u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Use these predictions as input features to train the blender.\",\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Targets are copied from the original training set.\",\u001b[0m                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Base predictors are retrained one last time on the full original training set.\"\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Multi-Layer Stacking\",\u001b[0m                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Train several different blenders to get a whole layer of blenders.\",\u001b[0m                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Add another blender on top of that to produce the final prediction.\",\u001b[0m                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"May squeeze out more performance but increases training time and complexity.\"\u001b[0m                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        },\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Stacking in Scikit-Learn\",\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"StackingClassifier and StackingRegressor classes are available.\",\u001b[0m                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Example: replacing VotingClassifier with StackingClassifier.\",\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"StackingClassifier calls predict_proba() if available, otherwise falls back to \u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdecision_function() or predict().\",\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"If no final estimator is provided, LogisticRegression (for classification) or RidgeCV (for \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregression) is used.\"\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    },\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    {\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"topic_title\": \"Conclusion\",\u001b[0m                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      \"sessions\": [\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        {\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"session_title\": \"Summary\",\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          \"content\": [\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Ensemble methods are versatile, powerful, and simple to use.\",\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Random forests, AdaBoost, and GBRT are among the first models to test.\",\u001b[0m                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"They shine with heterogeneous tabular data and require little preprocessing.\",\u001b[0m                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            \"Voting classifiers and stacking classifiers can help push system performance to its limits.\"\u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m          ]\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m      ]\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    }\u001b[0m                                                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m  ]\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Course Structuring and Summarization Agent</span>                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```json</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"course_title\": \"Ensemble Learning and Random Forests\",</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"topics\": [</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Introduction to Ensemble Learning\",</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"The Wisdom of the Crowd\",</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Aggregating predictions from a group of predictors (an ensemble) often yields better results </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">than individual predictors.\",</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Ensemble methods are frequently used towards the end of a project to refine existing good </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors.\",</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Winning solutions in machine learning competitions often involve ensemble methods.\"</span>               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Common Ensemble Methods\",</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Voting Classifiers: Aggregate predictions based on majority voting.\",</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bagging and Pasting: Train predictors on different random subsets of the training data.\",</span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Random Forests: Ensemble of decision trees, often trained via bagging.\",</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Boosting: Sequentially train predictors, each correcting its predecessor (e.g., AdaBoost, </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Gradient Boosting).\",</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Stacking: Train a model to aggregate the predictions of other models.\"</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    },</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Voting Classifiers\",</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Hard Voting Classifier\",</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Aggregate predictions of multiple classifiers; the class with the most votes is the ensemble's </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prediction.\",</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Can achieve higher accuracy than the best individual classifier, even with weak learners.\",</span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Requires a sufficient number of diverse weak learners.\",</span>                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Diversity can be achieved by using different training algorithms.\"</span>                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Law of Large Numbers Analogy\",</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Analogy with a biased coin toss: as the number of tosses increases, the ratio of heads </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">approaches the probability of heads.\",</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Ensemble methods benefit from independent predictors to improve accuracy.\"</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"VotingClassifier in Scikit-Learn\",</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Scikit-Learn's VotingClassifier class simplifies the implementation of voting classifiers.\",</span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Requires a list of named estimators and specification of hard or soft voting.\"</span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    },</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Bagging and Pasting\",</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Basic Concepts\",</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bagging: Training instances are sampled with replacement (bootstrap aggregating).\",</span>               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Pasting: Training instances are sampled without replacement.\",</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Both allow training instances to be sampled multiple times across predictors.\",</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bagging allows training instances to be sampled multiple times for the same predictor.\"</span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Aggregation and Parallelization\",</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Predictions are aggregated using the statistical mode (classification) or average </span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">(regression).\",</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bagging and pasting can be parallelized, making them scalable.\",</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Individual predictors have higher bias, but aggregation reduces both bias and variance.\"</span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Bagging and Pasting in Scikit-Learn\",</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"BaggingClassifier (or BaggingRegressor) class provides a simple API.\",</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Example: training an ensemble of 500 decision tree classifiers on 100 randomly sampled instances</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with replacement.\",</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"The n_jobs parameter controls the number of CPU cores used.\",</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bagging often results in better models due to increased diversity.\"</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Out-of-Bag Evaluation\",</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Approximately 37% of training instances are not sampled for each predictor (out-of-bag or OOB </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances).\",</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"OOB instances can be used to evaluate the ensemble without a separate validation set.\",</span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Set oob_score=True in BaggingClassifier to request OOB evaluation.\",</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"oob_decision_function_ variable provides class probabilities from OOB instances.\"</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Random Patches and Random Subspaces\",</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"BaggingClassifier supports sampling features using max_features and bootstrap_features.\",</span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Random patches method: sampling both training instances and features.\",</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Random subspaces method: keeping all training instances but sampling features.\",</span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Feature sampling increases predictor diversity, trading bias for lower variance.\"</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    },</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Random Forests\",</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Random Forest Overview\",</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Ensemble of decision trees, typically trained via bagging.\",</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Can use RandomForestClassifier (or RandomForestRegressor for regression).\",</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Has hyperparameters of both DecisionTreeClassifier and BaggingClassifier.\",</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Introduces extra randomness by searching for the best feature among a random subset of features </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">at each node.\"</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Feature Importance\",</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Random forests provide a measure of feature importance.\",</span>                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Importance is determined by how much tree nodes using a feature reduce impurity on average.\",</span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Scikit-Learn computes this score automatically and makes it available via </span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">feature_importances_.\",</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Useful for understanding which features matter and for feature selection.\"</span>                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    },</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Boosting\",</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Boosting Overview\",</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Combines several weak learners into a strong learner.\",</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Trains predictors sequentially, each trying to correct its predecessor.\",</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Popular methods: AdaBoost and Gradient Boosting.\"</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"AdaBoost\",</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"New predictors pay more attention to instances that the predecessor underfit.\",</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Increases the relative weight of misclassified training instances.\",</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Each predictor has a weight based on its accuracy.\",</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Predictions are made by weighing the predictions of all predictors.\",</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Scikit-Learn uses SAMME (multiclass version of AdaBoost).\",</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"SAMME.R relies on class probabilities and generally performs better.\",</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"AdaBoostClassifier can be trained using Scikit-Learn.\",</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"If the ensemble underfits, increase the number of estimators or reduce regularization.\"</span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Gradient Boosting\",</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Sequentially adds predictors to an ensemble, each correcting its predecessor.\",</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Fits the new predictor to the residual errors made by the previous predictor.\",</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Gradient Tree Boosting (Gradient Boosted Regression Trees - GBRT) uses decision trees as </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors.\",</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Scikit-Learn's GradientBoostingRegressor class can be used to train GBRT ensembles.\",</span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"The learning_rate hyperparameter scales each tree's contribution (shrinkage).\",</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Early stopping can be used to find the optimal number of trees.\"</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Gradient Boosting - Advanced Techniques\",</span>                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"staged_predict() method returns an iterator over predictions at each stage of training.\",</span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"warm_start=True allows resuming training from the previous state for early stopping.\",</span>            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"The subsample hyperparameter specifies the fraction of training instances used for training each</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tree (stochastic gradient boosting).\",</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"loss hyperparameter controls the cost function (e.g., squared_error, absolute_error, huber, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">quantile).\"</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"HistGradientBoosting\",</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"HistGradientBoostingClassifier and HistGradientBoostingRegressor are faster, especially with </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">large datasets.\",</span>                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Bins the inputs and looks at these bins rather than exact values.\",</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Supports categorical features and uses a faster technique to find the best split.\",</span>               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Requires installing scikit-learn-intelex.\",</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Offers advantages like support for missing values.\"</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Other Gradient Boosting Implementations\",</span>                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"XGBoost: Offers features like automatic regularization.\",</span>                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"CatBoost: Good at handling categorical features.\",</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"TensorFlow Random Forests: Provides optimized implementations of various random forest </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">algorithms.\",</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"These libraries offer GPU acceleration.\"</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    },</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Stacking\",</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Stacking Overview\",</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Trains a model (blender or meta learner) to aggregate the predictions of other predictors.\",</span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"The blender takes the predictions of the base predictors as inputs and makes the final </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prediction.\",</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Requires building a blending training set using out-of-sample predictions from the base </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors.\"</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Training the Blender\",</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Use cross_val_predict() on every predictor in the ensemble to get out-of-sample predictions.\",</span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Use these predictions as input features to train the blender.\",</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Targets are copied from the original training set.\",</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Base predictors are retrained one last time on the full original training set.\"</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Multi-Layer Stacking\",</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Train several different blenders to get a whole layer of blenders.\",</span>                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Add another blender on top of that to produce the final prediction.\",</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"May squeeze out more performance but increases training time and complexity.\"</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        },</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Stacking in Scikit-Learn\",</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"StackingClassifier and StackingRegressor classes are available.\",</span>                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Example: replacing VotingClassifier with StackingClassifier.\",</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"StackingClassifier calls predict_proba() if available, otherwise falls back to </span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision_function() or predict().\",</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"If no final estimator is provided, LogisticRegression (for classification) or RidgeCV (for </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regression) is used.\"</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    },</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    {</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"topic_title\": \"Conclusion\",</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      \"sessions\": [</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        {</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"session_title\": \"Summary\",</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          \"content\": [</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Ensemble methods are versatile, powerful, and simple to use.\",</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Random forests, AdaBoost, and GBRT are among the first models to test.\",</span>                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"They shine with heterogeneous tabular data and require little preprocessing.\",</span>                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            \"Voting classifiers and stacking classifiers can help push system performance to its limits.\"</span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">          ]</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">      ]</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    }</span>                                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  ]</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mBullet Point PowerPoint Specialist\u001b[0m                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mTake the JSON output from the previous step and generate a PowerPoint presentation. Include a title \u001b[0m     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mslide with the course name and audience info, then one slide per session with session titles and content.\u001b[0m      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Bullet Point PowerPoint Specialist</span>                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Take the JSON output from the previous step and generate a PowerPoint presentation. Include a title </span>     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">slide with the course name and audience info, then one slide per session with session titles and content.</span>      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m╭─\u001b[0m\u001b[35m───────────────────────────────────────────\u001b[0m\u001b[35m 🔧 Agent Tool Execution \u001b[0m\u001b[35m───────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mBullet Point PowerPoint Specialist\u001b[0m                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mThought: \u001b[0m\u001b[92mOkay, I will convert the provided JSON data into a PowerPoint presentation. The presentation will \u001b[0m    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92minclude a title slide, an agenda slide, and slides for each session with bullet points summarizing the \u001b[0m        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mcontent. I will use the `generate_pptx_from_json` tool to create the PowerPoint file.\u001b[0m                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mUsing Tool: \u001b[0m\u001b[1;92mgenerate_pptx_from_json\u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭──────────────────────────────────────────── 🔧 Agent Tool Execution ────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Bullet Point PowerPoint Specialist</span>                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Thought: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Okay, I will convert the provided JSON data into a PowerPoint presentation. The presentation will </span>    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">include a title slide, an agenda slide, and slides for each session with bullet points summarizing the </span>        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">content. I will use the `generate_pptx_from_json` tool to create the PowerPoint file.</span>                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Using Tool: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">generate_pptx_from_json</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────────\u001b[0m\u001b[34m Tool Input \u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
              "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
              "\u001b[34m│\u001b[0m  \u001b[38;2;230;219;116;49m\"{\\\"json_data\\\": {\\\"course_title\\\": \\\"Ensemble Learning and Random Forests\\\", \\\"topics\\\": [{\\\"topic_title\\\": \u001b[0m  \u001b[34m│\u001b[0m\n",
              "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
              "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────────── Tool Input ───────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #ffffff\">\"{\\\"json_data\\\": {\\\"course_title\\\": \\\"Ensemble Learning and Random Forests\\\", \\\"topics\\\": [{\\\"topic_title\\\": </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
              "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────────────────\u001b[0m\u001b[32m Tool Output \u001b[0m\u001b[32m─────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m✅ PowerPoint saved as 'course_presentation.pptx' with multi-page agenda and structured slides.\u001b[0m                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────────────────── Tool Output ──────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">✅ PowerPoint saved as 'course_presentation.pptx' with multi-page agenda and structured slides.</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mBullet Point PowerPoint Specialist\u001b[0m                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mPowerPoint saved as 'course_presentation.pptx' with multi-page agenda and structured slides.\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Bullet Point PowerPoint Specialist</span>                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">PowerPoint saved as 'course_presentation.pptx' with multi-page agenda and structured slides.</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mNarrative Creator\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m                                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYou are a highly skilled educational content narrator.\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYour goal is to generate an engaging, easy-to-follow narrative that reflects the structure of a PowerPoint \u001b[0m    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mpresentation and expands on the key points.\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m---\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mCourse Title: classical machine learning\u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mCourse Description: An introduction to core machine learning algorithms like regression, classification, and \u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mclustering, focusing on their concepts and practical applications.\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mAudience Age Group: ('20-22',)\u001b[0m                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mTeaching Style: Motivational storytelling\u001b[0m                                                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mLanguage: English\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m---\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mPresentation Slide Outline:\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mNone\u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRaw Content for This Section:\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mNone\u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m---\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m🎯 Instructions:\u001b[0m                                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mWrite a **structured educational narrative** that includes estimated **time durations** for each part. Format\u001b[0m  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mit so it can be used as a **video script**.\u001b[0m                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mFor each section, include:\u001b[0m                                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m1. **[Duration: ~X min]** at the beginning of the paragraph.\u001b[0m                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m2. A clear and age-appropriate **introduction** to the topic.\u001b[0m                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m3. A **step-by-step walkthrough** of each key point or slide element, reflecting the `presentation`.\u001b[0m           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m4. A **real-world example or analogy** to make the topic relatable.\u001b[0m                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m5. A **brief conclusion** connecting the lesson back to the overall course goal.\u001b[0m                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m💡 Tone & Style:\u001b[0m                                                                                               \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Match the teaching style: Motivational storytelling\u001b[0m                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Language: English\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Use age-appropriate vocabulary and structure based on the audience age: ('20-22',)\u001b[0m                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Ensure logical flow aligned with the slide sequence\u001b[0m                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Avoid excessive technical jargon unless intended for advanced audiences\u001b[0m                                      \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m🕒 Example Output Structure:\u001b[0m                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction  \u001b[0m                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m[Duration: ~2 min] Slide 1 Explanation  \u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m[Duration: ~2 min] Slide 2 Explanation  \u001b[0m                                                                       \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m[Duration: ~1 min] Real-World Analogy  \u001b[0m                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m[Duration: ~1 min] Conclusion\u001b[0m                                                                                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m---\u001b[0m                                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mReturn only the narrative in plain text, clearly structured with headings and time estimates.\u001b[0m                  \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Narrative Creator</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span>                                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You are a highly skilled educational content narrator.</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Your goal is to generate an engaging, easy-to-follow narrative that reflects the structure of a PowerPoint </span>    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">presentation and expands on the key points.</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">---</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Course Title: classical machine learning</span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Course Description: An introduction to core machine learning algorithms like regression, classification, and </span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clustering, focusing on their concepts and practical applications.</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Audience Age Group: ('20-22',)</span>                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Teaching Style: Motivational storytelling</span>                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Language: English</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">---</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Presentation Slide Outline:</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">None</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Raw Content for This Section:</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">None</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">---</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">🎯 Instructions:</span>                                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Write a **structured educational narrative** that includes estimated **time durations** for each part. Format</span>  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">it so it can be used as a **video script**.</span>                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">For each section, include:</span>                                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">1. **[Duration: ~X min]** at the beginning of the paragraph.</span>                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">2. A clear and age-appropriate **introduction** to the topic.</span>                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">3. A **step-by-step walkthrough** of each key point or slide element, reflecting the `presentation`.</span>           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">4. A **real-world example or analogy** to make the topic relatable.</span>                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">5. A **brief conclusion** connecting the lesson back to the overall course goal.</span>                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">💡 Tone &amp; Style:</span>                                                                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Match the teaching style: Motivational storytelling</span>                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Language: English</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Use age-appropriate vocabulary and structure based on the audience age: ('20-22',)</span>                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Ensure logical flow aligned with the slide sequence</span>                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Avoid excessive technical jargon unless intended for advanced audiences</span>                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">🕒 Example Output Structure:</span>                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction  </span>                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Slide 1 Explanation  </span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Slide 2 Explanation  </span>                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Real-World Analogy  </span>                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Conclusion</span>                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">---</span>                                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Return only the narrative in plain text, clearly structured with headings and time estimates.</span>                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mNarrative Creator\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m```text\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction to Ensemble Learning and Random Forests\u001b[0m                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mHey everyone, welcome! Today, we're diving into the exciting world of ensemble learning and random forests. \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mImagine you're trying to solve a really tough problem. Would you rely on just one person's opinion, or would \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92myou ask a group of people and combine their insights? That's the core idea behind ensemble learning: \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcombining multiple \"learners\" to create a super-smart system. We'll explore how this approach can \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msignificantly boost the accuracy and robustness of our machine learning models. Get ready to level up your ML\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mskills!\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] The Wisdom of the Crowd\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mLet's start with a fascinating concept: the wisdom of the crowd. Think about it – if you ask a complex \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mquestion to thousands of random people and then aggregate their answers, you'll often find that the combined \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92manswer is better than what any single expert could come up with. In machine learning, we do something \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msimilar. We aggregate the predictions of a group of predictors – these could be classifiers or regressors – \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand, more often than not, we get better predictions than we would from the best individual predictor. This \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgroup of predictors is called an ensemble, and the technique is known as ensemble learning. It's like having \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma team of experts working together! Ensemble methods are particularly useful towards the end of a project, \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwhen you want to squeeze out every last bit of performance from your models. You'll often see ensemble \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmethods used in winning solutions in machine learning competitions.\u001b[0m                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Common Ensemble Methods\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSo, what are some of these ensemble methods? We'll be covering a few key ones today:\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m*   **Voting Classifiers**: These aggregate predictions based on majority voting. It's like a democratic \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mprocess for your machine learning models!\u001b[0m                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m*   **Bagging and Pasting**: These methods train predictors on different random subsets of the training data.\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThink of it as each predictor getting a slightly different perspective on the problem.\u001b[0m                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m*   **Random Forests**: These are ensembles of decision trees, often trained using a technique called \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbagging. They're powerful and versatile.\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m*   **Boosting**: This involves sequentially training predictors, with each one trying to correct the \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmistakes of its predecessor. It's like learning from your errors, but for machines! Examples include AdaBoost\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand Gradient Boosting.\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m*   **Stacking**: This is a more advanced technique where we train a model to aggregate the predictions of \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mother models. It's like having a meta-learner that knows how to combine the strengths of different models.\u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction to Voting Classifiers\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNow, let's dive deeper into our first ensemble method: voting classifiers. Imagine you've trained a few \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdifferent classifiers, each with around 80% accuracy. You might have a logistic regression classifier, an SVM\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifier, a random forest classifier, and maybe a k-nearest neighbors classifier. How can we combine these \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mto get even better results?\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Hard Voting Classifier\u001b[0m                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOne simple way is to aggregate the predictions of each classifier. The class that gets the most votes becomes\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe ensemble's prediction. This is called a hard voting classifier. Surprisingly, this voting classifier \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92moften achieves higher accuracy than the best individual classifier in the ensemble. Even if each classifier \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mis a weak learner – meaning it performs only slightly better than random guessing – the ensemble can still be\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma strong learner, as long as there are enough diverse weak learners. Diversity is key here. We want our \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifiers to make different kinds of mistakes so that the ensemble can correct them. This diversity can be \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92machieved by using different training algorithms.\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Law of Large Numbers Analogy\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mHow is it possible that combining weak learners can create a strong learner? Let's use an analogy: imagine \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92myou have a slightly biased coin with a 51% chance of landing heads and a 49% chance of landing tails. If you \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtoss it 1,000 times, you'll generally get more or less 510 heads and 490 tails, resulting in a majority of \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mheads. The probability of obtaining a majority of heads after 1,000 tosses is close to 75%. The more you toss\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe coin, the higher the probability climbs. This is due to the law of large numbers: as you keep tossing the\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcoin, the ratio of heads gets closer and closer to the true probability of heads (51%). Similarly, in \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble methods, as we combine more and more diverse predictors, the errors tend to cancel each other out, \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mleading to a more accurate overall prediction.\u001b[0m                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] VotingClassifier in Scikit-Learn\u001b[0m                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn makes it easy to implement voting classifiers with the `VotingClassifier` class. All you need to\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdo is provide a list of named estimators – that is, the individual classifiers you want to combine – and \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mspecify whether you want hard or soft voting. It's that simple!\u001b[0m                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction to Bagging and Pasting\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNext, let's explore bagging and pasting. These are two closely related techniques for training multiple \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors on different subsets of the training data.\u001b[0m                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Basic Concepts of Bagging and Pasting\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe main idea behind bagging and pasting is to introduce diversity by training each predictor on a different \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mrandom subset of the training set. In bagging, sampling is performed with replacement. This means that a \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msingle training instance can be selected multiple times for the same predictor. This is also known as \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbootstrap aggregating. In pasting, sampling is performed without replacement. This means that once a training\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstance is selected, it can't be selected again for the same predictor. Both bagging and pasting allow \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining instances to be sampled several times across multiple predictors, but only bagging allows training \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances to be sampled several times for the same predictor.\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Aggregation and Parallelization in Bagging and Pasting\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOnce all the predictors are trained, the ensemble can make predictions for new instances by simply \u001b[0m            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92maggregating the predictions of all the predictors. For classification, the aggregation function is typically \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe statistical mode – that is, the most frequent prediction, just like with a hard voting classifier. For \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregression, the aggregation function is typically the average. One of the great things about bagging and \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpasting is that the predictors can all be trained in parallel, using different CPU cores or even different \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mservers. This makes them highly scalable. While each individual predictor has a higher bias than if it were \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrained on the original training set, the aggregation process reduces both bias and variance, leading to \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbetter overall performance.\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Bagging and Pasting in Scikit-Learn\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn provides a simple API for both bagging and pasting through the `BaggingClassifier` class (or \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m`BaggingRegressor` for regression). You can train an ensemble of, say, 500 decision tree classifiers, each \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrained on 100 training instances randomly sampled from the training set with replacement. This is an example\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mof bagging. If you want to use pasting instead, you simply set `bootstrap=False`. The `n_jobs` parameter \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtells Scikit-Learn how many CPU cores to use for training and predictions. Setting it to -1 tells \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn to use all available cores. Bagging often results in better models than pasting because it \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mintroduces more diversity in the subsets that each predictor is trained on. This extra diversity means that \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe predictors end up being less correlated, which reduces the ensemble's variance.\u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Out-of-Bag Evaluation\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mWith bagging, some training instances may be sampled several times for any given predictor, while others may \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnot be sampled at all. On average, about 63% of the training instances are sampled for each predictor. The \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mremaining 37% of the training instances that are not sampled are called out-of-bag (OOB) instances. These OOB\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances can be used to evaluate the ensemble without the need for a separate validation set. In \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn, you can set `oob_score=True` when creating a `BaggingClassifier` to request an automatic OOB \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mevaluation after training. The `oob_decision_function_` variable provides the class probabilities that each \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining instance received on average from the estimators that did not see it during training.\u001b[0m                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Random Patches and Random Subspaces\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe `BaggingClassifier` class also supports sampling the features as well as the training instances. This is \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcontrolled by two hyperparameters: `max_features` and `bootstrap_features`. They work just like `max_samples`\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand `bootstrap`, but for feature sampling instead of instance sampling. Sampling both training instances and \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfeatures is called the random patches method. Keeping all training instances but sampling features is called \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe random subspaces method. Sampling features results in even more predictor diversity, trading a bit more \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbias for a lower variance.\u001b[0m                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction to Random Forests\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mNow, let's move on to random forests. As we've discussed, a random forest is an ensemble of decision trees, \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgenerally trained via the bagging method.\u001b[0m                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Random Forest Overview\u001b[0m                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mInstead of building a `BaggingClassifier` and passing it a `DecisionTreeClassifier`, you can use the \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m`RandomForestClassifier` class (or `RandomForestRegressor` for regression tasks). A `RandomForestClassifier` \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhas all the hyperparameters of a `DecisionTreeClassifier` (to control how the trees are grown), plus all the \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhyperparameters of a `BaggingClassifier` (to control the ensemble itself). The random forest algorithm \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mintroduces extra randomness when growing trees. Instead of searching for the very best feature when splitting\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92ma node, it searches for the best feature among a random subset of features. This results in even greater tree\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdiversity, which trades a higher bias for a lower variance, generally yielding an overall better model.\u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Feature Importance in Random Forests\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOne of the great qualities of random forests is that they make it easy to measure the relative importance of \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92meach feature. Scikit-Learn measures a feature's importance by looking at how much the tree nodes that use \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthat feature reduce impurity on average across all trees in the forest. This score is computed automatically \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfor each feature after training and is available via the `feature_importances_` variable. Random forests are \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mvery handy for getting a quick understanding of what features actually matter, especially if you need to \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mperform feature selection.\u001b[0m                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction to Boosting\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mLet's shift gears and talk about boosting. Boosting refers to any ensemble method that can combine several \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mweak learners into a strong learner.\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Boosting Overview\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe general idea behind most boosting methods is to train predictors sequentially, with each one trying to \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcorrect its predecessor. There are many boosting methods available, but the most popular are AdaBoost and \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mGradient Boosting.\u001b[0m                                                                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] AdaBoost\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOne way for a new predictor to correct its predecessor is to pay more attention to the training instances \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthat the predecessor underfit. This is the technique used by AdaBoost. The algorithm first trains a base \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifier (such as a decision tree) and uses it to make predictions on the training set. Then, it increases \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe relative weight of misclassified training instances. It then trains a second classifier, using the \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mupdated weights, and repeats the process. Each predictor has a weight that depends on its accuracy on the \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mweighted training set. The more accurate the predictor is, the higher its weight will be. To make \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictions, AdaBoost simply computes the predictions of all the predictors and weighs them using the \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor weights. The predicted class is the one that receives the majority of weighted votes. Scikit-Learn \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92muses a multiclass version of AdaBoost called SAMME. If the predictors can estimate class probabilities, \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn can use a variant of SAMME called SAMME.R, which relies on class probabilities and generally \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mperforms better.\u001b[0m                                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Gradient Boosting\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAnother very popular boosting algorithm is gradient boosting. Just like AdaBoost, gradient boosting works by \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msequentially adding predictors to an ensemble, with each one correcting its predecessor. However, instead of \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor to the residual errors made by the previous predictor. This is called Gradient Tree Boosting, or \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mGradient Boosted Regression Trees (GBRT) when decision trees are used as predictors. You can use \u001b[0m              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn's `GradientBoostingRegressor` class to train GBRT ensembles. A key hyperparameter is the \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m`learning_rate`, which scales each tree's contribution. Setting it to a low value requires more trees but \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92musually leads to better generalization. This is a regularization technique called shrinkage.\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Gradient Boosting - Advanced Techniques\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTo find the optimal number of trees, you can use early stopping. The `staged_predict()` method returns an \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92miterator over the predictions made by the ensemble at each stage of training. You can also implement early \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mstopping by interrupting training when the validation error does not improve for a number of iterations, \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92musing `warm_start=True`. The `subsample` hyperparameter specifies the fraction of training instances to be \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mused for training each tree, trading higher bias for lower variance. This is called stochastic gradient \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mboosting.\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] HistGradientBoosting\u001b[0m                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn 1.0 introduced `HistGradientBoostingClassifier` and `HistGradientBoostingRegressor`, which are \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfaster, especially with large datasets. They bin the inputs and look at these bins rather than exact values, \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msupport categorical features, and use a faster technique to find the best split.\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Other Gradient Boosting Implementations\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mOther popular gradient boosting libraries include XGBoost and CatBoost, which offer features like automatic \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregularization and good handling of categorical features. The TensorFlow Random Forests library provides \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92moptimized implementations of various random forest algorithms.\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Introduction to Stacking\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mFinally, let's discuss stacking, which stands for stacked generalization.\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~2 min] Stacking Overview\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThe idea behind stacking is simple: instead of using trivial functions (such as hard voting) to aggregate the\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictions of all predictors in an ensemble, why don't we train a model to perform this aggregation? This \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minvolves training a blender (or meta learner) that takes the predictions of the base predictors as inputs and\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmakes the final prediction.\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Training the Blender\u001b[0m                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mTo train the blender, you first need to build a blending training set. You can use `cross_val_predict()` on \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mevery predictor in the ensemble to get out-of-sample predictions for each instance in the original training \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mset. These predictions are then used as input features to train the blender, and the targets are copied from \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe original training set. The base predictors are then retrained one last time on the full original training\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mset.\u001b[0m                                                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Multi-Layer Stacking\u001b[0m                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mYou can even train several different blenders to get a whole layer of blenders, and then add another blender \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mon top of that to produce the final prediction. This may squeeze out more performance but increases training \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtime and complexity.\u001b[0m                                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Stacking in Scikit-Learn\u001b[0m                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn provides `StackingClassifier` and `StackingRegressor` classes. The `StackingClassifier` calls \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m`predict_proba()` if available, otherwise falls back to `decision_function()` or `predict()`. If no final \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mestimator is provided, `LogisticRegression` (for classification) or `RidgeCV` (for regression) is used.\u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m[Duration: ~1 min] Conclusion\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIn conclusion, ensemble methods are versatile, powerful, and fairly simple to use. Random forests, AdaBoost, \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mand GBRT are among the first models you should test for most machine learning tasks. They shine with \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mheterogeneous tabular data and require little preprocessing. Voting classifiers and stacking classifiers can \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhelp push your system's performance to its limits. Thanks for joining me today, and happy machine learning!\u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Narrative Creator</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```text</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction to Ensemble Learning and Random Forests</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Hey everyone, welcome! Today, we're diving into the exciting world of ensemble learning and random forests. </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Imagine you're trying to solve a really tough problem. Would you rely on just one person's opinion, or would </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you ask a group of people and combine their insights? That's the core idea behind ensemble learning: </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">combining multiple \"learners\" to create a super-smart system. We'll explore how this approach can </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">significantly boost the accuracy and robustness of our machine learning models. Get ready to level up your ML</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">skills!</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] The Wisdom of the Crowd</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Let's start with a fascinating concept: the wisdom of the crowd. Think about it – if you ask a complex </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">question to thousands of random people and then aggregate their answers, you'll often find that the combined </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">answer is better than what any single expert could come up with. In machine learning, we do something </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">similar. We aggregate the predictions of a group of predictors – these could be classifiers or regressors – </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and, more often than not, we get better predictions than we would from the best individual predictor. This </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">group of predictors is called an ensemble, and the technique is known as ensemble learning. It's like having </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a team of experts working together! Ensemble methods are particularly useful towards the end of a project, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">when you want to squeeze out every last bit of performance from your models. You'll often see ensemble </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">methods used in winning solutions in machine learning competitions.</span>                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Common Ensemble Methods</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">So, what are some of these ensemble methods? We'll be covering a few key ones today:</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">*   **Voting Classifiers**: These aggregate predictions based on majority voting. It's like a democratic </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">process for your machine learning models!</span>                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">*   **Bagging and Pasting**: These methods train predictors on different random subsets of the training data.</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Think of it as each predictor getting a slightly different perspective on the problem.</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">*   **Random Forests**: These are ensembles of decision trees, often trained using a technique called </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bagging. They're powerful and versatile.</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">*   **Boosting**: This involves sequentially training predictors, with each one trying to correct the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mistakes of its predecessor. It's like learning from your errors, but for machines! Examples include AdaBoost</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and Gradient Boosting.</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">*   **Stacking**: This is a more advanced technique where we train a model to aggregate the predictions of </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">other models. It's like having a meta-learner that knows how to combine the strengths of different models.</span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction to Voting Classifiers</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now, let's dive deeper into our first ensemble method: voting classifiers. Imagine you've trained a few </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">different classifiers, each with around 80% accuracy. You might have a logistic regression classifier, an SVM</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifier, a random forest classifier, and maybe a k-nearest neighbors classifier. How can we combine these </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to get even better results?</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Hard Voting Classifier</span>                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One simple way is to aggregate the predictions of each classifier. The class that gets the most votes becomes</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the ensemble's prediction. This is called a hard voting classifier. Surprisingly, this voting classifier </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">often achieves higher accuracy than the best individual classifier in the ensemble. Even if each classifier </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is a weak learner – meaning it performs only slightly better than random guessing – the ensemble can still be</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a strong learner, as long as there are enough diverse weak learners. Diversity is key here. We want our </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifiers to make different kinds of mistakes so that the ensemble can correct them. This diversity can be </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">achieved by using different training algorithms.</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Law of Large Numbers Analogy</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">How is it possible that combining weak learners can create a strong learner? Let's use an analogy: imagine </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you have a slightly biased coin with a 51% chance of landing heads and a 49% chance of landing tails. If you </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">toss it 1,000 times, you'll generally get more or less 510 heads and 490 tails, resulting in a majority of </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">heads. The probability of obtaining a majority of heads after 1,000 tosses is close to 75%. The more you toss</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the coin, the higher the probability climbs. This is due to the law of large numbers: as you keep tossing the</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">coin, the ratio of heads gets closer and closer to the true probability of heads (51%). Similarly, in </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble methods, as we combine more and more diverse predictors, the errors tend to cancel each other out, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">leading to a more accurate overall prediction.</span>                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] VotingClassifier in Scikit-Learn</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn makes it easy to implement voting classifiers with the `VotingClassifier` class. All you need to</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">do is provide a list of named estimators – that is, the individual classifiers you want to combine – and </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">specify whether you want hard or soft voting. It's that simple!</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction to Bagging and Pasting</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Next, let's explore bagging and pasting. These are two closely related techniques for training multiple </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors on different subsets of the training data.</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Basic Concepts of Bagging and Pasting</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The main idea behind bagging and pasting is to introduce diversity by training each predictor on a different </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">random subset of the training set. In bagging, sampling is performed with replacement. This means that a </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">single training instance can be selected multiple times for the same predictor. This is also known as </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bootstrap aggregating. In pasting, sampling is performed without replacement. This means that once a training</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance is selected, it can't be selected again for the same predictor. Both bagging and pasting allow </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances to be sampled several times across multiple predictors, but only bagging allows training </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances to be sampled several times for the same predictor.</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Aggregation and Parallelization in Bagging and Pasting</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Once all the predictors are trained, the ensemble can make predictions for new instances by simply </span>            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aggregating the predictions of all the predictors. For classification, the aggregation function is typically </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the statistical mode – that is, the most frequent prediction, just like with a hard voting classifier. For </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regression, the aggregation function is typically the average. One of the great things about bagging and </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pasting is that the predictors can all be trained in parallel, using different CPU cores or even different </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">servers. This makes them highly scalable. While each individual predictor has a higher bias than if it were </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained on the original training set, the aggregation process reduces both bias and variance, leading to </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">better overall performance.</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Bagging and Pasting in Scikit-Learn</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn provides a simple API for both bagging and pasting through the `BaggingClassifier` class (or </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`BaggingRegressor` for regression). You can train an ensemble of, say, 500 decision tree classifiers, each </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained on 100 training instances randomly sampled from the training set with replacement. This is an example</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of bagging. If you want to use pasting instead, you simply set `bootstrap=False`. The `n_jobs` parameter </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tells Scikit-Learn how many CPU cores to use for training and predictions. Setting it to -1 tells </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn to use all available cores. Bagging often results in better models than pasting because it </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">introduces more diversity in the subsets that each predictor is trained on. This extra diversity means that </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the predictors end up being less correlated, which reduces the ensemble's variance.</span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Out-of-Bag Evaluation</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">With bagging, some training instances may be sampled several times for any given predictor, while others may </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">not be sampled at all. On average, about 63% of the training instances are sampled for each predictor. The </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">remaining 37% of the training instances that are not sampled are called out-of-bag (OOB) instances. These OOB</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances can be used to evaluate the ensemble without the need for a separate validation set. In </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn, you can set `oob_score=True` when creating a `BaggingClassifier` to request an automatic OOB </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation after training. The `oob_decision_function_` variable provides the class probabilities that each </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instance received on average from the estimators that did not see it during training.</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Random Patches and Random Subspaces</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The `BaggingClassifier` class also supports sampling the features as well as the training instances. This is </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">controlled by two hyperparameters: `max_features` and `bootstrap_features`. They work just like `max_samples`</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and `bootstrap`, but for feature sampling instead of instance sampling. Sampling both training instances and </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">features is called the random patches method. Keeping all training instances but sampling features is called </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the random subspaces method. Sampling features results in even more predictor diversity, trading a bit more </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bias for a lower variance.</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction to Random Forests</span>                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now, let's move on to random forests. As we've discussed, a random forest is an ensemble of decision trees, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generally trained via the bagging method.</span>                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Random Forest Overview</span>                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Instead of building a `BaggingClassifier` and passing it a `DecisionTreeClassifier`, you can use the </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`RandomForestClassifier` class (or `RandomForestRegressor` for regression tasks). A `RandomForestClassifier` </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">has all the hyperparameters of a `DecisionTreeClassifier` (to control how the trees are grown), plus all the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hyperparameters of a `BaggingClassifier` (to control the ensemble itself). The random forest algorithm </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">introduces extra randomness when growing trees. Instead of searching for the very best feature when splitting</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">a node, it searches for the best feature among a random subset of features. This results in even greater tree</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">diversity, which trades a higher bias for a lower variance, generally yielding an overall better model.</span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Feature Importance in Random Forests</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One of the great qualities of random forests is that they make it easy to measure the relative importance of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each feature. Scikit-Learn measures a feature's importance by looking at how much the tree nodes that use </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">that feature reduce impurity on average across all trees in the forest. This score is computed automatically </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for each feature after training and is available via the `feature_importances_` variable. Random forests are </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">very handy for getting a quick understanding of what features actually matter, especially if you need to </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">perform feature selection.</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction to Boosting</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Let's shift gears and talk about boosting. Boosting refers to any ensemble method that can combine several </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weak learners into a strong learner.</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Boosting Overview</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The general idea behind most boosting methods is to train predictors sequentially, with each one trying to </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">correct its predecessor. There are many boosting methods available, but the most popular are AdaBoost and </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Gradient Boosting.</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] AdaBoost</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">One way for a new predictor to correct its predecessor is to pay more attention to the training instances </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">that the predecessor underfit. This is the technique used by AdaBoost. The algorithm first trains a base </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifier (such as a decision tree) and uses it to make predictions on the training set. Then, it increases </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the relative weight of misclassified training instances. It then trains a second classifier, using the </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">updated weights, and repeats the process. Each predictor has a weight that depends on its accuracy on the </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weighted training set. The more accurate the predictor is, the higher its weight will be. To make </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictions, AdaBoost simply computes the predictions of all the predictors and weighs them using the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor weights. The predicted class is the one that receives the majority of weighted votes. Scikit-Learn </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">uses a multiclass version of AdaBoost called SAMME. If the predictors can estimate class probabilities, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn can use a variant of SAMME called SAMME.R, which relies on class probabilities and generally </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">performs better.</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Gradient Boosting</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Another very popular boosting algorithm is gradient boosting. Just like AdaBoost, gradient boosting works by </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sequentially adding predictors to an ensemble, with each one correcting its predecessor. However, instead of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the new </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor to the residual errors made by the previous predictor. This is called Gradient Tree Boosting, or </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Gradient Boosted Regression Trees (GBRT) when decision trees are used as predictors. You can use </span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn's `GradientBoostingRegressor` class to train GBRT ensembles. A key hyperparameter is the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`learning_rate`, which scales each tree's contribution. Setting it to a low value requires more trees but </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">usually leads to better generalization. This is a regularization technique called shrinkage.</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Gradient Boosting - Advanced Techniques</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To find the optimal number of trees, you can use early stopping. The `staged_predict()` method returns an </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">iterator over the predictions made by the ensemble at each stage of training. You can also implement early </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">stopping by interrupting training when the validation error does not improve for a number of iterations, </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">using `warm_start=True`. The `subsample` hyperparameter specifies the fraction of training instances to be </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">used for training each tree, trading higher bias for lower variance. This is called stochastic gradient </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">boosting.</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] HistGradientBoosting</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn 1.0 introduced `HistGradientBoostingClassifier` and `HistGradientBoostingRegressor`, which are </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">faster, especially with large datasets. They bin the inputs and look at these bins rather than exact values, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">support categorical features, and use a faster technique to find the best split.</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Other Gradient Boosting Implementations</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Other popular gradient boosting libraries include XGBoost and CatBoost, which offer features like automatic </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regularization and good handling of categorical features. The TensorFlow Random Forests library provides </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimized implementations of various random forest algorithms.</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Introduction to Stacking</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Finally, let's discuss stacking, which stands for stacked generalization.</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~2 min] Stacking Overview</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The idea behind stacking is simple: instead of using trivial functions (such as hard voting) to aggregate the</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictions of all predictors in an ensemble, why don't we train a model to perform this aggregation? This </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">involves training a blender (or meta learner) that takes the predictions of the base predictors as inputs and</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">makes the final prediction.</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Training the Blender</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To train the blender, you first need to build a blending training set. You can use `cross_val_predict()` on </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">every predictor in the ensemble to get out-of-sample predictions for each instance in the original training </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set. These predictions are then used as input features to train the blender, and the targets are copied from </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the original training set. The base predictors are then retrained one last time on the full original training</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set.</span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Multi-Layer Stacking</span>                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You can even train several different blenders to get a whole layer of blenders, and then add another blender </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on top of that to produce the final prediction. This may squeeze out more performance but increases training </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">time and complexity.</span>                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Stacking in Scikit-Learn</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn provides `StackingClassifier` and `StackingRegressor` classes. The `StackingClassifier` calls </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`predict_proba()` if available, otherwise falls back to `decision_function()` or `predict()`. If no final </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">estimator is provided, `LogisticRegression` (for classification) or `RidgeCV` (for regression) is used.</span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">[Duration: ~1 min] Conclusion</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">In conclusion, ensemble methods are versatile, powerful, and fairly simple to use. Random forests, AdaBoost, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and GBRT are among the first models you should test for most machine learning tasks. They shine with </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">heterogeneous tabular data and require little preprocessing. Voting classifiers and stacking classifiers can </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">help push your system's performance to its limits. Thanks for joining me today, and happy machine learning!</span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mNarrative Customizer\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m                                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mYou are an expert educational narrative editor and HTML formatter.\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mHere is the original narrative:\u001b[0m                                                                                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mNone\u001b[0m                                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mRevise it according to the following:\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Writing Style: Motivational storytelling\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Language: English\u001b[0m                                                                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Desired Length: Detailed explanation with example (e.g., short summary, in-depth walkthrough)\u001b[0m                \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m🎯 Output Instructions:\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Format the final output in **clean, well-structured HTML**\u001b[0m                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Use a **black-and-white color scheme** (purely grayscale)\u001b[0m                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Use appropriate HTML tags:\u001b[0m                                                                                   \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - <h1> for the main title\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - <h2> for section headers (e.g., \"Introduction\", \"Key Concepts\", \"Real-World Example\", \"Conclusion\")\u001b[0m        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - Add a small estimated duration under each section header (e.g., <small>~2 minutes</small>)\u001b[0m                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - <p> for paragraphs\u001b[0m                                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - <ul><li> for bullet points (if needed)\u001b[0m                                                                     \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Wrap the output in complete HTML including <html>, <head>, <body>\u001b[0m                                            \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Apply this CSS:\u001b[0m                                                                                              \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - Body: white background, black text\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - Font: Helvetica, Arial, sans-serif\u001b[0m                                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - No borders, no background colors\u001b[0m                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m  - Clean layout suitable for printing and web reading\u001b[0m                                                         \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m🚫 Do NOT include:\u001b[0m                                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Any markdown\u001b[0m                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Instructional text\u001b[0m                                                                                           \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m- Extra commentary outside of HTML\u001b[0m                                                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92m📄 This content will be saved into a `narrative.html` file and viewed in a web browser.\u001b[0m                        \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m  \u001b[92mReturn only the complete HTML file, properly formatted and styled.\u001b[0m                                             \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
              "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Narrative Customizer</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span>                                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">You are an expert educational narrative editor and HTML formatter.</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Here is the original narrative:</span>                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">None</span>                                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Revise it according to the following:</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Writing Style: Motivational storytelling</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Language: English</span>                                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Desired Length: Detailed explanation with example (e.g., short summary, in-depth walkthrough)</span>                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">🎯 Output Instructions:</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Format the final output in **clean, well-structured HTML**</span>                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Use a **black-and-white color scheme** (purely grayscale)</span>                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Use appropriate HTML tags:</span>                                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - &lt;h1&gt; for the main title</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - &lt;h2&gt; for section headers (e.g., \"Introduction\", \"Key Concepts\", \"Real-World Example\", \"Conclusion\")</span>        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - Add a small estimated duration under each section header (e.g., &lt;small&gt;~2 minutes&lt;/small&gt;)</span>                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - &lt;p&gt; for paragraphs</span>                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - &lt;ul&gt;&lt;li&gt; for bullet points (if needed)</span>                                                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Wrap the output in complete HTML including &lt;html&gt;, &lt;head&gt;, &lt;body&gt;</span>                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Apply this CSS:</span>                                                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - Body: white background, black text</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - Font: Helvetica, Arial, sans-serif</span>                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - No borders, no background colors</span>                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  - Clean layout suitable for printing and web reading</span>                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">🚫 Do NOT include:</span>                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Any markdown</span>                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Instructional text</span>                                                                                           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">- Extra commentary outside of HTML</span>                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">📄 This content will be saved into a `narrative.html` file and viewed in a web browser.</span>                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Return only the complete HTML file, properly formatted and styled.</span>                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mNarrative Customizer\u001b[0m                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m```html\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<!DOCTYPE html>\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<html lang=\"en\">\u001b[0m                                                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<head>\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <meta charset=\"UTF-8\">\u001b[0m                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <title>Ensemble Learning and Random Forests</title>\u001b[0m                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <style>\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        body {\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            background-color: white;\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            color: black;\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            font-family: Helvetica, Arial, sans-serif;\u001b[0m                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            margin: 20px;\u001b[0m                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            line-height: 1.6;\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        h1 {\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            font-size: 2.5em;\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            margin-bottom: 0.5em;\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            color: rgb(50,50,50);\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        h2 {\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            font-size: 1.8em;\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            margin-top: 1.5em;\u001b[0m                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            margin-bottom: 0.5em;\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            color: rgb(70,70,70);\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        p {\u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            margin-bottom: 1em;\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            color: rgb(90,90,90);\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        ul {\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            margin-bottom: 1em;\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        li {\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            color: rgb(90,90,90);\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        small {\u001b[0m                                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            font-size: 0.8em;\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m            color: rgb(110,110,110);\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        }\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    </style>\u001b[0m                                                                                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m</head>\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<body>\u001b[0m                                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h1>Ensemble Learning and Random Forests</h1>\u001b[0m                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Introduction to Ensemble Learning <small>~1 minute</small></h2>\u001b[0m                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        Hey everyone, welcome! Today, we're diving into the exciting world of ensemble learning and random \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mforests. Imagine you're trying to solve a really tough problem. Would you rely on just one person's opinion, \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mor would you ask a group of people and combine their insights? That's the core idea behind ensemble learning:\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcombining multiple \"learners\" to create a super-smart system. We'll explore how this approach can \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msignificantly boost the accuracy and robustness of our machine learning models. Get ready to level up your ML\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mskills!\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    </p>\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>The Wisdom of the Crowd <small>~2 minutes</small></h2>\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        Let's start with a fascinating concept: the wisdom of the crowd. Think about it – if you ask a \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcomplex question to thousands of random people and then aggregate their answers, you'll often find that the \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcombined answer is better than what any single expert could come up with. In machine learning, we do \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msomething similar. We aggregate the predictions of a group of predictors – these could be classifiers or \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregressors – and, more often than not, we get better predictions than we would from the best individual \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor. This group of predictors is called an ensemble, and the technique is known as ensemble learning. \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIt's like having a team of experts working together! Ensemble methods are particularly useful towards the end\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mof a project, when you want to squeeze out every last bit of performance from your models. You'll often see \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble methods used in winning solutions in machine learning competitions.\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    </p>\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Common Ensemble Methods <small>~1 minute</small></h2>\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>So, what are some of these ensemble methods? We'll be covering a few key ones today:</p>\u001b[0m                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <ul>\u001b[0m                                                                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        <li><b>Voting Classifiers</b>: These aggregate predictions based on majority voting. It's like a \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdemocratic process for your machine learning models!</li>\u001b[0m                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        <li><b>Bagging and Pasting</b>: These methods train predictors on different random subsets of the \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining data. Think of it as each predictor getting a slightly different perspective on the problem.</li>\u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        <li><b>Random Forests</b>: These are ensembles of decision trees, often trained using a technique \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcalled bagging. They're powerful and versatile.</li>\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        <li><b>Boosting</b>: This involves sequentially training predictors, with each one trying to correct \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe mistakes of its predecessor. It's like learning from your errors, but for machines! Examples include \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAdaBoost and Gradient Boosting.</li>\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m        <li><b>Stacking</b>: This is a more advanced technique where we train a model to aggregate the \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictions of other models. It's like having a meta-learner that knows how to combine the strengths of \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdifferent models.</li>\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    </ul>\u001b[0m                                                                                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Introduction to Voting Classifiers <small>~1 minute</small></h2>\u001b[0m                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Now, let's dive deeper into our first ensemble method: voting classifiers. Imagine you've trained a \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfew different classifiers, each with around 80% accuracy. You might have a logistic regression classifier, an\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSVM classifier, a random forest classifier, and maybe a k-nearest neighbors classifier. How can we combine \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthese to get even better results?</p>\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Hard Voting Classifier <small>~2 minutes</small></h2>\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>One simple way is to aggregate the predictions of each classifier. The class that gets the most votes \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbecomes the ensemble's prediction. This is called a hard voting classifier. Surprisingly, this voting \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifier often achieves higher accuracy than the best individual classifier in the ensemble. Even if each \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclassifier is a weak learner – meaning it performs only slightly better than random guessing – the ensemble \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcan still be a strong learner, as long as there are enough diverse weak learners. Diversity is key here. We \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwant our classifiers to make different kinds of mistakes so that the ensemble can correct them. This \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdiversity can be achieved by using different training algorithms.</p>\u001b[0m                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Law of Large Numbers Analogy <small>~1 minute</small></h2>\u001b[0m                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>How is it possible that combining weak learners can create a strong learner? Let's use an analogy: \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimagine you have a slightly biased coin with a 51% chance of landing heads and a 49% chance of landing tails.\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mIf you toss it 1,000 times, you'll generally get more or less 510 heads and 490 tails, resulting in a \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmajority of heads. The probability of obtaining a majority of heads after 1,000 tosses is close to 75%. The \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmore you toss the coin, the higher the probability climbs. This is due to the law of large numbers: as you \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mkeep tossing the coin, the ratio of heads gets closer and closer to the true probability of heads (51%). \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mSimilarly, in ensemble methods, as we combine more and more diverse predictors, the errors tend to cancel \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92meach other out, leading to a more accurate overall prediction.</p>\u001b[0m                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>VotingClassifier in Scikit-Learn <small>~1 minute</small></h2>\u001b[0m                                         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Scikit-Learn makes it easy to implement voting classifiers with the <code>VotingClassifier</code> \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mclass. All you need to do is provide a list of named estimators – that is, the individual classifiers you \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwant to combine – and specify whether you want hard or soft voting. It's that simple!</p>\u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Introduction to Bagging and Pasting <small>~1 minute</small></h2>\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Next, let's explore bagging and pasting. These are two closely related techniques for training \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmultiple predictors on different subsets of the training data.</p>\u001b[0m                                             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Basic Concepts of Bagging and Pasting <small>~2 minutes</small></h2>\u001b[0m                                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>The main idea behind bagging and pasting is to introduce diversity by training each predictor on a \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mdifferent random subset of the training set. In bagging, sampling is performed with replacement. This means \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthat a single training instance can be selected multiple times for the same predictor. This is also known as \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbootstrap aggregating. In pasting, sampling is performed without replacement. This means that once a training\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstance is selected, it can't be selected again for the same predictor. Both bagging and pasting allow \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining instances to be sampled several times across multiple predictors, but only bagging allows training \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances to be sampled several times for the same predictor.</p>\u001b[0m                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Aggregation and Parallelization in Bagging and Pasting <small>~1 minute</small></h2>\u001b[0m                   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Once all the predictors are trained, the ensemble can make predictions for new instances by simply \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92maggregating the predictions of all the predictors. For classification, the aggregation function is typically \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe statistical mode – that is, the most frequent prediction, just like with a hard voting classifier. For \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mregression, the aggregation function is typically the average. One of the great things about bagging and \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpasting is that the predictors can all be trained in parallel, using different CPU cores or even different \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mservers. This makes them highly scalable. While each individual predictor has a higher bias than if it were \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrained on the original training set, the aggregation process reduces both bias and variance, leading to \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbetter overall performance.</p>\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Bagging and Pasting in Scikit-Learn <small>~2 minutes</small></h2>\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Scikit-Learn provides a simple API for both bagging and pasting through the \u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>BaggingClassifier</code> class (or <code>BaggingRegressor</code> for regression). You can train an \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mensemble of, say, 500 decision tree classifiers, each trained on 100 training instances randomly sampled from\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe training set with replacement. This is an example of bagging. If you want to use pasting instead, you \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msimply set <code>bootstrap=False</code>. The <code>n_jobs</code> parameter tells Scikit-Learn how many CPU \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcores to use for training and predictions. Setting it to -1 tells Scikit-Learn to use all available cores. \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mBagging often results in better models than pasting because it introduces more diversity in the subsets that \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92meach predictor is trained on. This extra diversity means that the predictors end up being less correlated, \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwhich reduces the ensemble's variance.</p>\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Out-of-Bag Evaluation <small>~1 minute</small></h2>\u001b[0m                                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>With bagging, some training instances may be sampled several times for any given predictor, while \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mothers may not be sampled at all. On average, about 63% of the training instances are sampled for each \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor. The remaining 37% of the training instances that are not sampled are called out-of-bag (OOB) \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances. These OOB instances can be used to evaluate the ensemble without the need for a separate \u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mvalidation set. In Scikit-Learn, you can set <code>oob_score=True</code> when creating a \u001b[0m                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>BaggingClassifier</code> to request an automatic OOB evaluation after training. The \u001b[0m                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>oob_decision_function_</code> variable provides the class probabilities that each training instance \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mreceived on average from the estimators that did not see it during training.</p>\u001b[0m                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Random Patches and Random Subspaces <small>~1 minute</small></h2>\u001b[0m                                      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>The <code>BaggingClassifier</code> class also supports sampling the features as well as the training \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances. This is controlled by two hyperparameters: <code>max_features</code> and \u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>bootstrap_features</code>. They work just like <code>max_samples</code> and <code>bootstrap</code>, but\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfor feature sampling instead of instance sampling. Sampling both training instances and features is called \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe random patches method. Keeping all training instances but sampling features is called the random \u001b[0m          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msubspaces method. Sampling features results in even more predictor diversity, trading a bit more bias for a \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mlower variance.</p>\u001b[0m                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Introduction to Random Forests <small>~1 minute</small></h2>\u001b[0m                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Now, let's move on to random forests. As we've discussed, a random forest is an ensemble of decision \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrees, generally trained via the bagging method.</p>\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Random Forest Overview <small>~2 minutes</small></h2>\u001b[0m                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Instead of building a <code>BaggingClassifier</code> and passing it a \u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>DecisionTreeClassifier</code>, you can use the <code>RandomForestClassifier</code> class (or \u001b[0m            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>RandomForestRegressor</code> for regression tasks). A <code>RandomForestClassifier</code> has all the \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhyperparameters of a <code>DecisionTreeClassifier</code> (to control how the trees are grown), plus all the \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mhyperparameters of a <code>BaggingClassifier</code> (to control the ensemble itself). The random forest \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92malgorithm introduces extra randomness when growing trees. Instead of searching for the very best feature when\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92msplitting a node, it searches for the best feature among a random subset of features. This results in even \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mgreater tree diversity, which trades a higher bias for a lower variance, generally yielding an overall better\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmodel.</p>\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Feature Importance in Random Forests <small>~1 minute</small></h2>\u001b[0m                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>One of the great qualities of random forests is that they make it easy to measure the relative \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimportance of each feature. Scikit-Learn measures a feature's importance by looking at how much the tree \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnodes that use that feature reduce impurity on average across all trees in the forest. This score is computed\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mautomatically for each feature after training and is available via the <code>feature_importances_</code> \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mvariable. Random forests are very handy for getting a quick understanding of what features actually matter, \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mespecially if you need to perform feature selection.</p>\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Introduction to Boosting <small>~1 minute</small></h2>\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Let's shift gears and talk about boosting. Boosting refers to any ensemble method that can combine \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mseveral weak learners into a strong learner.</p>\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Boosting Overview <small>~2 minutes</small></h2>\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>The general idea behind most boosting methods is to train predictors sequentially, with each one \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtrying to correct its predecessor. There are many boosting methods available, but the most popular are \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAdaBoost and Gradient Boosting.</p>\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>AdaBoost <small>~2 minutes</small></h2>\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>One way for a new predictor to correct its predecessor is to pay more attention to the training \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstances that the predecessor underfit. This is the technique used by AdaBoost. The algorithm first trains a\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mbase classifier (such as a decision tree) and uses it to make predictions on the training set. Then, it \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mincreases the relative weight of misclassified training instances. It then trains a second classifier, using \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe updated weights, and repeats the process. Each predictor has a weight that depends on its accuracy on the\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mweighted training set. The more accurate the predictor is, the higher its weight will be. To make \u001b[0m             \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictions, AdaBoost simply computes the predictions of all the predictors and weighs them using the \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictor weights. The predicted class is the one that receives the majority of weighted votes. Scikit-Learn \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92muses a multiclass version of AdaBoost called SAMME. If the predictors can estimate class probabilities, \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn can use a variant of SAMME called SAMME.R, which relies on class probabilities and generally \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mperforms better.</p>\u001b[0m                                                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Gradient Boosting <small>~2 minutes</small></h2>\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Another very popular boosting algorithm is gradient boosting. Just like AdaBoost, gradient boosting \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mworks by sequentially adding predictors to an ensemble, with each one correcting its predecessor. However, \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mnew predictor to the residual errors made by the previous predictor. This is called Gradient Tree Boosting, \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mor Gradient Boosted Regression Trees (GBRT) when decision trees are used as predictors. You can use \u001b[0m           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mScikit-Learn's <code>GradientBoostingRegressor</code> class to train GBRT ensembles. A key hyperparameter is \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mthe <code>learning_rate</code>, which scales each tree's contribution. Setting it to a low value requires \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmore trees but usually leads to better generalization. This is a regularization technique called \u001b[0m              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mshrinkage.</p>\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Gradient Boosting - Advanced Techniques <small>~1 minute</small></h2>\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>To find the optimal number of trees, you can use early stopping. The <code>staged_predict()</code> \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mmethod returns an iterator over the predictions made by the ensemble at each stage of training. You can also \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mimplement early stopping by interrupting training when the validation error does not improve for a number of \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92miterations, using <code>warm_start=True</code>. The <code>subsample</code> hyperparameter specifies the \u001b[0m       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mfraction of training instances to be used for training each tree, trading higher bias for lower variance. \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mThis is called stochastic gradient boosting.</p>\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>HistGradientBoosting <small>~1 minute</small></h2>\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Scikit-Learn 1.0 introduced <code>HistGradientBoostingClassifier</code> and \u001b[0m                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>HistGradientBoostingRegressor</code>, which are faster, especially with large datasets. They bin the \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minputs and look at these bins rather than exact values, support categorical features, and use a faster \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtechnique to find the best split.</p>\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Other Gradient Boosting Implementations <small>~1 minute</small></h2>\u001b[0m                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Other popular gradient boosting libraries include XGBoost and CatBoost, which offer features like \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mautomatic regularization and good handling of categorical features. The TensorFlow Random Forests library \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mprovides optimized implementations of various random forest algorithms.</p>\u001b[0m                                    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Introduction to Stacking <small>~1 minute</small></h2>\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Finally, let's discuss stacking, which stands for stacked generalization.</p>\u001b[0m                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Stacking Overview <small>~2 minutes</small></h2>\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>The idea behind stacking is simple: instead of using trivial functions (such as hard voting) to \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92maggregate the predictions of all predictors in an ensemble, why don't we train a model to perform this \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92maggregation? This involves training a blender (or meta learner) that takes the predictions of the base \u001b[0m        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mpredictors as inputs and makes the final prediction.</p>\u001b[0m                                                       \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Training the Blender <small>~1 minute</small></h2>\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>To train the blender, you first need to build a blending training set. You can use \u001b[0m                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>cross_val_predict()</code> on every predictor in the ensemble to get out-of-sample predictions for each\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92minstance in the original training set. These predictions are then used as input features to train the \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mblender, and the targets are copied from the original training set. The base predictors are then retrained \u001b[0m    \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mone last time on the full original training set.</p>\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Multi-Layer Stacking <small>~1 minute</small></h2>\u001b[0m                                                     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>You can even train several different blenders to get a whole layer of blenders, and then add another \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mblender on top of that to produce the final prediction. This may squeeze out more performance but increases \u001b[0m   \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mtraining time and complexity.</p>\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Stacking in Scikit-Learn <small>~1 minute</small></h2>\u001b[0m                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>Scikit-Learn provides <code>StackingClassifier</code> and <code>StackingRegressor</code> classes. The \u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>StackingClassifier</code> calls <code>predict_proba()</code> if available, otherwise falls back to \u001b[0m      \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>decision_function()</code> or <code>predict()</code>. If no final estimator is provided, \u001b[0m                \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m<code>LogisticRegression</code> (for classification) or <code>RidgeCV</code> (for regression) is used.</p>\u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <h2>Conclusion <small>~1 minute</small></h2>\u001b[0m                                                               \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m    <p>In conclusion, ensemble methods are versatile, powerful, and fairly simple to use. Random forests, \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mAdaBoost, and GBRT are among the first models you should test for most machine learning tasks. They shine \u001b[0m     \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mwith heterogeneous tabular data and require little preprocessing. Voting classifiers and stacking classifiers\u001b[0m  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mcan help push your system's performance to its limits. Thanks for joining me today, and happy machine \u001b[0m         \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92mlearning!</p>\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m</body>\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m</html>\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
              "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Narrative Customizer</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```html</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;!DOCTYPE html&gt;</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;html lang=\"en\"&gt;</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;head&gt;</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;meta charset=\"UTF-8\"&gt;</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;title&gt;Ensemble Learning and Random Forests&lt;/title&gt;</span>                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;style&gt;</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        body {</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            background-color: white;</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: black;</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-family: Helvetica, Arial, sans-serif;</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin: 20px;</span>                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            line-height: 1.6;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        h1 {</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-size: 2.5em;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 0.5em;</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: rgb(50,50,50);</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        h2 {</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-size: 1.8em;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-top: 1.5em;</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 0.5em;</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: rgb(70,70,70);</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        p {</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 1em;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: rgb(90,90,90);</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        ul {</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            margin-bottom: 1em;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        li {</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: rgb(90,90,90);</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        small {</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            font-size: 0.8em;</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            color: rgb(110,110,110);</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        }</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/style&gt;</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;/head&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;body&gt;</span>                                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h1&gt;Ensemble Learning and Random Forests&lt;/h1&gt;</span>                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Introduction to Ensemble Learning &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Hey everyone, welcome! Today, we're diving into the exciting world of ensemble learning and random </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forests. Imagine you're trying to solve a really tough problem. Would you rely on just one person's opinion, </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">or would you ask a group of people and combine their insights? That's the core idea behind ensemble learning:</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">combining multiple \"learners\" to create a super-smart system. We'll explore how this approach can </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">significantly boost the accuracy and robustness of our machine learning models. Get ready to level up your ML</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">skills!</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/p&gt;</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;The Wisdom of the Crowd &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Let's start with a fascinating concept: the wisdom of the crowd. Think about it – if you ask a </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">complex question to thousands of random people and then aggregate their answers, you'll often find that the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">combined answer is better than what any single expert could come up with. In machine learning, we do </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">something similar. We aggregate the predictions of a group of predictors – these could be classifiers or </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regressors – and, more often than not, we get better predictions than we would from the best individual </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor. This group of predictors is called an ensemble, and the technique is known as ensemble learning. </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">It's like having a team of experts working together! Ensemble methods are particularly useful towards the end</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">of a project, when you want to squeeze out every last bit of performance from your models. You'll often see </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble methods used in winning solutions in machine learning competitions.</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/p&gt;</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Common Ensemble Methods &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;So, what are some of these ensemble methods? We'll be covering a few key ones today:&lt;/p&gt;</span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;ul&gt;</span>                                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;li&gt;&lt;b&gt;Voting Classifiers&lt;/b&gt;: These aggregate predictions based on majority voting. It's like a </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">democratic process for your machine learning models!&lt;/li&gt;</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;li&gt;&lt;b&gt;Bagging and Pasting&lt;/b&gt;: These methods train predictors on different random subsets of the </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training data. Think of it as each predictor getting a slightly different perspective on the problem.&lt;/li&gt;</span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;li&gt;&lt;b&gt;Random Forests&lt;/b&gt;: These are ensembles of decision trees, often trained using a technique </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">called bagging. They're powerful and versatile.&lt;/li&gt;</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;li&gt;&lt;b&gt;Boosting&lt;/b&gt;: This involves sequentially training predictors, with each one trying to correct </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the mistakes of its predecessor. It's like learning from your errors, but for machines! Examples include </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost and Gradient Boosting.&lt;/li&gt;</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        &lt;li&gt;&lt;b&gt;Stacking&lt;/b&gt;: This is a more advanced technique where we train a model to aggregate the </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictions of other models. It's like having a meta-learner that knows how to combine the strengths of </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">different models.&lt;/li&gt;</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;/ul&gt;</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Introduction to Voting Classifiers &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Now, let's dive deeper into our first ensemble method: voting classifiers. Imagine you've trained a </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">few different classifiers, each with around 80% accuracy. You might have a logistic regression classifier, an</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">SVM classifier, a random forest classifier, and maybe a k-nearest neighbors classifier. How can we combine </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">these to get even better results?&lt;/p&gt;</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Hard Voting Classifier &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;One simple way is to aggregate the predictions of each classifier. The class that gets the most votes </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">becomes the ensemble's prediction. This is called a hard voting classifier. Surprisingly, this voting </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifier often achieves higher accuracy than the best individual classifier in the ensemble. Even if each </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">classifier is a weak learner – meaning it performs only slightly better than random guessing – the ensemble </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can still be a strong learner, as long as there are enough diverse weak learners. Diversity is key here. We </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">want our classifiers to make different kinds of mistakes so that the ensemble can correct them. This </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">diversity can be achieved by using different training algorithms.&lt;/p&gt;</span>                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Law of Large Numbers Analogy &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;How is it possible that combining weak learners can create a strong learner? Let's use an analogy: </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">imagine you have a slightly biased coin with a 51% chance of landing heads and a 49% chance of landing tails.</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">If you toss it 1,000 times, you'll generally get more or less 510 heads and 490 tails, resulting in a </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">majority of heads. The probability of obtaining a majority of heads after 1,000 tosses is close to 75%. The </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">more you toss the coin, the higher the probability climbs. This is due to the law of large numbers: as you </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">keep tossing the coin, the ratio of heads gets closer and closer to the true probability of heads (51%). </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Similarly, in ensemble methods, as we combine more and more diverse predictors, the errors tend to cancel </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each other out, leading to a more accurate overall prediction.&lt;/p&gt;</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;VotingClassifier in Scikit-Learn &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Scikit-Learn makes it easy to implement voting classifiers with the &lt;code&gt;VotingClassifier&lt;/code&gt; </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">class. All you need to do is provide a list of named estimators – that is, the individual classifiers you </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">want to combine – and specify whether you want hard or soft voting. It's that simple!&lt;/p&gt;</span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Introduction to Bagging and Pasting &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Next, let's explore bagging and pasting. These are two closely related techniques for training </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multiple predictors on different subsets of the training data.&lt;/p&gt;</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Basic Concepts of Bagging and Pasting &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;The main idea behind bagging and pasting is to introduce diversity by training each predictor on a </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">different random subset of the training set. In bagging, sampling is performed with replacement. This means </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">that a single training instance can be selected multiple times for the same predictor. This is also known as </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bootstrap aggregating. In pasting, sampling is performed without replacement. This means that once a training</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance is selected, it can't be selected again for the same predictor. Both bagging and pasting allow </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training instances to be sampled several times across multiple predictors, but only bagging allows training </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances to be sampled several times for the same predictor.&lt;/p&gt;</span>                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Aggregation and Parallelization in Bagging and Pasting &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Once all the predictors are trained, the ensemble can make predictions for new instances by simply </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aggregating the predictions of all the predictors. For classification, the aggregation function is typically </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the statistical mode – that is, the most frequent prediction, just like with a hard voting classifier. For </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regression, the aggregation function is typically the average. One of the great things about bagging and </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pasting is that the predictors can all be trained in parallel, using different CPU cores or even different </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">servers. This makes them highly scalable. While each individual predictor has a higher bias than if it were </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trained on the original training set, the aggregation process reduces both bias and variance, leading to </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">better overall performance.&lt;/p&gt;</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Bagging and Pasting in Scikit-Learn &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Scikit-Learn provides a simple API for both bagging and pasting through the </span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;BaggingClassifier&lt;/code&gt; class (or &lt;code&gt;BaggingRegressor&lt;/code&gt; for regression). You can train an </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ensemble of, say, 500 decision tree classifiers, each trained on 100 training instances randomly sampled from</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the training set with replacement. This is an example of bagging. If you want to use pasting instead, you </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">simply set &lt;code&gt;bootstrap=False&lt;/code&gt;. The &lt;code&gt;n_jobs&lt;/code&gt; parameter tells Scikit-Learn how many CPU </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cores to use for training and predictions. Setting it to -1 tells Scikit-Learn to use all available cores. </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Bagging often results in better models than pasting because it introduces more diversity in the subsets that </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">each predictor is trained on. This extra diversity means that the predictors end up being less correlated, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">which reduces the ensemble's variance.&lt;/p&gt;</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Out-of-Bag Evaluation &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;With bagging, some training instances may be sampled several times for any given predictor, while </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">others may not be sampled at all. On average, about 63% of the training instances are sampled for each </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor. The remaining 37% of the training instances that are not sampled are called out-of-bag (OOB) </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances. These OOB instances can be used to evaluate the ensemble without the need for a separate </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validation set. In Scikit-Learn, you can set &lt;code&gt;oob_score=True&lt;/code&gt; when creating a </span>                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;BaggingClassifier&lt;/code&gt; to request an automatic OOB evaluation after training. The </span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;oob_decision_function_&lt;/code&gt; variable provides the class probabilities that each training instance </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">received on average from the estimators that did not see it during training.&lt;/p&gt;</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Random Patches and Random Subspaces &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;The &lt;code&gt;BaggingClassifier&lt;/code&gt; class also supports sampling the features as well as the training </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances. This is controlled by two hyperparameters: &lt;code&gt;max_features&lt;/code&gt; and </span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;bootstrap_features&lt;/code&gt;. They work just like &lt;code&gt;max_samples&lt;/code&gt; and &lt;code&gt;bootstrap&lt;/code&gt;, but</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for feature sampling instead of instance sampling. Sampling both training instances and features is called </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the random patches method. Keeping all training instances but sampling features is called the random </span>          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">subspaces method. Sampling features results in even more predictor diversity, trading a bit more bias for a </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">lower variance.&lt;/p&gt;</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Introduction to Random Forests &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Now, let's move on to random forests. As we've discussed, a random forest is an ensemble of decision </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trees, generally trained via the bagging method.&lt;/p&gt;</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Random Forest Overview &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Instead of building a &lt;code&gt;BaggingClassifier&lt;/code&gt; and passing it a </span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;DecisionTreeClassifier&lt;/code&gt;, you can use the &lt;code&gt;RandomForestClassifier&lt;/code&gt; class (or </span>            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;RandomForestRegressor&lt;/code&gt; for regression tasks). A &lt;code&gt;RandomForestClassifier&lt;/code&gt; has all the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hyperparameters of a &lt;code&gt;DecisionTreeClassifier&lt;/code&gt; (to control how the trees are grown), plus all the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hyperparameters of a &lt;code&gt;BaggingClassifier&lt;/code&gt; (to control the ensemble itself). The random forest </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">algorithm introduces extra randomness when growing trees. Instead of searching for the very best feature when</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">splitting a node, it searches for the best feature among a random subset of features. This results in even </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">greater tree diversity, which trades a higher bias for a lower variance, generally yielding an overall better</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model.&lt;/p&gt;</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Feature Importance in Random Forests &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;One of the great qualities of random forests is that they make it easy to measure the relative </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">importance of each feature. Scikit-Learn measures a feature's importance by looking at how much the tree </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">nodes that use that feature reduce impurity on average across all trees in the forest. This score is computed</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">automatically for each feature after training and is available via the &lt;code&gt;feature_importances_&lt;/code&gt; </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">variable. Random forests are very handy for getting a quick understanding of what features actually matter, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">especially if you need to perform feature selection.&lt;/p&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Introduction to Boosting &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Let's shift gears and talk about boosting. Boosting refers to any ensemble method that can combine </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">several weak learners into a strong learner.&lt;/p&gt;</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Boosting Overview &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;The general idea behind most boosting methods is to train predictors sequentially, with each one </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trying to correct its predecessor. There are many boosting methods available, but the most popular are </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost and Gradient Boosting.&lt;/p&gt;</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;AdaBoost &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;One way for a new predictor to correct its predecessor is to pay more attention to the training </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instances that the predecessor underfit. This is the technique used by AdaBoost. The algorithm first trains a</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">base classifier (such as a decision tree) and uses it to make predictions on the training set. Then, it </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">increases the relative weight of misclassified training instances. It then trains a second classifier, using </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the updated weights, and repeats the process. Each predictor has a weight that depends on its accuracy on the</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weighted training set. The more accurate the predictor is, the higher its weight will be. To make </span>             <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictions, AdaBoost simply computes the predictions of all the predictors and weighs them using the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictor weights. The predicted class is the one that receives the majority of weighted votes. Scikit-Learn </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">uses a multiclass version of AdaBoost called SAMME. If the predictors can estimate class probabilities, </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn can use a variant of SAMME called SAMME.R, which relies on class probabilities and generally </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">performs better.&lt;/p&gt;</span>                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Gradient Boosting &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Another very popular boosting algorithm is gradient boosting. Just like AdaBoost, gradient boosting </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">works by sequentially adding predictors to an ensemble, with each one correcting its predecessor. However, </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instead of tweaking the instance weights at every iteration like AdaBoost does, this method tries to fit the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new predictor to the residual errors made by the previous predictor. This is called Gradient Tree Boosting, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">or Gradient Boosted Regression Trees (GBRT) when decision trees are used as predictors. You can use </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Scikit-Learn's &lt;code&gt;GradientBoostingRegressor&lt;/code&gt; class to train GBRT ensembles. A key hyperparameter is </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the &lt;code&gt;learning_rate&lt;/code&gt;, which scales each tree's contribution. Setting it to a low value requires </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">more trees but usually leads to better generalization. This is a regularization technique called </span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">shrinkage.&lt;/p&gt;</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Gradient Boosting - Advanced Techniques &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;To find the optimal number of trees, you can use early stopping. The &lt;code&gt;staged_predict()&lt;/code&gt; </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">method returns an iterator over the predictions made by the ensemble at each stage of training. You can also </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">implement early stopping by interrupting training when the validation error does not improve for a number of </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">iterations, using &lt;code&gt;warm_start=True&lt;/code&gt;. The &lt;code&gt;subsample&lt;/code&gt; hyperparameter specifies the </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fraction of training instances to be used for training each tree, trading higher bias for lower variance. </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">This is called stochastic gradient boosting.&lt;/p&gt;</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;HistGradientBoosting &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Scikit-Learn 1.0 introduced &lt;code&gt;HistGradientBoostingClassifier&lt;/code&gt; and </span>                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;HistGradientBoostingRegressor&lt;/code&gt;, which are faster, especially with large datasets. They bin the </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">inputs and look at these bins rather than exact values, support categorical features, and use a faster </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">technique to find the best split.&lt;/p&gt;</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Other Gradient Boosting Implementations &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Other popular gradient boosting libraries include XGBoost and CatBoost, which offer features like </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">automatic regularization and good handling of categorical features. The TensorFlow Random Forests library </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">provides optimized implementations of various random forest algorithms.&lt;/p&gt;</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Introduction to Stacking &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Finally, let's discuss stacking, which stands for stacked generalization.&lt;/p&gt;</span>                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Stacking Overview &lt;small&gt;~2 minutes&lt;/small&gt;&lt;/h2&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;The idea behind stacking is simple: instead of using trivial functions (such as hard voting) to </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aggregate the predictions of all predictors in an ensemble, why don't we train a model to perform this </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aggregation? This involves training a blender (or meta learner) that takes the predictions of the base </span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predictors as inputs and makes the final prediction.&lt;/p&gt;</span>                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Training the Blender &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;To train the blender, you first need to build a blending training set. You can use </span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;cross_val_predict()&lt;/code&gt; on every predictor in the ensemble to get out-of-sample predictions for each</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">instance in the original training set. These predictions are then used as input features to train the </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">blender, and the targets are copied from the original training set. The base predictors are then retrained </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">one last time on the full original training set.&lt;/p&gt;</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Multi-Layer Stacking &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;You can even train several different blenders to get a whole layer of blenders, and then add another </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">blender on top of that to produce the final prediction. This may squeeze out more performance but increases </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training time and complexity.&lt;/p&gt;</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Stacking in Scikit-Learn &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;Scikit-Learn provides &lt;code&gt;StackingClassifier&lt;/code&gt; and &lt;code&gt;StackingRegressor&lt;/code&gt; classes. The </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;StackingClassifier&lt;/code&gt; calls &lt;code&gt;predict_proba()&lt;/code&gt; if available, otherwise falls back to </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;decision_function()&lt;/code&gt; or &lt;code&gt;predict()&lt;/code&gt;. If no final estimator is provided, </span>                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;code&gt;LogisticRegression&lt;/code&gt; (for classification) or &lt;code&gt;RidgeCV&lt;/code&gt; (for regression) is used.&lt;/p&gt;</span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;h2&gt;Conclusion &lt;small&gt;~1 minute&lt;/small&gt;&lt;/h2&gt;</span>                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    &lt;p&gt;In conclusion, ensemble methods are versatile, powerful, and fairly simple to use. Random forests, </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">AdaBoost, and GBRT are among the first models you should test for most machine learning tasks. They shine </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">with heterogeneous tabular data and require little preprocessing. Voting classifiers and stacking classifiers</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">can help push your system's performance to its limits. Thanks for joining me today, and happy machine </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learning!&lt;/p&gt;</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;/body&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;/html&gt;</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ga2lYnN6J-Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_narrative = result.tasks_output[-1]\n",
        "with open(\"final_narrative.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(str(final_narrative))"
      ],
      "metadata": {
        "id": "gbnJW3diQtew"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_dict = result.model_dump()\n",
        "\n",
        "with open(\"crew_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result_dict, f, indent=4, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "_nbi1STNmcDE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}